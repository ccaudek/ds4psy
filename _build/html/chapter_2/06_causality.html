

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lo Studio delle Cause dei Fenomeni &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-VMXNE4BCDL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-VMXNE4BCDL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_2/06_causality';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4psy/chapter_2/06_causality.html" />
    <link rel="shortcut icon" href="../_static/increasing.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="La crisi della generalizzabilità" href="07_crisis.html" />
    <link rel="prev" title="Le relazioni tra variabili" href="05_correlation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_prelims.html">Preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_chapter_2.html">Statistica descrittiva</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Lo Studio delle Cause dei Fenomeni</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_3/introduction_chapter_3.html">Probabilità</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04_expval_var.html">Proprietà delle variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04a_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04b_illusion.html">Incertezza inferenziale e variabilità dei risultati</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/10_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_4/introduction_part_4.html">Inferenza bayesiana</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/01a_models.html">Modelli scientifici</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/03_conjugate_families_1.html">Distribuzioni coniugate (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/11_beta_binomial_pymc.html">Inferenza bayesiana con PyMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/12_jax.html">Usare JAX per un campionamento più veloce</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/16_summary_posterior_pymc.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/17_prediction.html">La predizione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/18_mcmc_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/19_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/20_poisson_model.html">Modello di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/21_poisson_sim.html">Modello di Poisson: derivazione analitica e MCMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_freq.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/22_normal_normal_model.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/23_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/24_multiple_groups.html">Gruppi multipli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/32_loo.html">Validazione Incrociata Leave-One-Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/40_hier_beta_binom.html">Modello gerarchico beta-binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/41_hier_poisson.html">Modello gerarchico di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/42_hier_gaussian.html">Modello gerarchico gaussiano</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/45_missing.html">1. Perdita di Dati Casuale e Indipendente dalle Cause</a></li>


<li class="toctree-l2"><a class="reference internal" href="../chapter_4/hssm.html">Drift Diffusion Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_1.html">Il modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_2.html">Analisi bayesiana del modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_params_recovery.html">Analisi di simulazione per la stima dei parametri nel modello di regressione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_3.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_4.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_causal_inference.html">Inferenza causale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_causal_inference.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_5.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_7.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_simpson.html">Paradosso di Simpson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_logistic_reg.html">Modello di regressione logistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_binomial_reg.html">Regressione binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_covid.html">Inferenza controfattuale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_counterfactual.html">Analisi causale con PyMC</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_stab.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_s_m_errors.html">Crisi della replicabilità</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_virtual_env.html">Ambiente virtuale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a52_reglin_2.html">Regressione lineare con Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a53_reglin_4.html">Posterior Predictive Checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4psy/blob/main/docs/chapter_2/06_causality.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_2/06_causality.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lo Studio delle Cause dei Fenomeni</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduzione-alla-ricerca-causale">Introduzione alla Ricerca Causale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#i-disegni-di-ricerca-e-la-causalita">I Disegni di Ricerca e la Causalità</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelli-causali-grafici">Modelli Causali Grafici</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#importanza-delle-assunzioni">Importanza delle Assunzioni</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduzione-ai-dag">Introduzione ai DAG</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caratteristiche-dei-dag">Caratteristiche dei DAG</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relazioni-complesse">Relazioni Complesse</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipi-di-percorsi">Tipi di Percorsi</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#strutture-causali-elementari">Strutture Causali Elementari</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#irreversibilita-e-aciclicita-nei-dag">Irreversibilità e Aciclicità nei DAG</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-confondimento-nei-dati-osservazionali">Il Confondimento nei Dati Osservazionali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uso-dei-dag-per-identificare-il-confondimento">Uso dei DAG per Identificare il Confondimento</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#identificazione-e-blocco-dei-percorsi-retrostanti">Identificazione e Blocco dei Percorsi Retrostanti</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#controllo-statistico-per-bloccare-i-percorsi-retrostanti">Controllo Statistico per Bloccare i Percorsi Retrostanti</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#obiettivo-del-controllo-di-terze-variabili">Obiettivo del Controllo di Terze Variabili</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#come-bloccare-un-percorso-retrostante">Come Bloccare un Percorso Retrostante</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pratiche-per-il-controllo-delle-variabili-in-un-dag">Pratiche per il Controllo delle Variabili in un DAG</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#come-controllare-una-variabile-nei-dati-osservazionali">Come Controllare una Variabile nei Dati Osservazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisi-stratificata">Analisi Stratificata</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#includere-variabili-terze-nei-modelli-di-regressione">Includere Variabili Terze nei Modelli di Regressione</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-matching-come-metodo-di-controllo-statistico">Il Matching come Metodo di Controllo Statistico</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#uso-del-matching-per-controllare-variabili-multiple">Uso del Matching per Controllare Variabili Multiple</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-sul-matching">Considerazioni sul Matching</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-di-misurazione-nelle-variabili-di-confondimento-e-il-suo-impatto">Errore di Misurazione nelle Variabili di Confondimento e il suo Impatto</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#influenza-dell-errore-di-misurazione">Influenza dell’Errore di Misurazione</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-dilemma-del-controllo-statistico-eccessivo">Il Dilemma del Controllo Statistico Eccessivo</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pratica-comune-e-i-suoi-limiti">Pratica Comune e i suoi Limiti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tipi-di-variabili-da-non-controllare">Tipi di Variabili da Non Controllare</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisi-dei-rischi-nel-controllo-di-collider-e-mediatori">Analisi dei Rischi nel Controllo di Collider e Mediatori</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-bias-del-collider-nelle-procedure-di-campionamento">Il Bias del Collider nelle Procedure di Campionamento</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-di-non-risposta">Bias di Non Risposta</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-di-attrito">Bias di Attrito</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problemi-correlati-dati-mancanti-e-rappresentativita-nei-dati-osservazionali">Problemi Correlati: Dati Mancanti e Rappresentatività nei Dati Osservazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-di-selezione-endogena-e-dati-mancanti">Bias di Selezione Endogena e Dati Mancanti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#problema-della-non-rappresentativita-dei-campioni">Problema della Non Rappresentatività dei Campioni</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-bias-da-sovracontrollo-la-rimozione-dei-processi-di-interesse">Il Bias da Sovracontrollo: La Rimozione dei Processi di Interesse</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sovracontrollo-e-bias">Sovracontrollo e Bias</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-complessita-delle-inferenze-causali-sui-dati-correlazionali">La Complessità delle Inferenze Causali sui Dati Correlazionali</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-conclusive">Considerazioni Conclusive</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <a target="_blank" href="https://colab.research.google.com/github/ccaudek/ds4psy_2023/blob/main/070_correlation.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
<section class="tex2jax_ignore mathjax_ignore" id="lo-studio-delle-cause-dei-fenomeni">
<span id="correlation-causation-notebook"></span><h1>Lo Studio delle Cause dei Fenomeni<a class="headerlink" href="#lo-studio-delle-cause-dei-fenomeni" title="Permalink to this heading">#</a></h1>
<p>Per assicurare l’integrità e la validità scientifica dei modelli statistici, è essenziale abbinarli a un’analisi causale. La pura osservazione dei dati può rivelare correlazioni e pattern nei dati, ma senza un’indagine sulle cause che stanno dietro a queste correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.</p>
<p>Anche nell’ambito di una discussione sull’<em>analisi descrittiva</em> dei dati (e, forse, soprattutto in un tale contesto), è importante sottolineare le limitazioni di un tale approccio. L’aspetto cruciale da tenere a mente è che le cause dei fenomeni non possono essere inferite <em>solamente</em> dall’analisi dei dati. Né dall’analisi descrittiva dei dati che stiamo discutendo adesso, né dall’analisi inferenziale dei dati che discuteremo in seguito. Pertanto, per giungere ad una comprensione dei fenomeni è necessario integrare il processo di modellazione statistica con una comprensione delle cause sottostanti del fenomeno oggetto d’esame. In altre parole, per una comprensione scientificamente valida, è necessario combinare la modellazione statistica e con l’analisi causale.</p>
<p>In questo capitolo, ci concentreremo sull’introduzione dei concetti fondamentali dell’analisi causale, i quali costituiscono una base cruciale per l’interpretazione dei dati. Cominceremo con la distinzione chiara e universalmente riconosciuta tra correlazione e causalità. La correlazione indica una relazione tra due variabili, mettendo in evidenza la loro forza e direzione, mentre la causalità implica un legame di causa ed effetto tra le variabili. È di importanza cruciale comprendere che il fatto che due variabili siano correlate non implica automaticamente l’esistenza di un rapporto causale tra di esse. Il noto principio “correlazione non implica causalità” sottolinea questa distinzione critica. Numerosi esempi di correlazioni che non sono basate su una relazione causale diretta possono essere esaminati sul sito <a class="reference external" href="https://tylervigen.com/spurious-correlations">spurious correlations</a>.</p>
<p>Oltre a questo concetto fondamentale, procederemo quindi ad esplorare una serie di concetti introdotti da Judea Pearl nel suo testo “Causality” <span id="id1">[<a class="reference internal" href="../references/bibliography.html#id3" title="Judea Pearl. Causality. Cambridge University Press, 2009.">Pea09</a>]</span>. Questi concetti sono essenziali per descrivere le relazioni tra variabili. Essi includono strutture di relazione come biforcazioni, catene, collider e strutture discendenti. Questa cornice concettuale ci permetterà di discernere tra i diversi tipi di legami causali tra le variabili, ponendo così le basi per condurre un’analisi dei dati più completa e accurata.</p>
<p>Mediante esempi numerici, dimostreremo l’importanza dei fattori confondenti nell’analisi della correlazione e della covarianza. Questo passo ci condurrà oltre l’analisi delle relazioni bivariate di base, introducendoci alle dinamiche più complesse che regolano le relazioni tra le variabili.</p>
<section id="preparazione-del-notebook">
<h2>Preparazione del Notebook<a class="headerlink" href="#preparazione-del-notebook" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">graphviz</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">palette</span><span class="o">=</span><span class="s2">&quot;colorblind&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="introduzione-alla-ricerca-causale">
<h2>Introduzione alla Ricerca Causale<a class="headerlink" href="#introduzione-alla-ricerca-causale" title="Permalink to this heading">#</a></h2>
<p>L’inferenza causale è un processo cruciale nella previsione degli effetti di un intervento. Essa non solo permette di anticipare le conseguenze di una causa, ma anche di costruire scenari controfattuali, immaginando gli esiti alternativi che sarebbero potuti accadere se fossero state prese decisioni diverse. Questo tipo di ragionamento si rivela fondamentale anche in contesti puramente descrittivi, come nell’analisi di un campione di studio rispetto alla popolazione generale. Per comprendere le ragioni di eventuali discrepanze tra campione e popolazione, è necessario adottare un approccio causale che vada oltre la semplice descrizione dei dati, fornendo un modello causale che spieghi le differenze osservate.</p>
<p><span id="id2">McElreath [<a class="reference internal" href="../references/bibliography.html#id114" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press, Boca Raton, Florida, 2nd edition edition, 2020.">McE20</a>]</span> utilizza l’analogia dei Golem, robot di argilla potenti ma privi di saggezza e previsione, per descrivere un approccio limitante che è stato a lungo lo standard in psicologia.</p>
<figure class="align-default" id="golem-fig">
<a class="reference internal image-reference" href="../_images/mcelreath_golem.png"><img alt="../_images/mcelreath_golem.png" src="../_images/mcelreath_golem.png" style="height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall’alto, l’utente risponde a una serie di domande riguardanti la misurazione e l’intento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili.  (Figura tratta da <span id="id3">McElreath [<a class="reference internal" href="../references/bibliography.html#id114" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press, Boca Raton, Florida, 2nd edition edition, 2020.">McE20</a>]</span>).</span><a class="headerlink" href="#golem-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Questo approccio si concentra sul semplice test delle ipotesi nulle e non stabilisce una relazione chiara tra le problematiche causali della ricerca e i test statistici. Tale limitazione è stata considerata come una delle cause principali della crisi della replicabilità dei risultati nella ricerca psicologica (si veda il capitolo <a class="reference internal" href="07_crisis.html#generalizability-crisis-notebook"><span class="std std-ref">La crisi della generalizzabilità</span></a>) e, di conseguenza, della crisi della psicologia stessa.</p>
<p>Uno dei problemi messi in evidenza da McElreath nel suo lavoro “Statistical Rethinking” <span id="id4">[<a class="reference internal" href="../references/bibliography.html#id114" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press, Boca Raton, Florida, 2nd edition edition, 2020.">McE20</a>]</span> è che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sul test dell’ipotesi nulla non è in grado di distinguere tra questi diversi scenari. Questa constatazione è dimostrata in modo numerico nel capitolo dedicato all’inferenza causale <a class="reference internal" href="../chapter_5/05_causal_inference.html#causal-inference-notebook"><span class="std std-ref">Inferenza causale</span></a>.</p>
<p>Questa limitazione dell’approccio tradizionale viene paragonata da McElreath a un “Golem” nella data science, una metafora che fa eco a una creatura mitologica senza vita, potente ma stupida. Questo approccio è stato particolarmente diffuso in psicologia per decenni, nonostante sia stato dimostrato che è caratterizzato una bassa sensibilità, il che significa che è poco in grado di rilevare le caratteristiche cruciali dei fenomeni studiati. Inoltre, ha un alto tasso di falsi positivi, cioè tende a concludere erroneamente che ci sono differenze quando in realtà non esistono. Questa problematica è discussa, ad esempio, nel lavoro di <a href="#id5"><span class="problematic" id="id6">van2023new</span></a>.</p>
<p>La ricerca scientifica richiede una metodologia più sofisticata rispetto al mero “Golem” che si limita a confutare ipotesi nulle. È invece essenziale sviluppare modelli causali generativi e modelli statistici che siano solidamente basati su tali modelli generativi e rispondano alle domande di ricerca. Inoltre, è di fondamentale importanza avere una strategia razionale per l’estrazione delle stime dei modelli e per la quantificazione dell’incertezza associata ad esse. In questo contesto, l’analisi bayesiana dei dati si presenta come un approccio altamente efficace. In analisi semplici, le differenze rispetto all’approccio del “Golem” potrebbero sembrare minimali o addirittura introdurre alcune complicazioni. Tuttavia, quando ci si trova ad affrontare analisi più realistiche e complesse, la differenza diventa sostanziale.</p>
<p>Per condurre un’analisi scientifica dei dati che superi l’approccio “amatoriale” rappresentato dai “Golem”, <span id="id7">McElreath [<a class="reference internal" href="../references/bibliography.html#id114" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press, Boca Raton, Florida, 2nd edition edition, 2020.">McE20</a>]</span> suggerisce di seguire una serie di passaggi chiave:</p>
<ol class="arabic simple">
<li><p>Comprensione del concetto teorico oggetto della stima. Questo richiede la costruzione di una solida base teorica e una definizione chiara del fenomeno oggetto dell’analisi.</p></li>
<li><p>Sviluppo di modelli causali che descrivano accuratamente le relazioni tra le variabili coinvolte nel problema di ricerca. Questi modelli devono essere basati sulla teoria sottostante.</p></li>
<li><p>Utilizzo delle informazioni ottenute dai passaggi precedenti per formulare modelli statistici appropriati. Questi modelli dovrebbero riflettere fedelmente il contesto scientifico e le relazioni causali che sono state identificate.</p></li>
<li><p>Esecuzione di simulazioni basate sui modelli causali per verificare se i modelli statistici sviluppati siano in grado di stimare correttamente ciò che è teoricamente atteso. Questa fase di verifica è cruciale per garantire la validità dei modelli.</p></li>
<li><p>Infine, condurre l’analisi dei dati effettivi utilizzando i modelli statistici sviluppati, avendo la fiducia che questi modelli riflettano accuratamente le teorie sottostanti e le relazioni causali.</p></li>
</ol>
<p>Un elemento chiave sottolineato da <span id="id8">McElreath [<a class="reference internal" href="../references/bibliography.html#id114" title="Richard McElreath. Statistical rethinking: A Bayesian course with examples in R and Stan. CRC Press, Boca Raton, Florida, 2nd edition edition, 2020.">McE20</a>]</span> nel processo di analisi è l’utilizzo dei “Directed Acyclic Graphs” (DAG), che rappresentano uno strumento essenziale per realizzare il flusso di lavoro descritto. I DAG forniscono una rappresentazione grafica dei modelli causali, consentendo una visualizzazione chiara delle relazioni tra le variabili coinvolte. Questi grafici rendono trasparenti le assunzioni alla base dell’analisi, creando una connessione evidente tra le teorie sottostanti e l’analisi statistica. In contrasto, l’approccio dei “Golems” è caratterizzato dall’assenza di ipotesi sulle relazioni sottostanti tra le variabili. Questo rende difficile comprendere e interpretare le implicazioni scientifiche dei risultati ottenuti, poiché manca un collegamento chiaro tra le teorie e l’analisi statistica. Per un approfondimento, si veda il primo capitolo di <a class="reference external" href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking</a>.</p>
<section id="i-disegni-di-ricerca-e-la-causalita">
<h3>I Disegni di Ricerca e la Causalità<a class="headerlink" href="#i-disegni-di-ricerca-e-la-causalita" title="Permalink to this heading">#</a></h3>
<p>Per comprendere meglio l’uso dei DAG nell’inferenza causale, faremo riferimento alla trattazione fornita da un articolo di <span id="id9">[<a class="reference internal" href="../references/bibliography.html#id8" title="Julia M Rohrer. Thinking clearly about correlations and causation: graphical causal models for observational data. Advances in methods and practices in psychological science, 1(1):27–42, 2018.">Roh18</a>]</span> relativo alla ricerca sulla causalità nei disegni osservazionali.</p>
<p><strong>Disegni Osservazionali</strong>
Nei disegni osservazionali, i ricercatori osservano e registrano gli eventi senza intervenire direttamente. A differenza degli esperimenti controllati, qui non si manipolano le variabili studiate, ma si osservano le relazioni naturali che emergono. Questi studi sono preziosi quando gli esperimenti non sono fattibili per motivi etici o pratici. Tuttavia, i disegni osservazionali, sebbene efficaci nell’identificare correlazioni e tendenze, spesso mancano della capacità di stabilire con certezza relazioni causali, a causa di variabili confondenti e bias di selezione. Esempi comuni di disegni osservazionali includono studi trasversali e longitudinali.</p>
<p><strong>Disegni Sperimentali</strong>
I disegni sperimentali, d’altra parte, si basano sulla manipolazione controllata delle variabili e sulla randomizzazione. Quest’ultima, ovvero l’assegnazione casuale dei partecipanti ai gruppi, è fondamentale per ridurre i bias e garantire la validità delle conclusioni causali. Gli esperimenti randomizzati sono considerati il gold standard per indagare le relazioni causali, in quanto la randomizzazione consente di bilanciare gli effetti delle variabili osservate e non osservate tra i diversi gruppi di trattamento.</p>
<p><strong>Confronto e Considerazioni</strong>
Sebbene gli esperimenti offrano un elevato grado di sicurezza nella determinazione delle relazioni causali, i disegni osservazionali presentano vantaggi in termini di flessibilità e applicabilità in situazioni in cui gli esperimenti non possono essere condotti per motivi etici o pratici. Tuttavia, va notato che, da un lato, i disegni osservazionali spesso si basano su relazioni associative piuttosto che causali, e d’altro canto, gli esperimenti potrebbero non consentire una generalizzazione al di là delle condizioni artificiali del laboratorio.</p>
<p><strong>Definizione della Causalità</strong>
Nel contesto della ricerca, il concetto di causalità si riferisce a come una variabile (X) possa influenzare o determinare un’altra variabile (Y). Il linguaggio causale si serve di termini come “causa”, “influenza” e “determina”, a differenza di termini descrittivi come “associato” o “correlato”, che semplicemente indicano relazioni senza implicare un legame causale diretto. Va notato che la causalità è concepita come un concetto probabilistico, il che significa che una variazione in X aumenta la probabilità di un certo risultato in Y, piuttosto che determinarlo in modo assoluto.</p>
<p>Nella pratica della ricerca psicologica e sociale, spesso è necessario dedurre relazioni causali da dati osservazionali, poiché gli esperimenti randomizzati non sono sempre fattibili o eticamente accettabili. Di conseguenza, i ricercatori devono affrontare sfide e limitazioni, cercando di inferire relazioni causali in modi alternativi, sottolineando la complessità dell’analisi causale in contesti reali.</p>
<p><strong>Strategie di Ricerca nei Dati Osservazionali</strong></p>
<p>Nell’ambito della ricerca che si basa su dati osservazionali, gli studiosi si confrontano con diverse sfide che possono compromettere l’integrità e l’accuratezza delle inferenze tratte dai loro studi. Per affrontare tali sfide e accrescere la robustezza delle loro analisi, i ricercatori impiegano una varietà di strategie metodologiche.</p>
<ol class="arabic simple">
<li><p><strong>Uso di interventi surrogati.</strong> Questa tecnica si rivela particolarmente utile in situazioni dove la manipolazione diretta di una variabile di interesse risulta impraticabile o non etica. Piuttosto che intervenire direttamente, i ricercatori si avvalgono di variabili surrogate (o proxy), ovvero variabili che si presume siano in relazione con la variabile di interesse principale. L’obiettivo è di esplorare e dedurre l’effetto indiretto di una variabile su un’altra, stabilendo così associazioni che, pur non essendo dirette, possono fornire insight significativi sul fenomeno in esame.</p></li>
</ol>
<p>Tuttavia, l’approccio surrogato comporta delle sfide intrinseche. La principale tra queste è la difficoltà nel garantire una relazione diretta tra la variabile surrogata e la variabile di interesse. La validità delle inferenze tratte tramite variabili surrogate dipende fortemente dalla solidità dell’associazione tra queste e le variabili di interesse principali.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Linguaggio prudente nell’interpretazione dei dati</strong>: I ricercatori utilizzano un linguaggio cauto quando interpretano dati osservazionali. Ciò significa che evitano di fare affermazioni causali dirette quando i dati mostrano solo correlazioni.</p></li>
<li><p><strong>Utilizzo di metodi statistici avanzati per controllare variabili confondenti</strong>: Le variabili confondenti sono fattori esterni che possono influenzare il rapporto tra le variabili studiate. L’uso di tecniche statistiche, come la regressione multipla o l’analisi di matching, aiuta a controllare l’effetto di queste variabili confondenti, permettendo una stima più accurata del rapporto tra le variabili di interesse. Tuttavia, questi metodi hanno limiti (come vedremo nel capitolo <a class="reference internal" href="../chapter_5/05_causal_inference.html#causal-inference-notebook"><span class="std std-ref">Inferenza causale</span></a>) poiché potrebbero non riuscire a controllare completamente tutte le variabili confondenti, soprattutto in situazioni complesse.</p></li>
</ol>
<p><span id="id10">Rohrer [<a class="reference internal" href="../references/bibliography.html#id8" title="Julia M Rohrer. Thinking clearly about correlations and causation: graphical causal models for observational data. Advances in methods and practices in psychological science, 1(1):27–42, 2018.">Roh18</a>]</span> sottolinea che, nonostante l’adozione di queste strategie, persistono sfide in termini di validità esterna (cioè la generalizzabilità dei risultati) e interpretazione dei dati. La validità esterna può essere limitata poiché le condizioni specifiche dello studio potrebbero non rappresentare situazioni più ampie o diverse. Inoltre, l’interpretazione dei risultati può essere complicata dalla natura indiretta o surrogata delle evidenze raccolte.</p>
</section>
</section>
<section id="modelli-causali-grafici">
<h2>Modelli Causali Grafici<a class="headerlink" href="#modelli-causali-grafici" title="Permalink to this heading">#</a></h2>
<p>L’uso di dati osservazionali per trarre inferenze causali presenta sfide significative, ma con le giuste precauzioni e approcci metodologici, è possibile ottenere insight causali preziosi. In questo contesto, <span id="id11">Rohrer [<a class="reference internal" href="../references/bibliography.html#id8" title="Julia M Rohrer. Thinking clearly about correlations and causation: graphical causal models for observational data. Advances in methods and practices in psychological science, 1(1):27–42, 2018.">Roh18</a>]</span> evidenzia l’importanza dei DAG come strumento chiave per la rappresentazione visiva delle ipotesi causali. Questi diagrammi non solo facilitano la comprensione delle relazioni causali tra variabili ma offrono anche una guida per la corretta identificazione e trattamento delle variabili esterne, spesso chiamate “variabili di confondimento”.</p>
<p>Una delle funzioni più rilevanti dei DAGs è la loro capacità di identificare quali variabili di confondimento devono essere considerate nell’analisi e quali possono essere omesse senza compromettere l’integrità dell’inferenza causale. Questa caratteristica è essenziale, dato che sia il controllo insufficiente sia quello eccessivo delle variabili di confondimento possono portare a conclusioni errate (questo punto verrà approfondito nel capitolo <a class="reference internal" href="../chapter_5/05_causal_inference.html#causal-inference-notebook"><span class="std std-ref">Inferenza causale</span></a>). In particolare, i DAGs aiutano a discernere quando l’aggiustamento per certe variabili di confondimento può migliorare l’accuratezza delle inferenze causali e quando, al contrario, tale aggiustamento potrebbe introdurre distorsioni.</p>
<p>Grazie ai DAGs, i ricercatori possono esplicitare le loro ipotesi sulle relazioni causali tra le variabili, minimizzando così il rischio di incorrere negli errori comuni legati all’interpretazione di dati osservazionali. Questo approccio permette di elaborare una strategia di analisi più informata e metodologicamente solida, con l’obiettivo di avvicinarsi il più possibile alla comprensione delle dinamiche causali sottostanti.</p>
<section id="importanza-delle-assunzioni">
<h3>Importanza delle Assunzioni<a class="headerlink" href="#importanza-delle-assunzioni" title="Permalink to this heading">#</a></h3>
<p>È cruciale comprendere che non è possibile estrapolare conclusioni causali meramente da dati correlazionali senza un solido fondamento di conoscenze preliminari. Questo principio nasce dalla consapevolezza che una correlazione osservata può essere attribuibile a un’ampia gamma di fattori, inclusa la potenziale influenza di variabili terze non considerate nell’analisi. Di conseguenza, qualsiasi tentativo di inferenza causale privo una comprensione preliminare delle possibili relazioni causali rischia di essere fallace.</p>
<p>Nonostante tali sfide, è fondamentale non demordere di fronte alla complessità intrinseca della ricerca osservazionale. Sebbene questi studi non possano dimostrare inequivocabilmente la causalità a causa della loro intrinseca limitazione nel manipolare direttamente le variabili di interesse, mantengono un ruolo insostituibile nell’ambito scientifico. Gli studi osservazionali sono preziosi per la generazione di ipotesi e per orientare le ricerche future verso domande scientifiche rilevanti. Analogamente, anche gli studi sperimentali, pur essendo considerati il gold standard per la determinazione delle relazioni causali, non sono immuni da presupposti. Gli esperimenti, specialmente quelli condotti in ambienti altamente controllati come i laboratori, presuppongono che i risultati ottenuti siano generalizzabili oltre i confini dello studio, un’assunzione che non trova sempre conferma nella realtà.</p>
<p>In questo contesto, l’elemento distintivo di un’indagine rigorosa, sia essa osservazionale che sperimentale, risiede nella capacità di riconoscere, articolare e comunicare apertamente le assunzioni su cui si basa. Questo approccio non solo facilita una valutazione critica delle conclusioni causali da parte della comunità scientifica ma stimola anche un dialogo costruttivo e produttivo all’interno della stessa, essenziale per il progresso della conoscenza. La trasparenza nell’esposizione delle ipotesi permette di gettare le fondamenta per un avanzamento scientifico che sia informato, consapevole e, soprattutto, veritiero.</p>
</section>
</section>
<section id="introduzione-ai-dag">
<h2>Introduzione ai DAG<a class="headerlink" href="#introduzione-ai-dag" title="Permalink to this heading">#</a></h2>
<p>I DAGs vengono impiegati per analizzare l’effetto causale di una variabile su un’altra. Consideriamo come esempio <span id="id12">[<a class="reference internal" href="../references/bibliography.html#id8" title="Julia M Rohrer. Thinking clearly about correlations and causation: graphical causal models for observational data. Advances in methods and practices in psychological science, 1(1):27–42, 2018.">Roh18</a>]</span> l’effetto dell’istruzione sul reddito. Immaginiamo di dividere il livello di istruzione in due categorie: laurea o nessuna laurea entro i 30 anni. Successivamente, misuriamo il reddito a 40 anni. È importante sottolineare che non possiamo dedurre direttamente che il possesso di una laurea causa un aumento del reddito, poiché esistono numerose altre variabili che possono influenzare il reddito.</p>
<p>I DAGs ci aiutano a visualizzare questa complessa rete di relazioni causali in modo chiaro. In un DAG, le frecce rappresentano le relazioni causali tra le variabili, e l’assenza di cicli ricorsivi garantisce che le relazioni siano direzionali, ovvero vanno da una variabile all’altra senza creare loop causali.</p>
<p>Nel nostro esempio, il livello di istruzione può influenzare il reddito, ma ci sono anche altri fattori da considerare, come l’intelligenza, ad esempio. Un DAG ci permetterà di rappresentare queste relazioni in modo chiaro, mostrando come il livello di istruzione può avere un impatto indiretto sul reddito attraverso altre variabili.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Digraph</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">ranksep</span><span class="o">=</span><span class="s2">&quot;0.5&quot;</span><span class="p">)</span>  <span class="c1"># Aumenta la separazione tra i livelli</span>
<span class="n">f</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">nodesep</span><span class="o">=</span><span class="s2">&quot;1.0&quot;</span><span class="p">)</span>  <span class="c1"># Aumenta la separazione tra i nodi sullo stesso livello</span>

<span class="c1"># Crea un subgraph con lo stesso rank</span>
<span class="k">with</span> <span class="n">f</span><span class="o">.</span><span class="n">subgraph</span><span class="p">()</span> <span class="k">as</span> <span class="n">s</span><span class="p">:</span>
    <span class="n">s</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
    <span class="c1"># Aggiungi i nodi al subgraph</span>
    <span class="n">s</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">&quot;Istruzione&quot;</span><span class="p">)</span>
    <span class="n">s</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">&quot;Reddito&quot;</span><span class="p">)</span>

<span class="c1"># Definisci le relazioni tra i nodi</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Intelligenza&quot;</span><span class="p">,</span> <span class="s2">&quot;Istruzione&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Intelligenza&quot;</span><span class="p">,</span> <span class="s2">&quot;Reddito&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Istruzione&quot;</span><span class="p">,</span> <span class="s2">&quot;Reddito&quot;</span><span class="p">)</span>

<span class="c1"># Visualizza il DAG</span>
<span class="n">f</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1e11a8c1e63732a34329940e4a653c9e9d602c9bae82294ee1c1775763089ea2.svg" src="../_images/1e11a8c1e63732a34329940e4a653c9e9d602c9bae82294ee1c1775763089ea2.svg" /></div>
</div>
<p>Nel DAG illustrato nella figura precedente, l’associazione tra il livello di istruzione e il reddito è complicata da una variabile terza, cioè l’intelligenza. Il modello causale che emerge da questo DAG suggerisce che l’intelligenza influenza sia il livello di istruzione che il reddito. Queste ipotesi di causalità sono rappresentate dalle frecce che si estendono dall’intelligenza alle altre variabili nel diagramma. Inoltre, notiamo che c’è una freccia che collega direttamente il livello di istruzione al reddito, indicando che, oltre all’effetto causale dell’intelligenza, si assume che anche il livello di istruzione abbia un impatto causale diretto sul reddito.</p>
<section id="caratteristiche-dei-dag">
<h3>Caratteristiche dei DAG<a class="headerlink" href="#caratteristiche-dei-dag" title="Permalink to this heading">#</a></h3>
<p>I DAG forniscono dunque delle rappresentazioni grafiche che illustrano le relazioni causali ipotizzate tra le variabili. In un DAG, ogni nodo rappresenta una variabile, mentre le frecce indicano le relazioni causali tra di esse. La manipolazione sperimentale di una variabile all’origine di una freccia (per esempio, l’intervento sul livello di istruzione) si presume abbia effetti sulla variabile verso cui la freccia punta (in questo caso, il reddito). In un DAG, ogni variabile deve essere collegata tramite una freccia ad almeno un’altra variabile verso cui esercita un’inflenza causale; la direzione della freccia stabilisce la direzione di tale relazione causale.</p>
<p>I DAG sono considerati strumenti qualitativi: una freccia che va da A a B indica che A ha un qualche tipo di effetto su B, ma non specifica la natura esatta o l’intensità di questa relazione. Diversamente dai modelli di equazioni strutturali (SEM), i DAG non includono frecce bidirezionali, ma solo monodirezionali, per sottolineare la direzione univoca dell’influenza causale.</p>
</section>
<section id="relazioni-complesse">
<h3>Relazioni Complesse<a class="headerlink" href="#relazioni-complesse" title="Permalink to this heading">#</a></h3>
<p>I DAG sono costituiti da una serie di nodi e frecce che vengono impiegati per visualizzare situazioni intricate e per tracciare percorsi causali tra le variabili. Per esemplificare ulteriormente questo concetto, nel DAG presente nella figura successiva, abbiamo introdotto un nuovo nodo, “voti scolastici”, che è influenzato dall’intelligenza e, a sua volta, influisce sul livello di istruzione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Digraph</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">ranksep</span><span class="o">=</span><span class="s2">&quot;0.5&quot;</span><span class="p">)</span>  <span class="c1"># Aumenta la separazione tra i livelli</span>
<span class="n">f</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">nodesep</span><span class="o">=</span><span class="s2">&quot;1.0&quot;</span><span class="p">)</span>  <span class="c1"># Aumenta la separazione tra i nodi sullo stesso livello</span>

<span class="c1"># Crea un subgraph con lo stesso rank</span>
<span class="k">with</span> <span class="n">f</span><span class="o">.</span><span class="n">subgraph</span><span class="p">()</span> <span class="k">as</span> <span class="n">s</span><span class="p">:</span>
    <span class="n">s</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
    <span class="c1"># Aggiungi i nodi &quot;Istruzione&quot; e &quot;Reddito&quot; al subgraph</span>
    <span class="n">s</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">&quot;Istruzione&quot;</span><span class="p">)</span>
    <span class="n">s</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">&quot;Reddito&quot;</span><span class="p">)</span>

<span class="c1"># Aggiungi il nodo &quot;Voti Scolastici&quot;</span>
<span class="n">f</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">&quot;Voti Scolastici&quot;</span><span class="p">)</span>

<span class="c1"># Definisci le relazioni tra i nodi</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Intelligenza&quot;</span><span class="p">,</span> <span class="s2">&quot;Istruzione&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Intelligenza&quot;</span><span class="p">,</span> <span class="s2">&quot;Reddito&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span>
    <span class="s2">&quot;Intelligenza&quot;</span><span class="p">,</span> <span class="s2">&quot;Voti Scolastici&quot;</span>
<span class="p">)</span>  <span class="c1"># Aggiungi relazione tra Intelligenza e Voti Scolastici</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span>
    <span class="s2">&quot;Voti Scolastici&quot;</span><span class="p">,</span> <span class="s2">&quot;Istruzione&quot;</span>
<span class="p">)</span>  <span class="c1"># Aggiungi relazione tra Voti Scolastici e Istruzione</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Istruzione&quot;</span><span class="p">,</span> <span class="s2">&quot;Reddito&quot;</span><span class="p">)</span>

<span class="n">f</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/cfe49153a0093c5d707f23bcfdf0ef9a9e55cea97b9bd54c22379eb102caa139.svg" src="../_images/cfe49153a0093c5d707f23bcfdf0ef9a9e55cea97b9bd54c22379eb102caa139.svg" /></div>
</div>
</section>
<section id="tipi-di-percorsi">
<h3>Tipi di Percorsi<a class="headerlink" href="#tipi-di-percorsi" title="Permalink to this heading">#</a></h3>
<p>Nei DAGs, i percorsi rappresentano le connessioni causali ipotizzate tra le variabili, delineate attraverso frecce che indicano la direzione dell’effetto presunto. Un percorso semplice connette direttamente due nodi, per esempio, da “intelligenza” a “reddito”, suggerendo che l’intelligenza influisce direttamente sul reddito. Percorsi più complessi possono includere più nodi, come nel caso di “intelligenza → istruzione → reddito”, dove l’istruzione agisce come una variabile mediatrice che trasmette l’effetto dell’intelligenza sul reddito.</p>
<p>Un percorso può anche andare contro la direzione indicata dalle frecce, come nel caso di istruzione ← voti ← intelligenza → reddito. I percorsi che vanno contro la direzione delle frecce richiedono un’attenzione particolare. Nei DAGs, un percorso che procede contro la direzione delle frecce indica generalmente una relazione di confondimento o una dipendenza condizionale tra le variabili, piuttosto che un effetto causale.</p>
</section>
</section>
<section id="strutture-causali-elementari">
<h2>Strutture Causali Elementari<a class="headerlink" href="#strutture-causali-elementari" title="Permalink to this heading">#</a></h2>
<p>All’interno dei DAG, si possono riconoscere tre tipologie fondamentali di strutture causali: catene, biforcazioni e biforcazioni invertite.</p>
<ol class="arabic simple">
<li><p><strong>Catene (X → Z → Y)</strong>: Le catene, conosciute anche come sequenze causali o <em>pipe</em>, sono strutture rappresentate dalla successione X <span class="math notranslate nohighlight">\(\rightarrow\)</span> Z <span class="math notranslate nohighlight">\(\rightarrow\)</span> Y, dove una variabile intermedia Z trasmette l’effetto causale da X a Y. Questa struttura riflette una vera e propria catena di causalità. Un esempio potrebbe essere: intelligenza (X) influisce sul livello di istruzione (Z), che a sua volta influisce sul reddito (Y). In questa catena, il livello di istruzione agisce come un mediatore tra intelligenza e reddito.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Digraph</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;LR&#39;</span><span class="p">)</span>
<span class="n">f</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0403e612a1c981672b1ee4a38f37afca00d7d84309c42edcb2b1cae0caa3422f.svg" src="../_images/0403e612a1c981672b1ee4a38f37afca00d7d84309c42edcb2b1cae0caa3422f.svg" /></div>
</div>
<ol class="arabic simple" start="2">
<li><p><strong>Biforcazioni (X ← Z → Y)</strong>: Nel contesto dei Diagrammi Aciclici Diretti (DAGs), le <em>biforcazioni</em>, rappresentate dalla struttura <span class="math notranslate nohighlight">\(X \leftarrow Z \rightarrow Y\)</span>, giocano un ruolo cruciale nell’analisi causale, poiché evidenziano situazioni in cui una variabile comune <span class="math notranslate nohighlight">\(Z\)</span> funge da causa antecedente per due variabili distinte, <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>. Questo schema non denota una relazione causale diretta tra <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>, ma indica piuttosto che entrambe sono influenzate da <span class="math notranslate nohighlight">\(Z\)</span>, una causa comune. Questa configurazione è essenziale per capire il fenomeno del <em>confondimento</em>, che si verifica quando una correlazione osservata tra <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span> può essere attribuita alla presenza di <span class="math notranslate nohighlight">\(Z\)</span>.</p></li>
</ol>
<p>Per illustrare meglio questo concetto, prendiamo in esame le variabili rappresentate dal livello di istruzione (<span class="math notranslate nohighlight">\(X\)</span>) e dal reddito (<span class="math notranslate nohighlight">\(Y\)</span>), tra cui si osserva una correlazione. Questa correlazione, tuttavia, non implica necessariamente un legame di causalità diretta tra istruzione e reddito. Potrebbe invece emergere dall’influenza di una terza variabile, come l’intelligenza (<span class="math notranslate nohighlight">\(Z\)</span>), che agisce come causa comune influenzando sia <span class="math notranslate nohighlight">\(X\)</span> che <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>In questa situazione, l’associazione percepita tra istruzione e reddito non deriva da un’influenza diretta dell’una sull’altro, ma piuttosto dall’influenza esercitata dall’intelligenza su entrambe. Introducendo il concetto di <em>condizionamento</em>, ovvero l’analisi dei dati tenendo conto dei diversi livelli di intelligenza, è possibile chiarire la natura di questa associazione. Condizionando su <span class="math notranslate nohighlight">\(Z\)</span> (l’intelligenza), e quindi esaminando i dati all’interno di gruppi che condividono lo stesso livello di intelligenza, l’associazione apparente tra istruzione e reddito potrebbe attenuarsi o scomparire del tutto. Questo processo dimostra che la correlazione inizialmente osservata tra istruzione e reddito non è il risultato di un effetto diretto tra queste variabili, ma piuttosto l’effetto di una causa comune.</p>
<p>Il condizionamento, quindi, permette di stratificare i dati in base a <span class="math notranslate nohighlight">\(Z\)</span>, isolando l’effetto delle variabili di interesse da quello delle cause comuni. Questa metodologia è fondamentale per discernere le relazioni causali autentiche da quelle che appaiono meramente correlazionali a causa di confondimenti, offrendo una comprensione più precisa delle dinamiche causali sottostanti.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Digraph</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">f</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/21656cd2b29b1d0c7f94e4410b98b3ec83dfc35fbbeb57d859900d0d56d84d70.svg" src="../_images/21656cd2b29b1d0c7f94e4410b98b3ec83dfc35fbbeb57d859900d0d56d84d70.svg" /></div>
</div>
<ol class="arabic simple" start="3">
<li><p><strong>Biforcazioni Invertite (X → Z ← Y)</strong>: Le <strong>biforcazioni invertite</strong>, note anche come <em>collider</em>, presentano una configurazione specifica in cui due variabili, <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>, convergono influenzando una terza variabile, <span class="math notranslate nohighlight">\(Z\)</span>, formando una struttura <span class="math notranslate nohighlight">\(X \rightarrow Z \leftarrow Y\)</span>. In questo schema, <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span> sono considerate variabili indipendenti, il che significa che non esiste una relazione causale diretta o un’influenza reciproca evidente tra di loro. Nonostante <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span> confluiscano su <span class="math notranslate nohighlight">\(Z\)</span>, non si può dedurre l’esistenza di un legame causale diretto tra <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span> basandosi esclusivamente sulla loro comune influenza su <span class="math notranslate nohighlight">\(Z\)</span>.</p></li>
</ol>
<p>Un concetto chiave da comprendere è che, sebbene <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span> abbiano un impatto su <span class="math notranslate nohighlight">\(Z\)</span>, ciò non implica automaticamente una relazione causale tra <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>. Tuttavia, analizzando specificamente i casi in cui <span class="math notranslate nohighlight">\(Z\)</span> manifesta determinate caratteristiche, si potrebbe incorrere erroneamente in ciò che è conosciuto come il <em>bias del collider</em>. Questo tipo di bias si verifica quando la selezione di casi basata su <span class="math notranslate nohighlight">\(Z\)</span> introduce un’associazione artificiale tra <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>, che non riflette le relazioni presenti nell’intera popolazione.</p>
<p>Per illustrare questo fenomeno con un esempio pratico, consideriamo il talento musicale (<span class="math notranslate nohighlight">\(X\)</span>), il supporto familiare (<span class="math notranslate nohighlight">\(Y\)</span>), e il successo in una carriera musicale (<span class="math notranslate nohighlight">\(Z\)</span>). Il talento e il supporto familiare possono influenzare positivamente il successo musicale, ma non necessariamente implica che esista una relazione diretta tra il talento di una persona e il supporto familiare che riceve. Tuttavia, se ci concentriamo esclusivamente sulle persone che hanno raggiunto il successo musicale (<span class="math notranslate nohighlight">\(Z\)</span>), potremmo erroneamente percepire un’associazione tra talento e supporto familiare, un’associazione che potrebbe non essere presente o essere significativamente diversa nell’intera popolazione, che include individui talentuosi non riusciti a ottenere successo.</p>
<p>La comprensione delle biforcazioni invertite e del bias del collider è essenziale per evitare interpretazioni errate dei dati e conclusioni causali fuorvianti. Questo è particolarmente importante in studi dove variabili potenzialmente collider sono coinvolte, richiedendo un’analisi attenta per identificare e gestire correttamente queste strutture complesse nell’elaborazione delle inferenze causali.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Digraph</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">f</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/777f3bac16aac9a72af51e6f9711cd2eacc7c29460477490474fdd32e0f525b5.svg" src="../_images/777f3bac16aac9a72af51e6f9711cd2eacc7c29460477490474fdd32e0f525b5.svg" /></div>
</div>
<p>La comprensione di queste strutture causali di base è fondamentale per analizzare i percorsi causali più complessi. Esistono principalmente tre tipi di strutture causali di base che determinano le caratteristiche dei percorsi più estesi:</p>
<ol class="arabic simple">
<li><p><strong>Percorsi di Tipo Catena</strong>. Questi percorsi sono formati da una serie di collegamenti causali diretti. Un percorso composto esclusivamente da catene può trasmettere un’associazione causale. Ad esempio, consideriamo il percorso: intelligenza → voti → titolo di studio → reddito. In questo caso, c’è una trasmissione diretta dell’associazione causale lungo la catena. Ogni variabile lungo il percorso può essere vista come un “discendente” delle variabili precedenti e un “antenato” delle variabili successive. In altre parole, la variabile “intelligenza” influenzerebbe i “voti”, che a loro volta influenzano il “titolo di studio”, il quale infine influenzerebbe il “reddito”. Questi percorsi mostrano come un effetto può essere trasmesso attraverso una serie di variabili intermedie.</p></li>
<li><p><strong>Percorsi con Biforcazioni</strong>. Un percorso che contiene anche delle biforcazioni trasmette un’associazione, ma non rappresenta più una relazione causale a causa dell’introduzione di una variabile di confondimento. Per esempio, consideriamo il percorso: titolo di studio ← voti ← intelligenza → reddito. Qui, “intelligenza” è una variabile comune che influenza sia “voti” che “reddito”. In questa struttura, “intelligenza” agisce come una variabile di confondimento, rendendo la relazione tra “voti” e “reddito” meno diretta. Questo perché l’effetto di “voti” su “reddito” potrebbe essere spiegato o influenzato da “intelligenza”.</p></li>
<li><p><strong>Percorsi con Biforcazioni Invertite</strong>. Un percorso che presenta una biforcazione invertita è bloccato e non trasmette alcuna associazione. Questi percorsi includono una struttura dove due variabili indipendenti influenzano una terza. Ad esempio, nel percorso titolo di studio → reddito ← intelligenza → voti, abbiamo una biforcazione invertita al “reddito”. In questo caso, nonostante “titolo di studio” e “voti” influenzino entrambi il “reddito”, non c’è necessariamente una relazione diretta o una correlazione tra “titolo di studio” e “voti”. Questi percorsi sono “bloccati” in termini di trasmissione associativa tra le variabili agli estremi della biforcazione invertita.</p></li>
</ol>
<p>In breve, le tre strutture causali di base determinano le caratteristiche dei percorsi più lunghi. Un percorso costituito esclusivamente da catene può trasmettere un’associazione causale. I percorsi che includono biforcazioni sono in grado di trasmettere un’associazione, ma questa non è causale in quanto è influenzata dalla presenza di variabili confondenti. Infine, i percorsi che contengono biforcazioni invertite sono interrotti e non trasmettono alcuna associazione.</p>
</section>
<section id="irreversibilita-e-aciclicita-nei-dag">
<h2>Irreversibilità e Aciclicità nei DAG<a class="headerlink" href="#irreversibilita-e-aciclicita-nei-dag" title="Permalink to this heading">#</a></h2>
<p>Nei DAG i percorsi ciclici non sono ammessi. Ciò implica che una variabile non può diventare sua stessa antenata, eliminando così la possibilità di un’influenza causale su se stessa. Questa caratteristica garantisce la coerenza e la validità delle analisi causali basate su tali diagrammi. Ad esempio, nel DAG precedente, non si può invertire il percorso da intelligenza a reddito, poiché ciò creerebbe un percorso ciclico (intelligenza → istruzione → reddito → intelligenza).</p>
<p>Questa restrizione può sembrare controintuitiva, specialmente in psicologia dove spesso esistono cicli di feedback. Ad esempio, l’intelligenza può influenzare l’istruzione, ma anche l’istruzione può influenzare l’intelligenza. Tuttavia, tali cicli di feedback possono essere modellati in un DAG considerando l’ordine temporale e aggiungendo nodi per misurazioni ripetute.</p>
<p>Per esempio, un DAG potrebbe rappresentare come l’intelligenza nell’infanzia influenzi l’istruzione, che a sua volta influenza l’intelligenza in età adulta. La risoluzione temporale in un DAG può essere ulteriormente “ingrandita”, con valutazioni annuali, mensili o addirittura giornaliere di molteplici variabili, portando all’aggiunta di sempre più nodi nel DAG. Questo permette di modellare la dinamica temporale e i cambiamenti nelle relazioni causali nel tempo, pur mantenendo la struttura aciclica del grafico.</p>
<p>In sintesi, anche se i DAG sono aciclici e non permettono cicli diretti, possono comunque rappresentare sistemi dinamici e complessi con relazioni causali che cambiano nel tempo, attraverso una rappresentazione più dettagliata e stratificata del tempo e delle variabili.</p>
</section>
<section id="il-confondimento-nei-dati-osservazionali">
<h2>Il Confondimento nei Dati Osservazionali<a class="headerlink" href="#il-confondimento-nei-dati-osservazionali" title="Permalink to this heading">#</a></h2>
<p>La principale sfida nei dati osservazionali riguarda il confondimento. Questo fenomeno si manifesta quando c’è una causa comune o più cause che influenzano sia la variabile indipendente, che rappresenta la potenziale causa di interesse, sia la variabile dipendente, che rappresenta il risultato di interesse. L’influenza concomitante di queste variabili può dar luogo a ciò che spesso viene definito una correlazione spuria, la quale non deve essere confusa con un effetto causale.</p>
<p>Esaminiamo ora una simulazione che chiarisce il concetto di correlazione spuria. Denotiamo con <code class="docutils literal notranslate"><span class="pre">c</span></code> una variabile di confondimento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Nella simulazione, le variabili <code class="docutils literal notranslate"><span class="pre">x</span></code> e <code class="docutils literal notranslate"><span class="pre">y</span></code> sono indipendenti tra di loro dal punto di vista causale, ma entrambe sono influenzate dalla variabile <code class="docutils literal notranslate"><span class="pre">c</span></code>. Come abbiamo visto in precedenza, questa struttura casuale corrisponde ad una “biforcazione” nel DAG.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo ora la correlazione tra <code class="docutils literal notranslate"><span class="pre">a</span></code> e <code class="docutils literal notranslate"><span class="pre">c</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coef</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9478699776586944
</pre></div>
</div>
</div>
</div>
<p>In altre parole, anche se le variabili <code class="docutils literal notranslate"><span class="pre">x</span></code> e <code class="docutils literal notranslate"><span class="pre">y</span></code>  sono causalmente indipendenti, la presenza di una terza variabile <code class="docutils literal notranslate"><span class="pre">c</span></code> (variabile di confondimento) che le influenza entrambe fa sì che <code class="docutils literal notranslate"><span class="pre">x</span></code> e <code class="docutils literal notranslate"><span class="pre">y</span></code> risultino correlate tra di loro. Questo è un esempio di correlazione spuria.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Il codice è tratto da A. Molak (2023) &quot;Causal Inference and Discovery in Python&quot;.</span>

<span class="n">COLORS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="s2">&quot;C2&quot;</span><span class="p">]</span>

<span class="n">variables</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">:</span> <span class="n">c</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">var_1</span><span class="p">,</span> <span class="n">var_2</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([(</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">)]):</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">COLORS</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="s2">&quot;c&quot;</span> <span class="ow">in</span> <span class="p">[</span><span class="n">var_1</span><span class="p">,</span> <span class="n">var_2</span><span class="p">]:</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">COLORS</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">variables</span><span class="p">[</span><span class="n">var_1</span><span class="p">],</span> <span class="n">variables</span><span class="p">[</span><span class="n">var_2</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;$</span><span class="si">{</span><span class="n">var_1</span><span class="si">}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;$</span><span class="si">{</span><span class="n">var_2</span><span class="si">}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Relazioni a coppie tra $x$, $c$ e $y$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_69505/259294172.py:22: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.
  plt.subplots_adjust(wspace=0.3)
</pre></div>
</div>
<img alt="../_images/5c52c51b15afff4d78a2e4fc8b116791b0f8683b2d0afa4bec45addbe727181f.png" src="../_images/5c52c51b15afff4d78a2e4fc8b116791b0f8683b2d0afa4bec45addbe727181f.png" />
</div>
</div>
<p>In conclusione, quando osserviamo l’associazione tra due variabili, <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>, una tale associazione potrebbe non essere una conseguenza della diretta relazione causale tra <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span>, ma piuttosto un effetto di una terza variabile, in questo caso <span class="math notranslate nohighlight">\(C\)</span>, che è una “causa comune” per entrambe.</p>
</section>
<section id="uso-dei-dag-per-identificare-il-confondimento">
<h2>Uso dei DAG per Identificare il Confondimento<a class="headerlink" href="#uso-dei-dag-per-identificare-il-confondimento" title="Permalink to this heading">#</a></h2>
<p>I DAG possono essere utilizzati per identificare il confondimento, ossia per eliminare le associazioni spurie e assicurare l’isolamento dell’effetto causale genuino. Tuttavia, il vincolo per ottenere questo risultato è difficilmente soddisfacibile in situazioni reali, poiché richiede che il DAG contenga tutte le informazioni rilevanti relative all’effetto causale di interesse. Di conseguenza, nella pratica, i DAG non vengono impiegati principalmente per garantire l’isolamento dell’effetto causale privo di confondimenti, ma piuttosto come uno strumento per formulare e testare ipotesi sulla causalità.</p>
<p>Ad esempio, è possibile estendere il DAG mostrato nella figura precedente aggiungendo variabili supplementari che possono influenzare il livello di istruzione o altre variabili. Tuttavia, non tutte queste estensioni potrebbero risultare rilevanti se l’obiettivo è esaminare la relazione causale tra il livello di istruzione e il reddito. Per illustrare, una variabile che ha un impatto sul livello di istruzione ma non ha un effetto causale su altre variabili nel DAG non dovrebbe essere inclusa.</p>
<p>Per costruire un DAG causale completo che conduca a conclusioni causali valide, è fondamentale incorporare tutte le cause comuni di ciascuna coppia di variabili già presenti nel DAG. Ciò comporta l’inclusione di qualsiasi variabile che influenzi direttamente o indirettamente almeno due variabili nel DAG.</p>
<section id="identificazione-e-blocco-dei-percorsi-retrostanti">
<h3>Identificazione e Blocco dei Percorsi Retrostanti<a class="headerlink" href="#identificazione-e-blocco-dei-percorsi-retrostanti" title="Permalink to this heading">#</a></h3>
<p>In un DAG, i percorsi retrostanti, comunemente noti come “back-door”, rappresentano connessioni tra variabili che possono introdurre distorsioni nelle analisi causali. Un percorso retrostante ha origine da una variabile che influenza un’altra variabile (la variabile indipendente) e prosegue fino a collegarsi alla variabile di interesse (la variabile dipendente). Tali percorsi possono suggerire un’associazione tra variabili che non è effettivamente causale, ma piuttosto è il risultato di un fattore comune che influisce su entrambe le variabili.</p>
<p>Per chiarire questo concetto, consideriamo il DAG esaminato in precedenza che descrive la relazione tra il livello di istruzione e il reddito. In questo DAG, emergono due percorsi retrostanti:</p>
<ol class="arabic simple">
<li><p>Livello di Istruzione ← Voti Scolastici ← Intelligenza → Reddito.</p></li>
<li><p>Livello di Istruzione ← Intelligenza → Reddito.</p></li>
</ol>
<p>In entrambi questi casi, la variabile “Intelligenza” svolge il ruolo di intermediario tra il livello di istruzione e il reddito. Ciò implica che qualsiasi associazione osservata tra il livello di istruzione e il reddito potrebbe non essere completamente spiegata da una relazione causale diretta, ma potrebbe essere influenzata dalla presenza di un terzo fattore, ovvero l’intelligenza.</p>
<p>Questi percorsi sono considerati “aperti” poiché non contengono strutture che blocchino la correlazione spuria (ad esempio, biforcazioni invertite, che sono configurazioni che impediscono la trasmissione di associazioni non causali). La presenza di tali percorsi aperti può portare a interpretazioni errate della relazione tra il livello di istruzione e il reddito.</p>
<p>Per evitare conclusioni inaccurate, è fondamentale “bloccare” questi percorsi. Bloccare un percorso significa “controllare” le variabili in modo da eliminare l’influenza delle associazioni non causali. Nel nostro esempio, ciò può essere ottenuto controllando la variabile “Intelligenza” nelle analisi, garantendo così che le associazioni osservate tra il livello di istruzione e il reddito non siano influenzate in modo improprio da questa variabile comune.</p>
</section>
<section id="controllo-statistico-per-bloccare-i-percorsi-retrostanti">
<h3>Controllo Statistico per Bloccare i Percorsi Retrostanti<a class="headerlink" href="#controllo-statistico-per-bloccare-i-percorsi-retrostanti" title="Permalink to this heading">#</a></h3>
<section id="obiettivo-del-controllo-di-terze-variabili">
<h4>Obiettivo del Controllo di Terze Variabili<a class="headerlink" href="#obiettivo-del-controllo-di-terze-variabili" title="Permalink to this heading">#</a></h4>
<p>La procedura di controllo delle variabili terze ha l’obiettivo di interrompere i percorsi retrostanti aperti tra le variabili coinvolte. Se è possibile bloccare tutti i percorsi retrostanti tra le variabili indipendenti e quelle dipendenti, è quindi possibile identificare l’effetto causale che connette queste variabili, anche quando i dati sono di natura puramente osservazionale. Questo principio segue il criterio del “back-door” proposto da <span id="id13">Pearl [<a class="reference internal" href="../references/bibliography.html#id3" title="Judea Pearl. Causality. Cambridge University Press, 2009.">Pea09</a>]</span>. L’identificazione di un tale effetto causale è valida, a condizione che il DAG rifletta accuratamente la rete causale sottostante.</p>
<p>Tuttavia, l’assunzione di aver catturato correttamente la rete causale e di aver bloccato con successo tutti i percorsi retrostanti spesso si rivela molto impegnativa, poiché implica che non siano state trascurate variabili rilevanti all’interno del grafo causale. La plausibilità di questa assunzione deve essere valutata attentamente caso per caso, poiché può variare a seconda del contesto e della complessità della rete causale in esame.</p>
</section>
<section id="come-bloccare-un-percorso-retrostante">
<h4>Come Bloccare un Percorso Retrostante<a class="headerlink" href="#come-bloccare-un-percorso-retrostante" title="Permalink to this heading">#</a></h4>
<p>Un percorso retrostante può essere interrotto mediante il ‘taglio’ della trasmissione dell’associazione in qualsiasi punto del percorso, mediante il controllo statistico di un nodo. Per esempio, considerando il percorso non causale ‘istruzione ← voti ← intelligenza → reddito’, potremmo effettuare un controllo statistico sui ‘voti’. Questa azione bloccherebbe efficacemente questo percorso retrostante, impedendo la trasmissione di un’associazione non causale. Tuttavia, potremmo anche eseguire un controllo statistico su ‘intelligenza’, il che interromperebbe sia questo percorso che il secondo percorso retrostante, ‘istruzione ← intelligenza → reddito’.</p>
<p>Se il DAG nella figura riflette accuratamente la rete causale sottostante, controllare la variabile ‘intelligenza’ sarebbe sufficiente per identificare l’effetto causale dell’istruzione sul reddito poiché bloccherebbe tutti i percorsi retrostanti. Tuttavia, ripetiamo, è fondamentale che il DAG sia una rappresentazione fedele della realtà, poiché il successo del controllo dipende dalla sua corretta rappresentazione della struttura causale delle variabili coinvolte.</p>
</section>
<section id="pratiche-per-il-controllo-delle-variabili-in-un-dag">
<h4>Pratiche per il Controllo delle Variabili in un DAG<a class="headerlink" href="#pratiche-per-il-controllo-delle-variabili-in-un-dag" title="Permalink to this heading">#</a></h4>
<p>Esistono diverse tecniche per gestire le variabili all’interno di un DAG per neutralizzare i percorsi di confondimento. Sebbene queste tecniche possano variare nella loro applicazione pratica, necessitando di diversi approcci statistici, tutte mirano all’obiettivo comune di bloccare i percorsi che potrebbero introdurre distorsioni nelle inferenze causali. Un prerequisito per poter applicare tali tecniche, è che le variabili che si intende controllare siano state effettivamente misurate e siano disponibili per l’analisi. Questo prerequisito, ossia la capacità di identificare e misurare accuratamente le variabili di confondimento, non è sempre facilmente realizzabile nella pratica di ricerca.</p>
<p>Inoltre, affinché il controllo di queste variabili sia efficace, è essenziale che la loro misurazione sia accurata e priva di distorsioni. Il successo del controllo statistico dipende fortemente dalla qualità dei dati raccolti sulla variabile di interesse. Misurazioni inaccurate o bias nelle variabili di confondimento possono compromettere significativamente la validità delle analisi statistiche e, di conseguenza, delle conclusioni tratte dallo studio. Pertanto, assicurare la precisione nella raccolta dei dati e l’integrità delle misurazioni delle variabili confondenti è un passo critico per garantire l’affidabilità delle inferenze causali derivate dall’analisi dei DAG.</p>
</section>
</section>
<section id="come-controllare-una-variabile-nei-dati-osservazionali">
<h3>Come Controllare una Variabile nei Dati Osservazionali<a class="headerlink" href="#come-controllare-una-variabile-nei-dati-osservazionali" title="Permalink to this heading">#</a></h3>
<section id="analisi-stratificata">
<h4>Analisi Stratificata<a class="headerlink" href="#analisi-stratificata" title="Permalink to this heading">#</a></h4>
<p>In determinate circostanze, è praticabile suddividere il campione di studio per gestire le variabili confondenti attraverso un processo noto come “condizionare su”. Ad esempio, per controllare l’effetto di una variabile categorica come il sesso biologico, si può procedere dividendo il campione in gruppi omogenei basati sul sesso. Analizzando separatamente ciascun gruppo e poi aggregando le stime risultanti in un’unica stima complessiva, si minimizza il rischio che gli effetti attribuibili al sesso biologico confondano i risultati osservati. Questa tecnica, conosciuta come analisi stratificata, è apprezzata per la sua chiarezza e la sua capacità di isolare gli effetti di specifiche variabili di confondimento.</p>
<p>Tuttavia, l’applicazione dell’analisi stratificata può incontrare limitazioni quando la variabile di controllo presenta molti livelli, è di natura continua, o quando è necessario tenere in considerazione multiple variabili confondenti e le loro potenziali interazioni. In tali situazioni, “condizionare su” variabili confondenti richiede strategie più complesse, come l’utilizzo di modelli di regressione multivariata, che permettono di controllare simultaneamente per diverse variabili confondenti, mantenendo la fattibilità dell’analisi anche in presenza di un elevato grado di complessità.</p>
</section>
<section id="includere-variabili-terze-nei-modelli-di-regressione">
<h4>Includere Variabili Terze nei Modelli di Regressione<a class="headerlink" href="#includere-variabili-terze-nei-modelli-di-regressione" title="Permalink to this heading">#</a></h4>
<p>Nella ricerca psicologica, l’adozione di modelli di regressione multipla rappresenta un metodo diffuso per esercitare un controllo statistico. Questi modelli consentono di analizzare l’effetto della variabile dipendente non solo in relazione alla variabile indipendente di interesse ma anche tenendo conto di covariate aggiuntive. L’obiettivo è di “controllare” l’influenza di queste covariate per isolare più chiaramente l’effetto della variabile indipendente principale e, quando possibile, interrompere i percorsi di confondimento.</p>
<p>Tuttavia, un limite di questa prassi è l’assunzione frequente di relazioni lineari tra le variabili senza una giustificazione dettagliata. Tale presupposizione può portare a un controllo inadeguato delle covariate. Ad esempio, se l’effetto delle covariate sulla variabile dipendente e su quella indipendente non è lineare ma segue piuttosto una relazione quadratica, un semplice modello lineare potrebbe fallire nel neutralizzare completamente l’effetto delle covariate. Per affrontare adeguatamente questa sfida, sarebbe opportuno includere nel modello sia il termine lineare della covariata sia il suo termine al quadrato, per catturare accuratamente l’influenza non lineare.</p>
<p>Inoltre, la presenza di effetti interattivi tra le covariate e la variabile indipendente principale richiede un’attenzione particolare. Ignorare le potenziali interazioni può portare a stime degli effetti che non riflettono accuratamente la realtà. Pertanto, quando necessario, è fondamentale incorporare questi termini di interazione nel modello di regressione per assicurare che le stime degli effetti siano precise e rappresentative della complessità delle relazioni tra le variabili.</p>
</section>
</section>
<section id="il-matching-come-metodo-di-controllo-statistico">
<h3>Il Matching come Metodo di Controllo Statistico<a class="headerlink" href="#il-matching-come-metodo-di-controllo-statistico" title="Permalink to this heading">#</a></h3>
<section id="uso-del-matching-per-controllare-variabili-multiple">
<h4>Uso del Matching per Controllare Variabili Multiple<a class="headerlink" href="#uso-del-matching-per-controllare-variabili-multiple" title="Permalink to this heading">#</a></h4>
<p>In diverse circostanze di ricerca, emerge la necessità di considerare simultaneamente più variabili di confondimento, anziché limitarsi a una sola. Questo compito si complica ulteriormente quando si mira a controllare queste variabili senza presupporre una specifica relazione funzionale tra di esse e l’outcome di interesse, adottando quindi un approccio completamente non parametrico che evita di fare ipotesi predefinite sugli effetti delle variabili.</p>
<p>Il matching rappresenta una strategia efficace per gestire queste situazioni complesse, permettendo di appaiare i soggetti in modo da neutralizzare l’influenza delle variabili di confondimento. Tra i diversi metodi di matching, il matching basato sul punteggio di propensione (o propensity score matching) gode di grande popolarità nelle scienze sociali.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Il processo di propensity score matching inizia con il calcolo del propensity score, che rappresenta la probabilità che un individuo sia stato assegnato al gruppo di trattamento, basandosi sulle sue caratteristiche di base. Questo valore può essere ottenuto mediante tecniche di regressione logistica o altri approcci statistici simili.</p>
<p>Successivamente, si procede con la creazione di un gruppo di controllo attraverso il matching dei propensity scores. Si cercano individui nel gruppo di controllo che abbiano propensity scores simili a quelli nel gruppo di trattamento. In altre parole, si accoppiano individui con probabilità simili di essere assegnati al gruppo di trattamento, basandosi sulle loro caratteristiche di base.</p>
<p>Questo processo di matching crea un gruppo di controllo “equivalente” al gruppo di trattamento in termini di caratteristiche di base, riducendo al minimo il confondimento. Una volta completato il matching, è possibile condurre un’analisi comparativa tra i due gruppi, tenendo conto delle caratteristiche di base ora bilanciate grazie al propensity score matching. Questo consente di stimare in modo più accurato l’effetto causale del trattamento o dell’intervento di interesse.</p>
<p>Un esempio concreto di propensity score matching è la ricerca di Jackson et al. (2012) per studiare gli effetti dell’addestramento militare rispetto al servizio civile sulla personalità. Utilizzando le covariate come l’età, il livello di istruzione e il background socio-economico, è stato calcolato il propensity score di ciascun individuo, ovvero la probabilità di scegliere l’addestramento militare piuttosto che il servizio civile. Successivamente, sono stati creati gruppi appaiati di individui che avevano scelto il servizio militare e individui che avevano scelto il servizio civile che avevano propensity scores simili. Questo processo ha garantito che i due gruppi fossero comparabili rispetto alle variabili di controllo, consentendo una stima più accurata degli effetti dell’addestramento militare sulla personalità, mentre bloccava potenziali percorsi retrostanti confondenti.</p>
</div>
</section>
<section id="considerazioni-sul-matching">
<h4>Considerazioni sul Matching<a class="headerlink" href="#considerazioni-sul-matching" title="Permalink to this heading">#</a></h4>
<p>Il matching, e in particolare il matching basato sui punteggi di propensione, mira a raggiungere gli stessi obiettivi dei tradizionali metodi di controllo statistico che includono variabili di confondimento nelle analisi. Questa tecnica può offrire vantaggi nell’affinare la stima degli effetti causalità in determinate situazioni. Tuttavia, la sua efficacia non altera i principi fondamentali dell’inferenza causale. In altre parole, l’accuratezza nella determinazione degli effetti causali tramite i punteggi di propensione è limitata dalle stesse considerazioni che riguardano altri approcci di controllo statistico. Se una variabile di confondimento rilevante viene omessa o se vengono erroneamente incluse variabili irrilevanti, l’uso dei punteggi di propensione, come ogni altro metodo statistico, può non riuscire a identificare correttamente la natura causale dell’effetto in esame.</p>
<p>Un aspetto critico nell’impiego dei punteggi di propensione è l’accuratezza del modello statistico utilizzato per generarli. Questo modello deve riflettere fedelmente le relazioni tra le caratteristiche osservate dei partecipanti e la loro probabilità di sperimentare la condizione o il trattamento di interesse. La validità dell’approccio basato sui punteggi di propensione dipende strettamente dalla corretta specificazione di questo modello. Pertanto, è fondamentale assicurarsi che il modello catturi con precisione come le variabili di background influenzano la propensione a ricevere il trattamento, per garantire che i punteggi di propensione siano validi e che il matching basato su di essi possa fornire stime causali affidabili.</p>
</section>
</section>
<section id="errore-di-misurazione-nelle-variabili-di-confondimento-e-il-suo-impatto">
<h3>Errore di Misurazione nelle Variabili di Confondimento e il suo Impatto<a class="headerlink" href="#errore-di-misurazione-nelle-variabili-di-confondimento-e-il-suo-impatto" title="Permalink to this heading">#</a></h3>
<section id="influenza-dell-errore-di-misurazione">
<h4>Influenza dell’Errore di Misurazione<a class="headerlink" href="#influenza-dell-errore-di-misurazione" title="Permalink to this heading">#</a></h4>
<p>L’errore di misurazione può influenzare tutti i metodi di controllo statistico. Ad esempio, considerando l’intelligenza come variabile di confondimento nelle due figure precedenti, è importante notare che l’intelligenza non può essere misurata in modo perfettamente accurato. Di conseguenza, l’aggiustamento statistico per l’intelligenza potrebbe non essere in grado di eliminare completamente la sua influenza confondente. Questo potrebbe portare a una sovrastima erronea dell’effetto dell’istruzione sul reddito a causa della persistenza di un confondimento residuo. Va notato che questo problema si applica anche al matching basato sui punteggi di propensione se i punteggi stessi sono influenzati da errori di misurazione nelle variabili utilizzate per calcolarli.</p>
</section>
</section>
<section id="il-dilemma-del-controllo-statistico-eccessivo">
<h3>Il Dilemma del Controllo Statistico Eccessivo<a class="headerlink" href="#il-dilemma-del-controllo-statistico-eccessivo" title="Permalink to this heading">#</a></h3>
<section id="pratica-comune-e-i-suoi-limiti">
<h4>Pratica Comune e i suoi Limiti<a class="headerlink" href="#pratica-comune-e-i-suoi-limiti" title="Permalink to this heading">#</a></h4>
<p>In alcuni campi di ricerca, è diventata una pratica comune includere quante più covariate possibili, tanto che alcuni autori affermano di avere maggiore fiducia nei loro risultati perché il loro studio “utilizza più variabili di controllo rispetto a studi precedenti” (Tiefenbach &amp; Kohlbacher, 2015, p. 85). Mentre è vero che non controllare per confondenti importanti può minare le conclusioni di uno studio, non è corretto affermare che semplicemente aggiungere più covariate migliorerà sempre la stima di un effetto causale. Questo approccio è chiamato da McEleath “causal salad”:</p>
<blockquote>
<div><p>When I talk about “causal salad”, this is what I mean: no consideration of how the covariates relate to one another or the treatment.</p>
</div></blockquote>
<p>La semplice inclusione di un gran numero di covariate può comportare problemi, come l’emergere di effetti spuri. Pertanto, la selezione o l’inclusione delle covariate dovrebbe essere basata su una comprensione della struttura causale sottostante, piuttosto che su un approccio di “più è meglio”.</p>
</section>
<section id="tipi-di-variabili-da-non-controllare">
<h4>Tipi di Variabili da Non Controllare<a class="headerlink" href="#tipi-di-variabili-da-non-controllare" title="Permalink to this heading">#</a></h4>
<p>È importante distinguere tra due tipi di variabili che dovrebbero essere trattate con cautela quando si controlla il confondimento: i “collider” e i “mediatori”. A differenza dei confondenti, che influenzano causalmente la variabile indipendente di interesse, i “collider” e i “mediatori” sono influenzati causalmente dalla variabile indipendente stessa. Questi sono spesso chiamati “variabili post-trattamento” poiché rappresentano fenomeni che si verificano dopo l’applicazione del trattamento o dell’intervento.</p>
<p>Una regola fondamentale che i ricercatori dovrebbero seguire è quella di <strong>evitare di controllare o aggiungere tali variabili post-trattamento come covariate nei modelli di analisi</strong> (Rosenbaum, 1984; Rubin, 1974). L’inclusione di collider o mediatori come covariate può portare a risultati distorti e interpretazioni errate. Pertanto, è cruciale essere consapevoli di queste distinzioni e delle implicazioni causali quando si progetta e si analizza uno studio di ricerca.</p>
</section>
<section id="analisi-dei-rischi-nel-controllo-di-collider-e-mediatori">
<h4>Analisi dei Rischi nel Controllo di Collider e Mediatori<a class="headerlink" href="#analisi-dei-rischi-nel-controllo-di-collider-e-mediatori" title="Permalink to this heading">#</a></h4>
<p>Per approfondire la comprensione di questi concetti, ci avvaleremo di una simulazione numerica. Prima di procedere con l’esempio pratico, è utile ricordare la definizione di “collider”. Un collider è una variabile che risulta influenzata da due o più variabili all’interno di un modello. Includere un collider come covariata in un’analisi può involontariamente aprire nuovi percorsi indiretti, detti percorsi “back-door”, che introducono associazioni non reali tra le variabili in esame. Questo fenomeno può portare a conclusioni ingannevoli.</p>
<p>Al contrario, i “mediatori” sono variabili che fungono da ponte nel processo causale tra una variabile indipendente e una dipendente. Il controllo per un mediatore, includendolo nell’analisi, potrebbe ridurre o eliminare parte dell’effetto causale di interesse, in quanto i mediatori sono integrali alla catena causale che si intende indagare.</p>
<p>Per illustrare questi concetti attraverso un esempio pratico, consideriamo la relazione tra intelligenza (<span class="math notranslate nohighlight">\(X\)</span>) e creatività (<span class="math notranslate nohighlight">\(Y\)</span>) in un campione di studenti. Ipotizziamo che, nella popolazione generale degli studenti, non esista una relazione diretta tra intelligenza e creatività.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span> <span class="c1"># Per la riproducibilità dell&#39;esempio</span>

<span class="c1"># Numero di studenti</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Generazione di dati simulati</span>
<span class="n">intelligenza</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="c1"># Intelligenza: distribuzione normale</span>
<span class="n">creativita</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>  <span class="c1"># Creatività: distribuzione normale</span>

<span class="c1"># Non c&#39;è correlazione reale tra intelligenza e creatività</span>
<span class="n">correlazione_generale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">intelligenza</span><span class="p">,</span> <span class="n">creativita</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Correlazione nella popolazione generale: </span><span class="si">{</span><span class="n">correlazione_generale</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlazione nella popolazione generale: -0.03128347374134393
</pre></div>
</div>
</div>
</div>
<p>Proseguendo con l’esempio, immaginiamo ora che l’ammissione degli studenti a un rinomato programma artistico (<span class="math notranslate nohighlight">\(Z\)</span>) si basi su una combinazione delle loro capacità intellettuali e creative. In questo scenario, si presentano tre variabili principali:</p>
<ul class="simple">
<li><p><strong>Intelligenza (<span class="math notranslate nohighlight">\(X\)</span>)</strong>: Rappresenta le capacità cognitive degli studenti.</p></li>
<li><p><strong>Creatività (<span class="math notranslate nohighlight">\(Y\)</span>)</strong>: Indica le capacità creative degli studenti.</p></li>
<li><p><strong>Selezione nel programma artistico (<span class="math notranslate nohighlight">\(Z\)</span>)</strong>: Questa variabile funge da collider, poiché la selezione degli studenti è influenzata sia dall’intelligenza che dalla creatività.</p></li>
</ul>
<p>Il programma artistico tende a selezionare studenti che eccellono sia in intelligenza (<span class="math notranslate nohighlight">\(X\)</span>) che in creatività (<span class="math notranslate nohighlight">\(Y\)</span>), implicando che coloro che mostrano livelli elevati in entrambe queste dimensioni sono più propensi a essere ammessi (<span class="math notranslate nohighlight">\(Z\)</span>).</p>
<p>Se ci concentriamo esclusivamente sugli studenti che sono stati selezionati per il programma (<span class="math notranslate nohighlight">\(Z\)</span>), potremmo trarre erroneamente la conclusione che intelligenza e creatività siano inversamente correlate all’interno di questo gruppo. Ciò avviene perché, tra gli studenti selezionati, quelli con livelli eccezionalmente alti di intelligenza potrebbero non mostrare necessariamente i livelli più alti di creatività e viceversa, data la natura della selezione che valuta combinatamente le due caratteristiche.</p>
<p>In sostanza, la selezione per il programma (<span class="math notranslate nohighlight">\(Z\)</span>) introduce un collider nel nostro studio. Se includiamo questa variabile nel nostro modello di analisi, rischiamo di rilevare una relazione apparentemente negativa tra intelligenza e creatività che non riflette la realtà della popolazione generale degli studenti. L’associazione negativa osservata tra queste due variabili sarebbe quindi il risultato della modalità di selezione nel programma, non di una legittima interazione causale tra intelligenza e creatività.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creazione di un collider</span>
<span class="n">selezione_programma</span> <span class="o">=</span> <span class="p">(</span><span class="n">intelligenza</span> <span class="o">+</span> <span class="n">creativita</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">180</span> <span class="c1"># Collider</span>

<span class="c1"># Creazione di un DataFrame</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Intelligenza&#39;</span><span class="p">:</span> <span class="n">intelligenza</span><span class="p">,</span>
    <span class="s1">&#39;Creatività&#39;</span><span class="p">:</span> <span class="n">creativita</span><span class="p">,</span>
    <span class="s1">&#39;SelezioneProgramma&#39;</span><span class="p">:</span> <span class="n">selezione_programma</span>
<span class="p">})</span>

<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Intelligenza</th>
      <th>Creatività</th>
      <th>SelezioneProgramma</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>83.715541</td>
      <td>88.767588</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>114.960182</td>
      <td>108.513921</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>104.244677</td>
      <td>110.772258</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>77.405579</td>
      <td>85.009289</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>91.320996</td>
      <td>107.123475</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcolo della correlazione nella popolazione generale</span>
<span class="n">cor_gen</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Intelligenza&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Creatività&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Correlazione nella popolazione generale: </span><span class="si">{</span><span class="n">cor_gen</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Calcolo della correlazione nel gruppo selezionato dal programma (collider)</span>
<span class="n">data_selezionati</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;SelezioneProgramma&#39;</span><span class="p">]]</span>
<span class="n">cor_selezionati</span> <span class="o">=</span> <span class="n">data_selezionati</span><span class="p">[</span><span class="s1">&#39;Intelligenza&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">data_selezionati</span><span class="p">[</span><span class="s1">&#39;Creatività&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Correlazione nel gruppo selezionato: </span><span class="si">{</span><span class="n">cor_selezionati</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlazione nella popolazione generale: -0.03128347374134393
Correlazione nel gruppo selezionato: -0.2557322309536501
</pre></div>
</div>
</div>
</div>
<p>La chiave qui è che controllare o condizionare l’analisi su un collider (in questo caso, la selezione nel programma) può introdurre un bias, creando associazioni o correlazioni che non sono reali. Questo è un esempio classico di come il controllo di un collider in un’analisi statistica possa portare a conclusioni errate.</p>
</section>
</section>
<section id="il-bias-del-collider-nelle-procedure-di-campionamento">
<h3>Il Bias del Collider nelle Procedure di Campionamento<a class="headerlink" href="#il-bias-del-collider-nelle-procedure-di-campionamento" title="Permalink to this heading">#</a></h3>
<p>Il bias del collider può emergere non solo dall’uso inappropriato di covariati, ma anche da specifiche procedure di campionamento, un fenomeno noto come bias di selezione endogena. Elwert e Winship (2014) hanno esaminato diverse modalità in cui questo bias si manifesta, con particolare attenzione ai contesti rilevanti in psicologia.</p>
<section id="bias-di-non-risposta">
<h4>Bias di Non Risposta<a class="headerlink" href="#bias-di-non-risposta" title="Permalink to this heading">#</a></h4>
<p>Questo tipo di bias si verifica quando le variabili di interesse influenzano la probabilità di completamento di un’azione, come il completamento di un questionario. Ad esempio, in uno studio sulla relazione tra grinta e intelligenza, potremmo trovare che sia la grinta che l’intelligenza influenzano la probabilità di completare un questionario impegnativo. Se analizziamo solo i questionari completati, introduciamo un collider: il completamento del questionario stesso. Questo può portare a rilevare erroneamente un’associazione negativa tra grinta e intelligenza, dato che individui con alta grinta ma bassa intelligenza, o viceversa, potrebbero essere sovrarappresentati tra quelli che completano il questionario.</p>
</section>
<section id="bias-di-attrito">
<h4>Bias di Attrito<a class="headerlink" href="#bias-di-attrito" title="Permalink to this heading">#</a></h4>
<p>Questo bias si manifesta in studi longitudinali quando si analizzano solo i dati dei partecipanti che non hanno abbandonato lo studio. Ad esempio, in uno studio sugli effetti dei problemi di salute sulla soddisfazione lavorativa, l’abbandono dello studio potrebbe essere influenzato sia dalla salute che dalle condizioni di lavoro. Se le persone con problemi di salute tendono a rimanere nello studio se hanno un lavoro meno stressante, mentre quelle in ambienti di lavoro stressanti rimangono se godono di buona salute, ciò crea un legame artificiale tra salute e ambiente di lavoro stressante nel campione residuo. L’analisi di questo gruppo selezionato potrebbe portare a sottostimare l’effetto dei problemi di salute sulla soddisfazione lavorativa.</p>
</section>
</section>
<section id="problemi-correlati-dati-mancanti-e-rappresentativita-nei-dati-osservazionali">
<h3>Problemi Correlati: Dati Mancanti e Rappresentatività nei Dati Osservazionali<a class="headerlink" href="#problemi-correlati-dati-mancanti-e-rappresentativita-nei-dati-osservazionali" title="Permalink to this heading">#</a></h3>
<section id="bias-di-selezione-endogena-e-dati-mancanti">
<h4>Bias di Selezione Endogena e Dati Mancanti<a class="headerlink" href="#bias-di-selezione-endogena-e-dati-mancanti" title="Permalink to this heading">#</a></h4>
<p>Il bias di selezione endogena è strettamente legato ai problemi di dati mancanti. Il bias di non risposta e di attrito, che portano a dati mancanti, devono essere considerati attentamente per trarre conclusioni causali valide da dati osservazionali.</p>
</section>
<section id="problema-della-non-rappresentativita-dei-campioni">
<h4>Problema della Non Rappresentatività dei Campioni<a class="headerlink" href="#problema-della-non-rappresentativita-dei-campioni" title="Permalink to this heading">#</a></h4>
<p>La non rappresentatività dei campioni è un altro problema legato al bias di selezione endogena. Se, ad esempio, uno studio si concentra solo su studenti universitari, ciò introduce un bias di selezione tra tutte le variabili che influenzano la probabilità di diventare uno studente universitario, come lo status socio-economico e le capacità cognitive.</p>
</section>
</section>
<section id="il-bias-da-sovracontrollo-la-rimozione-dei-processi-di-interesse">
<h3>Il Bias da Sovracontrollo: La Rimozione dei Processi di Interesse<a class="headerlink" href="#il-bias-da-sovracontrollo-la-rimozione-dei-processi-di-interesse" title="Permalink to this heading">#</a></h3>
<section id="sovracontrollo-e-bias">
<h4>Sovracontrollo e Bias<a class="headerlink" href="#sovracontrollo-e-bias" title="Permalink to this heading">#</a></h4>
<p>Se l’analisi dei collider può portare alla comparsa di associazioni spurie, è altrettanto importante riconoscere che il controllo dei mediatori può contribuire all’annullamento di associazioni che sono effettivamente presenti. Si può dire che si verifica un “bias da sovracontrollo” quando il controllo statistico delle variabili mediatrici elimina i processi di interesse che collegano le variabili tra loro.</p>
<p>Per chiarire questo concetto, prendiamo in considerazione uno scenario in cui vogliamo indagare sull’effetto dell’istruzione sull’intelligenza in età adulta. In questo contesto, l’istruzione può influenzare diversi aspetti dello sviluppo intellettuale di un individuo, sia in modo diretto che attraverso variabili mediatrici, quali l’accesso a risorse educative, il contesto socio-economico o la motivazione personale.</p>
<p>Se nel nostro modello statistico applichiamo un eccessivo controllo su tutte queste variabili mediatrici, potremmo erroneamente concludere che l’istruzione non ha un impatto significativo sull’intelligenza in età adulta. Questo accade perché, attraverso il controllo delle variabili mediatrici, rimuoviamo i percorsi attraverso cui l’istruzione effettivamente influenza l’intelligenza. Di conseguenza, l’effetto diretto dell’istruzione potrebbe apparire attenuato o persino assente.</p>
</section>
</section>
<section id="la-complessita-delle-inferenze-causali-sui-dati-correlazionali">
<h3>La Complessità delle Inferenze Causali sui Dati Correlazionali<a class="headerlink" href="#la-complessita-delle-inferenze-causali-sui-dati-correlazionali" title="Permalink to this heading">#</a></h3>
<p>La sfida di trarre inferenze causali da dati osservazionali è notevolmente complicata dalla necessità di identificare e controllare adeguatamente i fattori confondenti. Questo processo richiede un’attenta considerazione dei potenziali problemi, come il confondimento non lineare e gli errori di misurazione. Prima di raccogliere i dati, è fondamentale valutare le possibili variabili influenti per garantire che tutte le variabili rilevanti siano misurate. In questo contesto, è anche cruciale considerare quali variabili non dovrebbero essere controllate, ad esempio i collider e i mediatori.</p>
<p>La fase di pianificazione della raccolta dati assume un ruolo critico. I ricercatori devono anticipare come il processo di reclutamento del campione possa introdurre un bias di selezione endogena, compromettendo così la validità delle conclusioni. Frequentemente, i ricercatori si trovano di fronte a dati privi di misure affidabili dei confondenti chiave, a causa di variabili non considerate in precedenza o perché i dati sono stati raccolti da fonti terze. In questi casi, un’analisi dettagliata della rete causale sottostante può portare alla conclusione che i dati disponibili non sono sufficienti per supportare affermazioni causali. È anche importante riconoscere che, soprattutto nel campo della psicologia, i grafici causali tendono a essere molto più complessi di quanto è stato illustrato nei presenti esampi didattici.</p>
<p>Le conclusioni causali più affidabili emergono da ciò che è noto come “evidenze convergenti”, ossia risultati che sono stati replicati attraverso l’uso di metodologie di ricerca diverse. Sebbene gli esperimenti controllati randomizzati offrano un alto grado di fiducia nella validità interna, confermando così l’esistenza di relazioni causa-effetto all’interno dell’ambito dello studio, essi si basano su presupposti specifici che devono essere soddisfatti per estendere la validità di queste relazioni a contesti più ampi o alla realtà quotidiana. Tale necessità evidenzia limitazioni nella validità esterna, ovvero la capacità di generalizzare i risultati al di là delle specifiche condizioni sperimentali.</p>
<p>D’altro canto, l’adozione di una varietà di approcci metodologici, che spaziano dai disegni sperimentali ai rilevamenti osservazionali, arricchisce la comprensione delle dinamiche in esame. Questa pluralità di prospettive non solo incrementa la generalizzabilità e la rilevanza dei risultati ma anche apre la strada alla scoperta di nuovi fenomeni che meritano ulteriori indagini. In sostanza, l’integrazione di risultati derivanti da diverse metodologie di ricerca rafforza la validità esterna delle conclusioni e fornisce una base più solida per l’affermazione di relazioni causali complesse.</p>
</section>
</section>
<section id="considerazioni-conclusive">
<h2>Considerazioni Conclusive<a class="headerlink" href="#considerazioni-conclusive" title="Permalink to this heading">#</a></h2>
<p>Nell’ambito degli studi basati su dati osservazionali, districarsi tra le complesse maglie delle inferenze causali richiede non solo acume analitico ma anche una sensibilità particolare verso vari aspetti critici del processo di ricerca. Dall’identificazione dei fattori confondenti all’analisi accurata dei percorsi causali, passando per il delicato equilibrio tra la gestione di mediatori e collider, fino alla valutazione della robustezza interna ed esterna degli studi, ogni fase porta con sé sfide e opportunità.</p>
<p>Il primo passo verso un’interpretazione corretta dei dati osservazionali consiste nel saper riconoscere e gestire le variabili confondenti. Queste variabili, agendo su entrambe le variabili indipendenti e dipendenti, possono generare correlazioni ingannevoli che mascherano la vera natura delle relazioni in esame.</p>
<p>L’uso dei DAG emerge come uno strumento molto utile in questo territorio incerto, offrendo una rappresentazione visiva dei percorsi causali e fornendo indicazioni preziose su come evitare trappole analitiche quali il sovracontrollo o il controllo inappropriato di variabili post-trattamento.</p>
<p>Quando si tratta di mediatori e collider, il terreno si fa ancora più scivoloso. I mediatori, essendo ponti tra cause ed effetti, necessitano di una gestione oculata per non perdere di vista l’effetto causale che intendiamo esplorare. Allo stesso tempo, è fondamentale resistere alla tentazione di controllare indiscriminatamente i collider, poiché ciò può aprire la porta a correlazioni spurie che distorcono la realtà dei fenomeni studiati.</p>
<p>La questione del bilanciamento tra validità interna ed esterna ci ricorda che, sebbene gli esperimenti randomizzati possano offrire garanzie solide di validità interna, la loro capacità di parlare al mondo esterno allo studio – la validità esterna – non è da dare per scontata. Solo un approccio che valorizza la diversità metodologica, abbracciando tanto gli studi sperimentali quanto quelli osservazionali, può aspirare a rispondere in modo compiuto alle domande di ricerca che ci poniamo.</p>
<p>Per studiare con successo le dinamiche nascoste che regolano le relazioni tra le variabili che studiamo, è essenziale non solo un’attenta valutazione dei dati a disposizione ma anche una profonda riflessione sulle strutture causali in gioco. Integrare diversi approcci di ricerca arricchisce la nostra comprensione e ci avvicina a conclusioni causali solide e generalizzabili.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w -m
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Sat Feb 03 2024

Python implementation: CPython
Python version       : 3.11.7
IPython version      : 8.19.0

Compiler    : Clang 16.0.6 
OS          : Darwin
Release     : 23.3.0
Machine     : x86_64
Processor   : i386
CPU cores   : 8
Architecture: 64bit

arviz     : 0.17.0
scipy     : 1.11.4
graphviz  : 0.20.1
matplotlib: 3.8.2
seaborn   : 0.13.0
numpy     : 1.26.2
pandas    : 2.1.4

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="05_correlation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Le relazioni tra variabili</p>
      </div>
    </a>
    <a class="right-next"
       href="07_crisis.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">La crisi della generalizzabilità</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduzione-alla-ricerca-causale">Introduzione alla Ricerca Causale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#i-disegni-di-ricerca-e-la-causalita">I Disegni di Ricerca e la Causalità</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelli-causali-grafici">Modelli Causali Grafici</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#importanza-delle-assunzioni">Importanza delle Assunzioni</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduzione-ai-dag">Introduzione ai DAG</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caratteristiche-dei-dag">Caratteristiche dei DAG</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relazioni-complesse">Relazioni Complesse</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipi-di-percorsi">Tipi di Percorsi</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#strutture-causali-elementari">Strutture Causali Elementari</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#irreversibilita-e-aciclicita-nei-dag">Irreversibilità e Aciclicità nei DAG</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-confondimento-nei-dati-osservazionali">Il Confondimento nei Dati Osservazionali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uso-dei-dag-per-identificare-il-confondimento">Uso dei DAG per Identificare il Confondimento</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#identificazione-e-blocco-dei-percorsi-retrostanti">Identificazione e Blocco dei Percorsi Retrostanti</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#controllo-statistico-per-bloccare-i-percorsi-retrostanti">Controllo Statistico per Bloccare i Percorsi Retrostanti</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#obiettivo-del-controllo-di-terze-variabili">Obiettivo del Controllo di Terze Variabili</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#come-bloccare-un-percorso-retrostante">Come Bloccare un Percorso Retrostante</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pratiche-per-il-controllo-delle-variabili-in-un-dag">Pratiche per il Controllo delle Variabili in un DAG</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#come-controllare-una-variabile-nei-dati-osservazionali">Come Controllare una Variabile nei Dati Osservazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisi-stratificata">Analisi Stratificata</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#includere-variabili-terze-nei-modelli-di-regressione">Includere Variabili Terze nei Modelli di Regressione</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-matching-come-metodo-di-controllo-statistico">Il Matching come Metodo di Controllo Statistico</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#uso-del-matching-per-controllare-variabili-multiple">Uso del Matching per Controllare Variabili Multiple</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-sul-matching">Considerazioni sul Matching</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-di-misurazione-nelle-variabili-di-confondimento-e-il-suo-impatto">Errore di Misurazione nelle Variabili di Confondimento e il suo Impatto</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#influenza-dell-errore-di-misurazione">Influenza dell’Errore di Misurazione</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-dilemma-del-controllo-statistico-eccessivo">Il Dilemma del Controllo Statistico Eccessivo</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pratica-comune-e-i-suoi-limiti">Pratica Comune e i suoi Limiti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tipi-di-variabili-da-non-controllare">Tipi di Variabili da Non Controllare</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisi-dei-rischi-nel-controllo-di-collider-e-mediatori">Analisi dei Rischi nel Controllo di Collider e Mediatori</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-bias-del-collider-nelle-procedure-di-campionamento">Il Bias del Collider nelle Procedure di Campionamento</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-di-non-risposta">Bias di Non Risposta</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-di-attrito">Bias di Attrito</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problemi-correlati-dati-mancanti-e-rappresentativita-nei-dati-osservazionali">Problemi Correlati: Dati Mancanti e Rappresentatività nei Dati Osservazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-di-selezione-endogena-e-dati-mancanti">Bias di Selezione Endogena e Dati Mancanti</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#problema-della-non-rappresentativita-dei-campioni">Problema della Non Rappresentatività dei Campioni</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-bias-da-sovracontrollo-la-rimozione-dei-processi-di-interesse">Il Bias da Sovracontrollo: La Rimozione dei Processi di Interesse</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sovracontrollo-e-bias">Sovracontrollo e Bias</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-complessita-delle-inferenze-causali-sui-dati-correlazionali">La Complessità delle Inferenze Causali sui Dati Correlazionali</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-conclusive">Considerazioni Conclusive</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>