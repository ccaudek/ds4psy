

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Il teorema di Bayes &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-VMXNE4BCDL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-VMXNE4BCDL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_3/03_bayes_theorem';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4psy/chapter_3/03_bayes_theorem.html" />
    <link rel="shortcut icon" href="../_static/increasing.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="✏️ Esercizi" href="E_bayes_theorem.html" />
    <link rel="prev" title="✏️ Esercizi" href="E_cond_prob.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Correlazione e causazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/07_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_chapter_3.html">Probabilità</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_cond_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_expval_var.html">Variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="04a_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="04b_illusion.html">Incertezza inferenziale e variabilità dei risultati</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_4/introduction_part_4.html">Inferenza bayesiana</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/03_conjugate_families_1.html">Distribuzioni coniugate (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/11_beta_binomial_pymc.html">Inferenza bayesiana con PyMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/12_jax.html">Usare JAX per un campionamento più veloce</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/13_preliz.html">Scegliere le distribuzioni a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/16_summary_posterior_pymc.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/17_prediction.html">La predizione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/18_mcmc_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/19_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/20_poisson_model.html">Modello di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/21_poisson_sim.html">Modello di Poisson: derivazione analitica e MCMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_freq.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/22_normal_normal_model.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/23_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/24_multiple_groups.html">Gruppi multipli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/40_hier_beta_binom.html">Modello gerarchico beta-binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/41_hier_poisson.html">Modello gerarchico di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/42_hier_gaussian.html">Modello gerarchico gaussiano</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/hssm.html">Drift Diffusion Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_1.html">Il modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_2.html">Analisi bayesiana del modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_params_recovery.html">Analisi di simulazione per la stima dei parametri nel modello di regressione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_3.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_4.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_5.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_multilevel_modeling.html">A Primer on Bayesian Methods for Multilevel Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_7.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_simpson.html">Paradosso di Simpson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_logistic_reg.html">Modello di regressione logistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_binomial_reg.html">Regressione binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_covid.html">Inferenza controfattuale: calcolo delle morti in eccesso dovute al COVID-19</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_counterfactual.html">Analisi causale con PyMC</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_stab.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_s_m_errors.html">Crisi della replicabilità</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a04_summation_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a05_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a06_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a07_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a08_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a09_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_predict_counts.html">La predizione delle frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a21_reglin_2.html">Regressione lineare con Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a23_reglin_4.html">Posterior Predictive Checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4psy/blob/main/docs/chapter_3/03_bayes_theorem.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_3/03_bayes_theorem.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Il teorema di Bayes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretazione">Interpretazione</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alcuni-esempi">Alcuni esempi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inferire-il-genere-dalla-lunghezza-dei-capelli">Inferire il genere dalla lunghezza dei capelli</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mammografia-e-cancro-al-seno">Mammografia e cancro al seno</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-valore-predittivo-di-un-test-di-laboratorio">Il valore predittivo di un test di laboratorio</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-di-bayes-applicato-ai-dati-penguins">Teorema di Bayes applicato ai dati <code class="docutils literal notranslate"><span class="pre">penguins</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-delle-due-urne">Il problema delle due urne</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-dei-dadi">Il problema dei dadi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#l-errore-dell-avvocato-difensore">L’errore dell’avvocato difensore</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-di-bayes-per-eventi-dicotomici">Teorema di Bayes per eventi dicotomici</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-numerico-diagnosi-di-disturbo-d-ansia-sociale-das">Esempio Numerico: Diagnosi di Disturbo d’Ansia Sociale (DAS)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-iniziali">Informazioni Iniziali</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calcolo-degli-odds-a-posteriori">Calcolo degli Odds a Posteriori</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Interpretazione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/github/ccaudek/ds4psy_2023/blob/main/120_bayes_theorem.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="il-teorema-di-bayes">
<span id="bayes-theorem-notebook"></span><h1>Il teorema di Bayes<a class="headerlink" href="#il-teorema-di-bayes" title="Permalink to this heading">#</a></h1>
<div class="admonition-obiettivi-di-apprendimento admonition">
<p class="admonition-title">Obiettivi di apprendimento</p>
<p>Dopo aver completato questo capitolo, acquisirai le competenze per:</p>
<ul class="simple">
<li><p>Capire in profondità il teorema di Bayes e la sua importanza.</p></li>
<li><p>Utilizzare il teorema di Bayes per analizzare e interpretare i test diagnostici, tenendo in considerazione la prevalenza della malattia in questione.</p></li>
<li><p>Affrontare e risolvere problemi di probabilità discreta che necessitano dell’applicazione del teorema di Bayes.</p></li>
</ul>
</div>
<p>In questo capitolo esploreremo il teorema di Bayes, un fondamentale risultato della teoria delle probabilità che ci permette di calcolare le probabilità a posteriori di eventi ipotetici, dati i loro valori a priori e nuove informazioni. In altre parole, ci consente di aggiornare razionalmente le nostre conoscenze alla luce di nuove evidenze. Prima di procedere con il presente capitolo, è essenziale leggere l’appendice <a class="reference internal" href="../chapter_7/a07_calculus.html#calculus-appendix"><span class="std std-ref">Per liberarvi dai terrori preliminari</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Supponiamo di avere una partizione dell’evento certo <span class="math notranslate nohighlight">\(\Omega\)</span> in due soli eventi mutuamente esclusivi, che chiamiamo ipotesi <span class="math notranslate nohighlight">\(H_1\)</span> e <span class="math notranslate nohighlight">\(H_2\)</span>. Supponiamo inoltre di conoscere le probabilità a priori <span class="math notranslate nohighlight">\(P(H_1)\)</span> e <span class="math notranslate nohighlight">\(P(H_2)\)</span> delle due ipotesi. Consideriamo ora un terzo evento <span class="math notranslate nohighlight">\(E\)</span>, con probabilità non nulla, di cui conosciamo le probabilità condizionate <span class="math notranslate nohighlight">\(P(E \mid H_1)\)</span> e <span class="math notranslate nohighlight">\(P(E \mid H_2)\)</span>, ovvero la probabilità che si verifichi l’evento <span class="math notranslate nohighlight">\(E\)</span> dati i valori delle due ipotesi. Supponendo che si sia verificato l’evento <span class="math notranslate nohighlight">\(E\)</span>, vogliamo conoscere le probabilità a posteriori delle ipotesi, ovvero <span class="math notranslate nohighlight">\(P(H_1 \mid E)\)</span> e <span class="math notranslate nohighlight">\(P(H_2 \mid E)\)</span>.</p>
<p>La figura seguente rappresenta una partizione dell’evento certo in due eventi chiamati ‘ipotesi’ <span class="math notranslate nohighlight">\(H_1\)</span> e <span class="math notranslate nohighlight">\(H_2\)</span>. L’evidenza <span class="math notranslate nohighlight">\(E\)</span> è un sottoinsieme dello spazio campione.</p>
<a class="reference internal image-reference" href="../_images/bayes_theorem.png"><img alt="../_images/bayes_theorem.png" class="align-center" src="../_images/bayes_theorem.png" style="height: 230px;" /></a>
<p>Per trovare la probabilità dell’ipotesi 1 data l’evidenza osservata, scriviamo:</p>
<div class="math notranslate nohighlight">
\[
P(H_1 \mid E) = \frac{P(E \cap H_1)}{P(E)}.
\]</div>
<p>Possiamo sostituire <span class="math notranslate nohighlight">\(P(E \cap H_1)\)</span> con <span class="math notranslate nohighlight">\(P(E \mid H_1)P(H_1)\)</span> data la definizione di probabilità condizionata <span class="math notranslate nohighlight">\(P(E \mid H_1) = \frac{P(E \cap H_1)}{P(H_1)}\)</span>. Così facendo l’equazione precedente diventa:</p>
<div class="math notranslate nohighlight">
\[
P(H_1 \mid E) = \frac{P(E \mid H_1) P(H_1)}{P(E)}.
\]</div>
<p>Poiché <span class="math notranslate nohighlight">\(H_1\)</span> e <span class="math notranslate nohighlight">\(H_2\)</span> sono eventi disgiunti, la probabilità dell’evento <span class="math notranslate nohighlight">\(E\)</span> può essere calcolata utilizzando il teorema della probabilità totale:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
P(E) &amp;= P(E \cap H_1) + P(E \cap H_2)\notag\\
     &amp;= P(E \mid H_1)P(H_1) + P(E \mid H_2)P(H_2).
\end{split}
\end{split}\]</div>
<p>Sostituendo questi risultati nella formula di Bayes, otteniamo:</p>
<div class="math notranslate nohighlight" id="equation-eq-bayes1">
<span class="eqno">(14)<a class="headerlink" href="#equation-eq-bayes1" title="Permalink to this equation">#</a></span>\[
P(H_1 \mid E) = \frac{P(E \mid H_1)P(H_1)}{P(E \mid H_1)P(H_1) + P(E \mid H_2)P(H_2)}.
\]</div>
<p>L’eq. <a class="reference internal" href="#equation-eq-bayes1">(14)</a> è il caso più semplice della formula di Bayes, dove ci sono solo due eventi disgiunti <span class="math notranslate nohighlight">\(H_1\)</span> e <span class="math notranslate nohighlight">\(H_2\)</span>. Il caso generale può essere formulato nel modo seguente.</p>
<p>Sia <span class="math notranslate nohighlight">\((H_i)_{i\geq 1}\)</span> una partizione dell’evento certo <span class="math notranslate nohighlight">\(\Omega\)</span> e sia <span class="math notranslate nohighlight">\(E \subseteq \Omega\)</span> un evento tale che <span class="math notranslate nohighlight">\(P(E) &gt; 0\)</span>, allora, per <span class="math notranslate nohighlight">\(i = 1, \dots, \infty\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-bayes2">
<span class="eqno">(15)<a class="headerlink" href="#equation-eq-bayes2" title="Permalink to this equation">#</a></span>\[
P(H_i \mid E) = \frac{P(E \mid H_i)P(H_i)}{\sum_{j=1}^{\infty}P(H_j)P(E \mid H_j)}.
\]</div>
<p>Se <span class="math notranslate nohighlight">\(H_i\)</span> è una variabile continua (ad esempio, il valore di un parametro in un modello statistico), allora sostituiamo la somma a donominatore con un integrale</p>
<div class="math notranslate nohighlight" id="equation-eq-bayes-cont">
<span class="eqno">(16)<a class="headerlink" href="#equation-eq-bayes-cont" title="Permalink to this equation">#</a></span>\[
P(H_i \mid E) = \frac{P(E \mid H_i) \cdot P(H_i)}{\int P(E \mid H) \cdot P(H) \, dH},
\]</div>
<p>dove <span class="math notranslate nohighlight">\(P(H_i \mid E)\)</span> è la probabilità a posteriori dell’ipotesi <span class="math notranslate nohighlight">\(H_i\)</span> dato l’evidenza <span class="math notranslate nohighlight">\(E\)</span>, <span class="math notranslate nohighlight">\(P(E \mid H_i)\)</span> è la verosimiglianza di <span class="math notranslate nohighlight">\(E\)</span> dato <span class="math notranslate nohighlight">\(H_i\)</span>, <span class="math notranslate nohighlight">\(P(H_i)\)</span> è la probabilità a priori dell’ipotesi <span class="math notranslate nohighlight">\(H_i\)</span>, e l’integrale è effettuato sull’insieme delle ipotesi <span class="math notranslate nohighlight">\(H\)</span>.</p>
<section id="interpretazione">
<h2>Interpretazione<a class="headerlink" href="#interpretazione" title="Permalink to this heading">#</a></h2>
<p>Possiamo identificare tre concetti fondamentali nell’eq. <a class="reference internal" href="#equation-eq-bayes2">(15)</a>.</p>
<ul class="simple">
<li><p>La probabilità a priori, <span class="math notranslate nohighlight">\(P(H)\)</span>, rappresenta la misura di fiducia che attribuiamo all’ipotesi <span class="math notranslate nohighlight">\(H\)</span> prima di avere qualsiasi informazione sull’evidenza <span class="math notranslate nohighlight">\(E\)</span>.</p></li>
<li><p>La probabilità a posteriori, <span class="math notranslate nohighlight">\(P(H \mid E)\)</span>, rappresenta l’aggiornamento della probabilità a priori dopo aver ottenuto l’evidenza <span class="math notranslate nohighlight">\(E\)</span>. In altre parole, è la misura di fiducia che abbiamo nell’ipotesi <span class="math notranslate nohighlight">\(H\)</span> dopo aver preso in considerazione l’evidenza <span class="math notranslate nohighlight">\(E\)</span>.</p></li>
<li><p>La verosimiglianza di <span class="math notranslate nohighlight">\(E\)</span> dato <span class="math notranslate nohighlight">\(H\)</span>, <span class="math notranslate nohighlight">\(P(E \mid H)\)</span>, rappresenta la probabilità dell’evidenza <span class="math notranslate nohighlight">\(E\)</span> quando l’ipotesi <span class="math notranslate nohighlight">\(H\)</span> è vera. È una misura di quanta “supporto” o “conferma” fornisce l’evidenza <span class="math notranslate nohighlight">\(E\)</span> all’ipotesi <span class="math notranslate nohighlight">\(H\)</span>.</p></li>
</ul>
<p>Il teorema di Bayes è uno strumento fondamentale che ci permette di aggiornare le nostre credenze in base a nuove informazioni. In pratica, ci consente di calcolare la probabilità di un’ipotesi o evento dati gli elementi di evidenza disponibili. Questo teorema è particolarmente rilevante nell’interpretazione soggettiva della probabilità, poiché ci dà un metodo per aggiornare la nostra credenza sull’ipotesi <span class="math notranslate nohighlight">\(H\)</span> alla luce di nuove evidenze <span class="math notranslate nohighlight">\(E\)</span>. In altre parole, ci aiuta ad adeguare la probabilità assegnata a un’ipotesi in base alle nuove informazioni che abbiamo a disposizione. Questo processo di aggiornamento delle credenze è estremamente utile in molti campi, come l’intelligenza artificiale, la statistica, la biologia e la psicologia. In sostanza, il teorema di Bayes ci permette di considerare l’informazione come una risorsa dinamica e di tener conto di come questa influenza la nostra credenza. Ci aiuta a prendere decisioni più informate e a interpretare meglio i dati che abbiamo a disposizione, aumentando la nostra comprensione e la nostra capacità di fare previsioni corrette.</p>
</section>
<section id="alcuni-esempi">
<h2>Alcuni esempi<a class="headerlink" href="#alcuni-esempi" title="Permalink to this heading">#</a></h2>
<section id="inferire-il-genere-dalla-lunghezza-dei-capelli">
<h3>Inferire il genere dalla lunghezza dei capelli<a class="headerlink" href="#inferire-il-genere-dalla-lunghezza-dei-capelli" title="Permalink to this heading">#</a></h3>
<p>Supponiamo di vedere una persona con i capelli lunghi. Vogliamo stimare la probabilità che questa persona sia una donna. Cioè, per <span class="math notranslate nohighlight">\(H = \text{donna} \)</span> e <span class="math notranslate nohighlight">\( E = \text{capelli lunghi} \)</span>, vogliamo stimare <span class="math notranslate nohighlight">\( P(H \mid E) \)</span>.</p>
<p>Le informazioni a priori sono che</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( P(H) = 0.5, \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( P(E) = 0.4, \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( P(E \mid H) = 0.7. \)</span></p></li>
</ul>
<p>Utilizzando la regola di Bayes, possiamo calcolare:</p>
<div class="math notranslate nohighlight">
\[ P(H \mid E) = \frac{P(H) \times P(E \mid H)}{P(E)} = \frac{0.5 \times 0.7}{0.4} = 0.875. \]</div>
</section>
<section id="mammografia-e-cancro-al-seno">
<h3>Mammografia e cancro al seno<a class="headerlink" href="#mammografia-e-cancro-al-seno" title="Permalink to this heading">#</a></h3>
<p>Un lettore attento si sarà reso conto che, in precedenza, abbiamo già applicato il teorema di Bayes quando abbiamo risolto il problema sulla mammografia e cancro al seno. In quel caso, le due ipotesi erano “la malattia è presente”, che possiamo denotare con <span class="math notranslate nohighlight">\(M^+\)</span>, e “la malattia è assente”, <span class="math notranslate nohighlight">\(M^-\)</span>. L’evidenza <span class="math notranslate nohighlight">\(E\)</span> era costituita dal risultato positivo al test (denotiamo questo evento con <span class="math notranslate nohighlight">\(T^+\)</span>). Con questa notazione, possiamo scrivere l’eq. <a class="reference internal" href="#equation-eq-bayes1">(14)</a> nel modo seguente</p>
<div class="math notranslate nohighlight">
\[
P(M^+ \mid T^+) = \frac{P(T^+ \mid M^+) P(M^+)}{P(T^+ \mid M^+) P(M^+) + P(T^+ \mid M^-) P(M^-)},
\]</div>
<p>dove <span class="math notranslate nohighlight">\(P(M^+ \mid T^+)\)</span> rappresenta la probabilità che un paziente abbia la malattia (<span class="math notranslate nohighlight">\(M^+\)</span>) dato che l’esame medico risulta positivo (<span class="math notranslate nohighlight">\(T^+\)</span>), <span class="math notranslate nohighlight">\(P(T^+ \mid M^+)\)</span> è la probabilità che l’esame risulti positivo (<span class="math notranslate nohighlight">\(T^+\)</span>) dato che il paziente ha effettivamente la malattia (<span class="math notranslate nohighlight">\(M^+\)</span>), <span class="math notranslate nohighlight">\(P(M^+)\)</span> è la probabilità a priori che un paziente abbia la malattia, ovvero la probabilità che un paziente scelto a caso abbia la malattia prima di eseguire l’esame, <span class="math notranslate nohighlight">\(P(T^+ \mid M^-)\)</span> è la probabilità che l’esame risulti positivo (<span class="math notranslate nohighlight">\(T^+\)</span>) dato che il paziente non ha la malattia (<span class="math notranslate nohighlight">\(M^-\)</span>) e <span class="math notranslate nohighlight">\(P(M^-)\)</span> è la probabilità a priori che un paziente non abbia la malattia, ovvero la probabilità che un paziente scelto a caso non abbia la malattia prima di eseguire l’esame.</p>
<p>Inserendo i dati del problema nella formula precedente otteniamo</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P(M^+ \mid T^+) &amp;= \frac{0.9 \cdot 0.01}{0.9 \cdot 0.01 + 0.1 \cdot 0.99} \notag\\
&amp;= \frac{9}{108} \notag\\
&amp;\approx 0.083.\notag
\end{align}
\end{split}\]</div>
</section>
<section id="il-valore-predittivo-di-un-test-di-laboratorio">
<h3>Il valore predittivo di un test di laboratorio<a class="headerlink" href="#il-valore-predittivo-di-un-test-di-laboratorio" title="Permalink to this heading">#</a></h3>
<p>L’esercizio precedente illustra un importante utilizzo del teorema di Bayes. Esso ci permette di calcolare la probabilità di malattia in caso di test positivo o di assenza di malattia in caso di test negativo. Per fare ciò, abbiamo bisogno di conoscere tre informazioni chiave: la prevalenza di una malattia, la sensibilità e la specificità del test utilizzato per la diagnosi.</p>
<p>In particolare, la prevalenza di una malattia è la sua frequenza nella popolazione. La sensibilità del test ci dice quale percentuale di soggetti malati viene identificata come tali dal test. La specificità del test ci dice quale percentuale di soggetti sani viene identificata come tali dal test.</p>
<p>Il teorema di Bayes ci permette di combinare queste informazioni per calcolare la probabilità di avere la malattia (o di non averla) sulla base del risultato del test. In questo modo, possiamo utilizzare il teorema di Bayes per prendere decisioni informate sulla diagnosi e sul trattamento delle malattie.</p>
<br />
<a class="reference internal image-reference" href="../_images/bayes_theorem_2x.png"><img alt="../_images/bayes_theorem_2x.png" class="align-center" src="../_images/bayes_theorem_2x.png" style="height: 320px;" /></a>
<br />
<p>L’esercizio precedente ha mostrato un importante utilizzo del teorema di Bayes. In particolare, abbiamo visto come il teorema di Bayes ci permette di calcolare la probabilità di avere una malattia quando il test risulta positivo o la probabilità di non avere la malattia quando il test risulta negativo. Per fare ciò, abbiamo bisogno di tre informazioni: la prevalenza della malattia, la sensibilità e la specificità del test diagnostico. Ora esamineremo più in dettaglio l’applicazione del teorema di Bayes in questo contesto.</p>
<p>La sensibilità del test è definita come la probabilità che il test dia un risultato positivo dato che la malattia è presente: <span class="math notranslate nohighlight">\(P(T^+ \mid M^+)\)</span>. Una sensibilità del 100% significa che il test è positivo in tutti i casi di malattia, una sensibilità del 90% significa che il test è positivo nel 90% dei casi di malattia, e così via.</p>
<p>La specificità del test è definita come la probabilità che il test dia un risultato negativo dato che la malattia è assente: <span class="math notranslate nohighlight">\(P(T^- \mid M^-)\)</span>. Una specificità del 100% significa che il test è negativo in tutti i casi di assenza di malattia, una specificità del 90% significa che il test è negativo nel 90% dei casi di assenza di malattia, e così via.</p>
<p>La prevalenza della malattia è definita come la probabilità che la malattia sia presente: <span class="math notranslate nohighlight">\(P^+\)</span>. Possiamo interpretare la prevalenza come la proporzione di individui malati nella popolazione in un dato istante. Ad esempio, una prevalenza del 5 per mille significa che il 5 per mille della popolazione è affetto dalla malattia.</p>
<p>La seguente tabella chiarisce la terminologia utilizzata</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p></p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(T^+\)</span></p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(T^-\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><span class="math notranslate nohighlight">\(M^+\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(P(T^+ \cap M^+)\)</span> (sensibilità)</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(P(T^- \cap M^+)\)</span> (1 - sensibilità)</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><span class="math notranslate nohighlight">\(M^-\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(P(T^+ \cap M^-)\)</span> (1 - specificità )</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(P(T^- \cap M^-)\)</span> (specificità)</p></td>
</tr>
</tbody>
</table>
<p>dove <span class="math notranslate nohighlight">\(T^+\)</span> rappresenta il risultato positivo del test, cioè quando il test indica la presenza della malattia; <span class="math notranslate nohighlight">\(T^-\)</span> rappresenta il risultato negativo del test, cioè quando il test indica l’assenza della malattia; <span class="math notranslate nohighlight">\(M^+\)</span> indica la presenza effettiva della malattia; <span class="math notranslate nohighlight">\(M^-\)</span> indica l’assenza effettiva della malattia.</p>
<p>Nel caso dell’applicazione del teorema di Bayes alla diagnosi medica, abbiamo bisogno di conoscere la prevalenza della malattia (la proporzione di individui malati nella popolazione), la sensibilità del test (la probabilità che il test dia un risultato positivo quando la malattia è presente) e la specificità del test (la probabilità che il test dia un risultato negativo quando la malattia è assente). Usando queste informazioni, possiamo calcolare il valore predittivo del test positivo, cioè la probabilità che una persona sia effettivamente malata dato che il test è risultato positivo.</p>
<div class="math notranslate nohighlight">
\[
P(M^+ \mid T^+) = \frac{P(T^+ \mid M^+) P(M^+)}{P(T^+ \mid M^+) P(M^+) + P(T^+ \mid M^-) P(M^-)}.
\]</div>
<div class="math notranslate nohighlight">
\[
P(M^+ \mid T^+) = \frac{\text{sensibilità} \cdot \text{prevalenza}}{\text{sensibilità} \cdot \text{prevalenza} + (1 - \text{specificità}) \cdot (1 - \text{prevalenza})}.
\]</div>
<p>Entrambe le formule sono equivalenti e rappresentano la probabilità che una persona sia malata dato un risultato positivo del test. Questa è una formula chiave per valutare l’efficacia di un test diagnostico e per comprendere quanto sia probabile che un individuo sia effettivamente malato dato un risultato positivo del test.</p>
<p>In modo simile, possiamo calcolare il valore predittivo del test negativo, cioè la probabilità che una persona non sia malata dato un risultato negativo del test.</p>
<div class="math notranslate nohighlight">
\[
P(M^- \mid T^-  ) = \frac{\text{specificità} \cdot (1 - \text{prevalenza})}{\text{specificità} \cdot (1 - \text{prevalenza}) + (1 - \text{sensibilità}) \cdot \text{prevalenza}}.
\]</div>
<p>Calcoliamo ora il valore predittivo del test positivo e il valore predittivo del test negativo con i dati dell’esempio sulla mammografia e cancro al seno.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">positive_predictive_value_of_diagnostic_test</span><span class="p">(</span><span class="n">sens</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">prev</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sens</span> <span class="o">*</span> <span class="n">prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sens</span> <span class="o">*</span> <span class="n">prev</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">spec</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prev</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">negative_predictive_value_of_diagnostic_test</span><span class="p">(</span><span class="n">sens</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">prev</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">spec</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prev</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">spec</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prev</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sens</span><span class="p">)</span> <span class="o">*</span> <span class="n">prev</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sens</span> <span class="o">=</span> <span class="mf">0.9</span>  <span class="c1"># sensibilità</span>
<span class="n">spec</span> <span class="o">=</span> <span class="mf">0.9</span>  <span class="c1"># specificità</span>
<span class="n">prev</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># prevalenza</span>
</pre></div>
</div>
</div>
</div>
<p>Valore predittivo del test positivo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_pos</span> <span class="o">=</span> <span class="n">positive_predictive_value_of_diagnostic_test</span><span class="p">(</span><span class="n">sens</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">prev</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(M+ | T+) = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">res_pos</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(M+ | T+) = 0.083
</pre></div>
</div>
</div>
</div>
<p>Valore predittivo del test negativo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_neg</span> <span class="o">=</span> <span class="n">negative_predictive_value_of_diagnostic_test</span><span class="p">(</span><span class="n">sens</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">prev</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(M- | T-) = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">res_neg</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(M- | T-) = 0.999
</pre></div>
</div>
</div>
</div>
<p>Consideriamo ora il test antigenico rapido per il virus SARS-CoV-2, che può essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L’Istituto Superiore di Sanità ha pubblicato un documento il 5 novembre 2020, nel quale viene sottolineato che, fino a quel momento, i dati disponibili sui vari test sono quelli forniti dai produttori: la sensibilità varia tra il 70% e l’86%, mentre la specificità si attesta tra il 95% e il 97%.</p>
<p>Nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus è stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa 0.2% su una popolazione totale di circa 59 milioni di persone.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span> <span class="n">prev</span> <span class="o">=</span> <span class="mi">138599</span> <span class="o">/</span> <span class="mi">59000000</span>
 <span class="n">prev</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.002349135593220339
</pre></div>
</div>
</div>
</div>
<p>L’obiettivo è determinare la probabilità di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia <span class="math notranslate nohighlight">\(P(M^+ \mid T^+)\)</span>. Per raggiungere questo scopo, ci avvarremo della formula relativa al valore predittivo positivo del test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sens</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.7</span> <span class="o">+</span> <span class="mf">0.86</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># sensibilità</span>
<span class="n">spec</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.95</span> <span class="o">+</span> <span class="mf">0.97</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="c1"># specificità</span>

<span class="n">res_pos</span> <span class="o">=</span> <span class="n">positive_predictive_value_of_diagnostic_test</span><span class="p">(</span><span class="n">sens</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">prev</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(M+ | T+) = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">res_pos</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(M+ | T+) = 0.044
</pre></div>
</div>
</div>
</div>
<p>Pertanto, se il risultato del tampone è positivo, la probabilità di essere effettivamente affetti da Covid-19 è solo del 4.4%, approssimativamente.</p>
<p>Se la prevalenza fosse 100 volte superiore (cioè, pari al 23.5%), la probabilità di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari all’85.7%, approssimativamente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prev</span> <span class="o">=</span> <span class="mi">138599</span> <span class="o">/</span> <span class="mi">59000000</span> <span class="o">*</span> <span class="mi">100</span>

<span class="n">res_pos</span> <span class="o">=</span> <span class="n">positive_predictive_value_of_diagnostic_test</span><span class="p">(</span><span class="n">sens</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">prev</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(M+ | T+) = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">res_pos</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(M+ | T+) = 0.857
</pre></div>
</div>
</div>
</div>
<p>Se il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilità di non essere infetto sarebbe del 99.9%, approssimativamente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sens</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.7</span> <span class="o">+</span> <span class="mf">0.86</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># sensibilità</span>
<span class="n">spec</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.95</span> <span class="o">+</span> <span class="mf">0.97</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># specificità</span>
<span class="n">prev</span> <span class="o">=</span> <span class="mi">138599</span> <span class="o">/</span> <span class="mi">59000000</span>  <span class="c1"># prevalenza</span>

<span class="n">res_neg</span> <span class="o">=</span> <span class="n">negative_predictive_value_of_diagnostic_test</span><span class="p">(</span><span class="n">sens</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">prev</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(M- | T-) = </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">res_neg</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(M- | T-) = 0.999
</pre></div>
</div>
</div>
</div>
</section>
<section id="teorema-di-bayes-applicato-ai-dati-penguins">
<h3>Teorema di Bayes applicato ai dati <code class="docutils literal notranslate"><span class="pre">penguins</span></code><a class="headerlink" href="#teorema-di-bayes-applicato-ai-dati-penguins" title="Permalink to this heading">#</a></h3>
<p>Proseguendo con l’esempio del capitolo precedente, usiamo i dati <code class="docutils literal notranslate"><span class="pre">penguins</span></code> per applicare il teorema di Bayes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/penguins.csv&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 333 entries, 0 to 343
Data columns (total 8 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   species            333 non-null    object 
 1   island             333 non-null    object 
 2   bill_length_mm     333 non-null    float64
 3   bill_depth_mm      333 non-null    float64
 4   flipper_length_mm  333 non-null    float64
 5   body_mass_g        333 non-null    float64
 6   sex                333 non-null    object 
 7   year               333 non-null    int64  
dtypes: float64(4), int64(1), object(3)
memory usage: 23.4+ KB
</pre></div>
</div>
</div>
</div>
<p>Riprendiamo le funzioni <code class="docutils literal notranslate"><span class="pre">prob</span></code> e <code class="docutils literal notranslate"><span class="pre">conditional</span></code> che abbiamo definito in precedenza.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prob</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the probability of a proposition, A.&quot;&quot;&quot;</span> 
    <span class="k">return</span> <span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conditional</span><span class="p">(</span><span class="n">proposition</span><span class="p">,</span> <span class="n">given</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">prob</span><span class="p">(</span><span class="n">proposition</span><span class="p">[</span><span class="n">given</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Per la congiunzione vale la proprietà di commutatività:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">female</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;female&quot;</span>
<span class="n">small</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;body_mass_g&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;body_mass_g&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prob</span><span class="p">(</span><span class="n">female</span> <span class="o">&amp;</span> <span class="n">small</span><span class="p">)</span> <span class="o">==</span> <span class="n">prob</span><span class="p">(</span><span class="n">small</span> <span class="o">&amp;</span> <span class="n">female</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Quindi possiamo scrivere:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional</span><span class="p">(</span><span class="n">female</span><span class="p">,</span> <span class="n">given</span><span class="o">=</span><span class="n">small</span><span class="p">)</span> <span class="o">*</span> <span class="n">prob</span><span class="p">(</span><span class="n">small</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2552552552552553
</pre></div>
</div>
</div>
</div>
<p>oppure</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional</span><span class="p">(</span><span class="n">small</span><span class="p">,</span> <span class="n">given</span><span class="o">=</span><span class="n">female</span><span class="p">)</span> <span class="o">*</span> <span class="n">prob</span><span class="p">(</span><span class="n">female</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2552552552552552
</pre></div>
</div>
</div>
</div>
<p>Giungiamo così al teorema di Bayes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional</span><span class="p">(</span><span class="n">female</span><span class="p">,</span> <span class="n">given</span><span class="o">=</span><span class="n">small</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8252427184466019
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional</span><span class="p">(</span><span class="n">small</span><span class="p">,</span> <span class="n">given</span><span class="o">=</span><span class="n">female</span><span class="p">)</span> <span class="o">*</span> <span class="n">prob</span><span class="p">(</span><span class="n">female</span><span class="p">)</span> <span class="o">/</span> <span class="n">prob</span><span class="p">(</span><span class="n">small</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8252427184466018
</pre></div>
</div>
</div>
</div>
<p>oppure</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional</span><span class="p">(</span><span class="n">small</span><span class="p">,</span> <span class="n">given</span><span class="o">=</span><span class="n">female</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5151515151515151
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional</span><span class="p">(</span><span class="n">female</span><span class="p">,</span> <span class="n">given</span><span class="o">=</span><span class="n">small</span><span class="p">)</span> <span class="o">*</span> <span class="n">prob</span><span class="p">(</span><span class="n">small</span><span class="p">)</span> <span class="o">/</span> <span class="n">prob</span><span class="p">(</span><span class="n">female</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5151515151515152
</pre></div>
</div>
</div>
</div>
</section>
<section id="il-problema-delle-due-urne">
<h3>Il problema delle due urne<a class="headerlink" href="#il-problema-delle-due-urne" title="Permalink to this heading">#</a></h3>
<p>Supponiamo che vi siano due urne.</p>
<ul class="simple">
<li><p>L’urna 1 (<span class="math notranslate nohighlight">\(U_1\)</span>) contiene 30 palline bianche (B) e 10 palline nere (N).</p></li>
<li><p>L’urna 2 (<span class="math notranslate nohighlight">\(U_2\)</span>) contiene 20 palline bianche e 20 palline nere.</p></li>
</ul>
<p>Supponiamo di scegliere una delle urne a caso e, senza guardare, di scegliere una pallina a caso. Se la pallina è bianca, qual è la probabilità che provenga dall’urna 1?</p>
<p>Quello che vogliamo è la probabilità condizionata che abbiamo scelto dall’Urna 1 dato che abbiamo ottenuto una pallina bianca, <span class="math notranslate nohighlight">\(P(U_1 \mid B)\)</span>.</p>
<p>Il problema ci fornisce le seguenti informazioni:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(B \mid U_1)\)</span> = 3/4,</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B \mid U_2)\)</span> = 1/2.</p></li>
</ul>
<p>Il teorema di Bayes ci dice come le informazioni a disposizione si possono mettere in relazione con la domanda del problema:</p>
<div class="math notranslate nohighlight">
\[
P(U_1 \mid B) = \frac{P(B \mid U_1) P(U_1)}{P(B)}
\]</div>
<p>Per calcolare la probabilità <span class="math notranslate nohighlight">\(P(B)\)</span> usiamo il teorema della probabilità totale:</p>
<div class="math notranslate nohighlight">
\[
P(B) = P(B \mid U_1) P(U_1) + P(B \mid U_2) P(U_2),
\]</div>
<p>ovvero</p>
<div class="math notranslate nohighlight">
\[
P(B) = 3/4 \cdot 1/2 + 1/2 \cdot 1/2 = 5/8.
\]</div>
<p>Concludiamo applicando il teorema di Bayes:</p>
<div class="math notranslate nohighlight">
\[
P(U_1 \mid B) = \frac{3/4 \cdot 1/2}{5/8} = 3/5.
\]</div>
<p>Il processo di aggiornamento bayesiano può essere anche svolto nel modo seguente. Riscrivo il teorema di Bayes nel modo seguente:</p>
<div class="math notranslate nohighlight">
\[
P(H \mid D) = \frac{P(D \mid H) P(H)}{P(D)}
\]</div>
<p>La probabilità <span class="math notranslate nohighlight">\(P(H)\)</span> è la probabilità delle ipotesi prima di avere osservato i dati. Nel nostro caso, le due ipotesi sono “Urna 1” e “Urna 2”, entrambe con la stessa probabilità, dato che non abbiamo ragioni a priori per dare più peso ad un’ipotesi rispetto all’altra. Costruiamo una tabella con un DataFrame in cui inseriamo la colonna <code class="docutils literal notranslate"><span class="pre">prior</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Urn 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Urn 2&quot;</span><span class="p">])</span>
<span class="n">table</span><span class="p">[</span><span class="s2">&quot;prior&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Urn 1</th>
      <td>0.5</td>
    </tr>
    <tr>
      <th>Urn 2</th>
      <td>0.5</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>La probabilità <span class="math notranslate nohighlight">\(P(D \mid H)\)</span> è la probabilità dei dati, data l’ipotesi. È chiamata verosimiglianza. La probabilità di una pallina bianca dato che viene estratta dall’Urna 1 è 3/4. La probabilità di una pallina bianca dato che viene estratta dall’Urna 1 è 1/2. Aggiungo alla tabella la colonna <code class="docutils literal notranslate"><span class="pre">likelihood</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="p">[</span><span class="s2">&quot;likelihood&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Urn 1</th>
      <td>0.5</td>
      <td>0.75</td>
    </tr>
    <tr>
      <th>Urn 2</th>
      <td>0.5</td>
      <td>0.50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>La probabilità <span class="math notranslate nohighlight">\(P(H \mid D)\)</span> è la probabilità dell’ipotesi dopo avere osservato i dati. Si ottiene come il prodotto della verosimiglianza per la probabilità a priori, diviso per una <em>costante di normalizzazione</em>. Iniziamo a calcolare il la distribuzione a posteriori non normalizzata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="p">[</span><span class="s2">&quot;unnorm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s2">&quot;prior&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">table</span><span class="p">[</span><span class="s2">&quot;likelihood&quot;</span><span class="p">]</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Urn 1</th>
      <td>0.5</td>
      <td>0.75</td>
      <td>0.375</td>
    </tr>
    <tr>
      <th>Urn 2</th>
      <td>0.5</td>
      <td>0.50</td>
      <td>0.250</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>La probabilità dei dati, <span class="math notranslate nohighlight">\(P(D)\)</span>, ovvero il numeratore bayesiano, è dato dalla somma di tutti i valori della distribuzione a posteriori non normalizzata:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prob_data</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s2">&quot;unnorm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Possiamo ora normalizzare la distribuzione a posteriori:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="p">[</span><span class="s2">&quot;posterior&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s2">&quot;unnorm&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">prob_data</span>
<span class="n">table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Urn 1</th>
      <td>0.5</td>
      <td>0.75</td>
      <td>0.375</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>Urn 2</th>
      <td>0.5</td>
      <td>0.50</td>
      <td>0.250</td>
      <td>0.4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="il-problema-dei-dadi">
<h3>Il problema dei dadi<a class="headerlink" href="#il-problema-dei-dadi" title="Permalink to this heading">#</a></h3>
<p>Il metodo precedente può anche essere usato quando ci sono più di due ipotesi. <span id="id1">Downey [<a class="reference internal" href="../references/bibliography.html#id47" title="Allen B Downey. Think Bayes. &quot; O'Reilly Media, Inc.&quot;, 2021.">Dow21</a>]</span> discute il seguente problema. Supponiamo che nell’Urna 1 ci sia un dado a 6 facce, nell’Urna 2 un dado a 8 facce e nell’Urna 3 un dado a 12 facce. Un dado viene estratto a caso da un’urna e produce il risultato 1. Qual è la probabilità che ho usato un dado a 6 facce?</p>
<p>Inizio a definire le tre ipotesi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">table2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
    </tr>
    <tr>
      <th>8</th>
    </tr>
    <tr>
      <th>12</th>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Per evitare arrotondamenti uso la funzione <code class="docutils literal notranslate"><span class="pre">Fraction()</span></code>. Inizio a definire la distribuzione a priori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fractions</span> <span class="kn">import</span> <span class="n">Fraction</span>

<span class="n">table2</span><span class="p">[</span><span class="s2">&quot;prior&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">table2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1/3</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1/3</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1/3</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Definisco la verosimiglianza. Se il dado è a 6 facce, la probabilità di ottenere 1 è 1/6; se il dado ha 8 facce è 1/8; se il dado ha 12 facce è 1/12.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table2</span><span class="p">[</span><span class="s2">&quot;likelihood&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">Fraction</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">table2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1/3</td>
      <td>1/6</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1/3</td>
      <td>1/8</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1/3</td>
      <td>1/12</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Trovo la distribuzione a posteriori non normalizzata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table2</span><span class="p">[</span><span class="s2">&quot;unnorm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table2</span><span class="p">[</span><span class="s2">&quot;prior&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">table2</span><span class="p">[</span><span class="s2">&quot;likelihood&quot;</span><span class="p">]</span>
<span class="n">table2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1/3</td>
      <td>1/6</td>
      <td>1/18</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1/3</td>
      <td>1/8</td>
      <td>1/24</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1/3</td>
      <td>1/12</td>
      <td>1/36</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Normalizzo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prob_data</span> <span class="o">=</span> <span class="n">table2</span><span class="p">[</span><span class="s2">&quot;unnorm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">table2</span><span class="p">[</span><span class="s2">&quot;posterior&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">table2</span><span class="p">[</span><span class="s2">&quot;unnorm&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">prob_data</span>
<span class="n">table2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prior</th>
      <th>likelihood</th>
      <th>unnorm</th>
      <th>posterior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>1/3</td>
      <td>1/6</td>
      <td>1/18</td>
      <td>4/9</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1/3</td>
      <td>1/8</td>
      <td>1/24</td>
      <td>1/3</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1/3</td>
      <td>1/12</td>
      <td>1/36</td>
      <td>2/9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>La probabilità posteriore del dado a 6 facce è 4/9, che è più grande delle probabilità degli altri dadi, 3/9 e 2/9. Intuitivamente, il dado a 6 facce è il più probabile perché ha la probabilità più grande di produrre il risultato che abbiamo osservato.</p>
</section>
<section id="l-errore-dell-avvocato-difensore">
<h3>L’errore dell’avvocato difensore<a class="headerlink" href="#l-errore-dell-avvocato-difensore" title="Permalink to this heading">#</a></h3>
<p>Una donna è stata assassinata e il marito è sotto processo per questo crimine. Durante il processo emerge che l’imputato aveva un passato di abusi sulla moglie. L’avvocato difensore sostiene che questa prova dovrebbe essere esclusa perché irrilevante, dato che solo 1 uomo su 10000 che abusa della moglie finisce poi per ucciderla. Dovrebbe il giudice accettare la richiesta dell’avvocato difensore di escludere questa prova?</p>
<p>Supponiamo che la cifra 1 su 10000 fornita dall’avvocato difensore sia corretta e assumiamo inoltre le seguenti probabilità per una popolazione rilevante di mariti e mogli: 1 marito su 10 abusa della moglie, 1 moglie su 5 assassinata viene uccisa dal marito, e il 50% dei mariti che uccidono le loro mogli le aveva precedentemente abusate.</p>
<p>Definiamo <span class="math notranslate nohighlight">\( A \)</span> come l’evento in cui il marito abusa della moglie, e <span class="math notranslate nohighlight">\( G \)</span> come l’evento in cui il marito è colpevole. L’argomento della difesa è che <span class="math notranslate nohighlight">\( P(G \mid A) = \frac{1}{10000} \)</span>, quindi la colpevolezza è estremamente improbabile condizionata a una storia pregressa di abusi.</p>
<p>Tuttavia, l’avvocato difensore omette di considerare un fatto cruciale: in questo caso, sappiamo che la moglie è stata assassinata. Pertanto, la probabilità rilevante non è <span class="math notranslate nohighlight">\( P(G \mid A) \)</span>, ma <span class="math notranslate nohighlight">\( P(G \mid A,M) \)</span>, dove <span class="math notranslate nohighlight">\( M \)</span> è l’evento in cui la moglie è stata assassinata.</p>
<p>Applicando la regola di Bayes con un ulteriore fattore di condizionamento, otteniamo:</p>
<div class="math notranslate nohighlight">
\[
P(G \mid A,M) = \frac{P(A \mid G,M)P(G \mid M)}{P(A \mid G,M)P(G \mid M) + P(A \mid G^c,M)P(G^c \mid M)} 
= \frac{0.5 \cdot 0.2}{0.5 \cdot 0.2 + 0.1 \cdot 0.8} 
= \frac{59}{100}.
\]</div>
<p>La condizionata della Regola di Bayes e include le seguenti componenti:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( P(G \mid A,M) \)</span>: La probabilità che il marito sia colpevole, dato che ha abusato della moglie e che questa è stata assassinata.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(A \mid G,M) \)</span>: La probabilità che il marito abbia abusato della moglie, dato che è colpevole e che la moglie è stata assassinata. Questa è stata assunta come <span class="math notranslate nohighlight">\(0.5\)</span> nel problema.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(G \mid M) \)</span>: La probabilità che il marito sia colpevole, dato che la moglie è stata assassinata. Questa è stata assunta come <span class="math notranslate nohighlight">\(0.2\)</span> nel problema.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(A \mid G^c,M) \)</span>: La probabilità che il marito abbia abusato della moglie, dato che non è colpevole ma la moglie è stata assassinata. Questa è stata assunta come <span class="math notranslate nohighlight">\(0.1\)</span> nel problema.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(G^c \mid M) \)</span>: La probabilità che il marito non sia colpevole, dato che la moglie è stata assassinata. Questa è semplicemente <span class="math notranslate nohighlight">\(1 - P(G \mid M) = 0.8\)</span>.</p></li>
</ul>
<p>La formula permette di combinare diverse fonti di informazione per arrivare a una stima più accurata della probabilità di colpevolezza. In questo caso, la probabilità a posteriori di colpevolezza, <span class="math notranslate nohighlight">\( P(G \mid A,M) \)</span>, si rivela essere molto più alta della probabilità iniziale <span class="math notranslate nohighlight">\( P(G \mid A) \)</span> proposta dall’avvocato difensore. Pertanto, contrariamente all’argomento dell’avvocato, la storia di abusi del marito è un’informazione molto importante che non dovrebbe essere ignorata nel processo. Condizionando sulla prova degli abusi, la probabilità di colpevolezza sale da <span class="math notranslate nohighlight">\( P(G \mid M) = 0.2 \)</span> a <span class="math notranslate nohighlight">\( P(G \mid A,M) \approx 0.59 \)</span>, contraddicendo quindi l’argomento dell’avvocato difensore.</p>
<p>Nel calcolo di <span class="math notranslate nohighlight">\( P(G \mid A,M) \)</span>, non abbiamo utilizzato la probabilità <span class="math notranslate nohighlight">\( P(G\mid A) \)</span> fornita dall’avvocato difensore; è irrilevante per il nostro calcolo perché non tiene conto del fatto che la moglie è stata assassinata.</p>
<p>Questo esempio mette in evidenza come sia necessario  condizionare su tutte le prove disponibili. Inoltre, questo esempio mette in luce le complessità e le potenziali insidie nell’utilizzo della probabilità condizionata, soprattutto quando sono in gioco variabili di confondimento.</p>
</section>
</section>
<section id="teorema-di-bayes-per-eventi-dicotomici">
<h2>Teorema di Bayes per eventi dicotomici<a class="headerlink" href="#teorema-di-bayes-per-eventi-dicotomici" title="Permalink to this heading">#</a></h2>
<p>Consideriamo un caso clinico in cui un paziente ha una finestra temporale di quattro ore al giorno durante la quale potrebbe manifestare un episodio di depressione. In assenza di ulteriori informazioni, l’estimazione a priori della probabilità che il paziente stia vivendo un episodio depressivo in un dato momento è del 25%.</p>
<p>Supponiamo ora che un parente del paziente noti che quest’ultimo ha cessato di rispondere ai messaggi e alle chiamate. Come cambia la probabilità che il paziente stia effettivamente attraversando un episodio depressivo alla luce di questa nuova evidenza?</p>
<p>Per rispondere a questa domanda, possiamo utilizzare il Teorema di Bayes, formalizzato come segue:</p>
<div class="math notranslate nohighlight">
\[
P(\text{Ipotesi | Dati}) = \frac{{P(\text{Dati | Ipotesi}) \times P(\text{Ipotesi})}}{P(\text{Dati})}.
\]</div>
<p>Per calcolare <span class="math notranslate nohighlight">\( P(\text{Ipotesi | Dati}) \)</span>, consideriamo i seguenti valori:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( P(\text{Ipotesi}) = 0.25 \)</span>: la probabilità a priori che il paziente stia attraversando un episodio depressivo.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(\text{Dati | Ipotesi}) = 0.8 \)</span>: la probabilità che il paziente smetta di rispondere durante un episodio depressivo.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(\text{Dati}) = 0.2 \)</span>: la probabilità generale che il paziente smetta di rispondere, indipendentemente dal suo stato emotivo.</p></li>
</ul>
<p>La probabilità posteriore <span class="math notranslate nohighlight">\( P(\text{Ipotesi | Dati}) \)</span> è quindi calcolata come:</p>
<div class="math notranslate nohighlight">
\[
P(\text{Ipotesi | Dati}) = \frac{0.8 \times 0.25}{0.2}.
\]</div>
<p>In contesti in cui sono possibili solo due esiti, come il presente, possiamo utilizzare i rapporti di probabilità (odds) per esprimere le probabilità. Ad esempio, se la probabilità a priori che il paziente stia vivendo un episodio di depressione è del 25%, l’odds è <span class="math notranslate nohighlight">\( \frac{1}{3} \)</span>, dato che la probabilità complementare è del 75%. In tali circostanze, il Teorema di Bayes può anche essere espresso come:</p>
<div class="math notranslate nohighlight">
\[
\text{Odds}(\text{H | D}) = \text{Odds}(\text{H}) \times \frac{P(D | H)}{P(D | \neg H)}.
\]</div>
<p>Qui, il fattore <span class="math notranslate nohighlight">\( \frac{P(D | H)}{P(D | \neg H)} \)</span> è noto come “rapporto di verosimiglianza”.</p>
<p>Esaminiamo più attentamente come si passa dalla forma originale del teorema di Bayes alla forma espressa in termini di odds. La forma originale del teorema di Bayes è:</p>
<div class="math notranslate nohighlight">
\[
P(H|D) = \frac{P(D|H) \times P(H)}{P(D)},
\]</div>
<p>dove:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( P(H|D) \)</span> è la probabilità a posteriori dell’ipotesi <span class="math notranslate nohighlight">\( H \)</span> dato il dato <span class="math notranslate nohighlight">\( D \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(D|H) \)</span> è la probabilità del dato <span class="math notranslate nohighlight">\( D \)</span> dato che l’ipotesi <span class="math notranslate nohighlight">\( H \)</span> è vera.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(H) \)</span> è la probabilità a priori dell’ipotesi <span class="math notranslate nohighlight">\( H \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( P(D) \)</span> è la probabilità totale del dato <span class="math notranslate nohighlight">\( D \)</span>.</p></li>
</ul>
<p>Gli odds a favore di un evento <span class="math notranslate nohighlight">\( A \)</span> si definiscono come il rapporto tra la probabilità che <span class="math notranslate nohighlight">\( A \)</span> si verifichi e la probabilità che <span class="math notranslate nohighlight">\( A \)</span> non si verifichi:</p>
<div class="math notranslate nohighlight">
\[
\text{Odds}(A) = \frac{P(A)}{P(\neg A)} = \frac{P(A)}{1 - P(A)}.
\]</div>
<p>Ora, possiamo esprimere la probabilità a posteriori <span class="math notranslate nohighlight">\( P(H|D) \)</span> in termini di odds. Utilizziamo la formula degli odds per ottenere:</p>
<div class="math notranslate nohighlight">
\[
\text{Odds}(H|D) = \frac{P(H|D)}{P(\neg H|D)} = \frac{P(H|D)}{1 - P(H|D)}.
\]</div>
<p>Sostituendo la forma originale del Teorema di Bayes per <span class="math notranslate nohighlight">\( P(H|D) \)</span> e per <span class="math notranslate nohighlight">\( P(\neg H|D) \)</span>, otteniamo:</p>
<div class="math notranslate nohighlight">
\[
\text{Odds}(H|D) = \frac{\frac{P(D|H) \times P(H)}{P(D)}}{\frac{P(D|\neg H) \times P(\neg H)}{P(D)}}.
\]</div>
<p>Nota che <span class="math notranslate nohighlight">\( P(D) \)</span> si semplifica:</p>
<div class="math notranslate nohighlight">
\[
\text{Odds}(H|D) = \frac{P(D|H) \times P(H)}{P(D|\neg H) \times P(\neg H)}.
\]</div>
<p>Ora, utilizziamo la formula degli odds per <span class="math notranslate nohighlight">\( P(H) \)</span> e <span class="math notranslate nohighlight">\( P(\neg H) \)</span>:</p>
<div class="math notranslate nohighlight">
\[
\text{Odds}(H) = \frac{P(H)}{P(\neg H)}.
\]</div>
<p>Sostituendo nella formula precedente, otteniamo:</p>
<div class="math notranslate nohighlight">
\[
\text{Odds}(H|D) = \text{Odds}(H) \times \frac{P(D|H)}{P(D|\neg H)}.
\]</div>
<p>Una volta ottenuta la versione precedente del teorema di Bayes espresso in termini di odds, facciamo un passo ulteriore, ovvero applichiamo il logaritmo:</p>
<div class="math notranslate nohighlight">
\[
\log \left( \text{Odds}(H | D) \right) = \log \left( \text{Odds}(H) \right) + 10 \log \left( \frac{P(D | H)}{P(D | \neg H)} \right).
\]</div>
<p>La forma logaritmica dell’equazione di Bayes è particolarmente istruttiva. Infati, se definiamo “evidenza” <span class="math notranslate nohighlight">\( J(H) \)</span> come indicato da Jaynes, possiamo scrivere:</p>
<div class="math notranslate nohighlight">
\[
J(H | D) = J(H) + 10 \log \left( \frac{P(D | H)}{P(D | \neg H)} \right).
\]</div>
<p>Quest’ultimo formalismo è potente per la sua linearità: l’aggiornamento dell’evidenza avviene semplicemente sommando o sottraendo il termine centrale dell’equazione.</p>
<p>Per visualizzare questi concetti, possiamo creare un grafico che mostri come le odds posteriori cambiano in risposta a diversi rapporti di verosimiglianza.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Valori di probabilità da 0 a 1</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="c1"># Calcolo delle log-odds</span>
<span class="n">log_odds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probabilities</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">probabilities</span><span class="p">))</span>

<span class="c1"># Calcolo dell&#39;evidenza di Jaynes J(H)</span>
<span class="c1"># Assumiamo un fattore di 10 per scalare il logaritmo, come nel formalismo di Jaynes</span>
<span class="n">evidence_jaynes</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">log_odds</span>

<span class="c1"># Creazione del grafico</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">evidence_jaynes</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Evidenza di Jaynes $J(H)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Probabilità $P(H)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Evidenza di Jaynes $J(H)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Evidenza di Jaynes in Funzione della Probabilità&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/322206d2c62a762103ed1ea8d887f50041775e43ce41e7560e3b106dbca26f7c.png" src="../_images/322206d2c62a762103ed1ea8d887f50041775e43ce41e7560e3b106dbca26f7c.png" />
</div>
</div>
<p>L’equazione di Jaynes ha alcune proprietà matematiche che la rendono particolarmente interessante per l’aggiornamento sequenziale delle credenze o delle evidenze. Ecco una spiegazione più dettagliata della linearità e della facilità di aggiornamento in questa forma.</p>
<p>Nella forma logaritmica del Teorema di Bayes:</p>
<div class="math notranslate nohighlight">
\[
\log \left( \text{Odds}(H | D) \right) = \log \left( \text{Odds}(H) \right) + 10 \log \left( \frac{P(D | H)}{P(D | \neg H)} \right)
\]</div>
<p>notiamo che l’aggiornamento delle credenze (o delle evidenze, se utilizziamo la notazione di Jaynes) avviene in maniera lineare. Questo è un vantaggio significativo perché la linearità semplifica notevolmente il calcolo quando si ha a che fare con una serie di evidenze o dati.</p>
<p>Supponiamo di avere una serie di dati indipendenti <span class="math notranslate nohighlight">\( D_1, D_2, \ldots, D_n \)</span>. In un modello Bayesiano, potremmo voler aggiornare le nostre credenze in modo sequenziale ogni volta che osserviamo un nuovo dato. Nella forma logaritmica, l’aggiornamento diventa semplicemente una somma di termini logaritmici:</p>
<div class="math notranslate nohighlight">
\[
\log \left( \text{Odds}(H | D_1, D_2, \ldots, D_n) \right) = \log \left( \text{Odds}(H) \right) + \sum_{i=1}^{n} 10 \log \left( \frac{P(D_i | H)}{P(D_i | \neg H)} \right).
\]</div>
<p>Questa forma è “modulare”, nel senso che ogni nuovo pezzo di evidenza contribuisce con un termine additivo al logaritmo degli odds a posteriori. Questo significa che non è necessario ricominciare da capo ogni volta che si ottiene un nuovo dato; è sufficiente aggiungere (o sottrarre, se l’evidenza è contraria all’ipotesi) il nuovo termine al totale esistente.</p>
<p>Nella notazione di Jaynes, il termine <span class="math notranslate nohighlight">\( 10 \log \left( \frac{P(D | H)}{P(D | \neg H)} \right) \)</span> rappresenta un “quantitativo di evidenza” a favore di <span class="math notranslate nohighlight">\( H \)</span> rispetto a <span class="math notranslate nohighlight">\( \neg H \)</span> fornito dal dato <span class="math notranslate nohighlight">\( D \)</span>. Maggiore è questo valore (in unità di decibel, se si utilizza il fattore 10), più il dato è informativo a favore dell’ipotesi <span class="math notranslate nohighlight">\( H \)</span>.</p>
<p>In sintesi, la forma logaritmica del Teorema di Bayes offre un modo lineare e modulare di aggiornare le credenze o le evidenze, rendendola particolarmente utile in applicazioni pratiche come il machine learning, la diagnosi medica e la psicologia sperimentale.</p>
<section id="esempio-numerico-diagnosi-di-disturbo-d-ansia-sociale-das">
<h3>Esempio Numerico: Diagnosi di Disturbo d’Ansia Sociale (DAS)<a class="headerlink" href="#esempio-numerico-diagnosi-di-disturbo-d-ansia-sociale-das" title="Permalink to this heading">#</a></h3>
<p>Supponiamo di essere un psicologo che utilizza un questionario per diagnosticare il Disturbo d’Ansia Sociale (DAS) in un campione di individui. Vogliamo utilizzare il Teorema di Bayes nella sua forma logaritmica per aggiornare le nostre credenze sulla presenza del DAS in un particolare individuo, basandoci su una serie di domande del questionario.</p>
<section id="informazioni-iniziali">
<h4>Informazioni Iniziali<a class="headerlink" href="#informazioni-iniziali" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Probabilità a priori di DAS</strong>: Supponiamo che la probabilità a priori che un individuo selezionato a caso abbia il DAS sia del 10%. Gli odds a priori saranno quindi <span class="math notranslate nohighlight">\( \frac{0.1}{0.9} \approx 0.1111 \)</span>.</p></li>
<li><p><strong>Domande del Questionario</strong>: Utilizziamo un questionario con tre domande rilevanti (D1, D2, D3), ognuna delle quali ha una probabilità di risposta “sì” data da <span class="math notranslate nohighlight">\( P(D_i \mid \text{DAS}) \)</span> e <span class="math notranslate nohighlight">\( P(D_i | \neg \text{DAS}) \)</span>.</p></li>
</ul>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Domanda</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\( P(D_i \mid \text{DAS}) \)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\( P(D_i \mid \neg \text{DAS}) \)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>D1</p></td>
<td><p>0.9</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>D2</p></td>
<td><p>0.8</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-even"><td><p>D3</p></td>
<td><p>0.85</p></td>
<td><p>0.25</p></td>
</tr>
</tbody>
</table>
</section>
<section id="calcolo-degli-odds-a-posteriori">
<h4>Calcolo degli Odds a Posteriori<a class="headerlink" href="#calcolo-degli-odds-a-posteriori" title="Permalink to this heading">#</a></h4>
<p>Per calcolare gli odds a posteriori utilizzando la formula logaritmica, utilizziamo:</p>
<div class="math notranslate nohighlight">
\[
\log \left( \text{Odds}(\text{DAS} \mid D_1, D_2, D_3) \right) = \log \left( \text{Odds}(\text{DAS}) \right) + 10 \log \left( \frac{P(D_1 \mid \text{DAS})}{P(D_1 \mid \neg \text{DAS})} \right) + 10 \log \left( \frac{P(D_2 \mid \text{DAS})}{P(D_2 \mid \neg \text{DAS})} \right) + 10 \log \left( \frac{P(D_3 \mid \text{DAS})}{P(D_3 \mid \neg \text{DAS})} \right)
\]</div>
<p>Calcoliamo.</p>
<p>Dopo aver effettuato i calcoli, otteniamo i seguenti risultati:</p>
<ul class="simple">
<li><p>Termine logaritmico per la domanda D1: <span class="math notranslate nohighlight">\(6.53\)</span></p></li>
<li><p>Termine logaritmico per la domanda D2: <span class="math notranslate nohighlight">\(4.26\)</span></p></li>
<li><p>Termine logaritmico per la domanda D3: <span class="math notranslate nohighlight">\(5.31\)</span></p></li>
</ul>
<p>La somma di questi termini logaritmici, sommata al logaritmo degli odds a priori (<span class="math notranslate nohighlight">\( \log_{10}(0.1111) \approx -0.96 \)</span>), ci dà un log-odds a posteriori di <span class="math notranslate nohighlight">\( 15.15 \)</span>.</p>
<p>Convertendo questo valore dalla forma logaritmica alla forma originale, otteniamo odds a posteriori di circa <span class="math notranslate nohighlight">\( 1.42 \times 10^{15} \)</span>.</p>
<p>Infine, convertiamo gli odds a posteriori in probabilità a posteriori, che risultano essere praticamente <span class="math notranslate nohighlight">\( 1 \)</span> (o <span class="math notranslate nohighlight">\( 100\% \)</span>).</p>
</section>
</section>
<section id="id2">
<h3>Interpretazione<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>In questo esempio, l’elevata probabilità a posteriori suggerisce fortemente che l’individuo in questione è affetto da DAS, date le risposte al questionario.</p>
<p>Ogni termine logaritmico aggiunto alla somma rappresenta un “quantitativo di evidenza” a favore della diagnosi di DAS. Ad esempio, il termine <span class="math notranslate nohighlight">\( 6.53 \)</span> per la domanda D1 indica che questa domanda è molto informativa nel sostenere l’ipotesi di DAS.</p>
<p>Inoltre, l’aggiornamento modulare degli odds in forma logaritmica ci ha permesso di incorporare facilmente nuove informazioni senza dover ricalcolare l’intera equazione.</p>
<p>Questo esempio illustra come la forma logaritmica del Teorema di Bayes possa essere utilizzata in un contesto psicologico per la diagnosi di disturbi mentali, facilitando l’aggiornamento sequenziale delle credenze in modo lineare e modulare.</p>
</section>
</section>
<section id="commenti-e-considerazioni-finali">
<h2>Commenti e considerazioni finali<a class="headerlink" href="#commenti-e-considerazioni-finali" title="Permalink to this heading">#</a></h2>
<p>La riflessione epistemologica contemporanea ha ribadito che la conoscenza non può essere vista come una certezza inconfutabile o una garanzia razionale di verità. Invece, essa emerge come una serie di decisioni prese all’interno di un contesto di incertezza. Questa comprensione è particolarmente pertinente nel campo della ricerca scientifica, dove né la logica deduttiva né le rigorose dimostrazioni matematiche sono sufficienti. Di conseguenza, la scienza necessita di una “logica dell’incertezza,” che è efficacemente fornita dalla teoria delle probabilità, e più specificamente, dal teorema di Bayes.</p>
<p>Il teorema di Bayes ci offre un framework per interpretare la probabilità come una valutazione soggettiva influenzata da diversi fattori condizionanti. In pratica, il teorema esprime la probabilità a posteriori <span class="math notranslate nohighlight">\( P(H_i \mid E) \)</span> come un risultato derivato dalla combinazione della probabilità a priori <span class="math notranslate nohighlight">\( P(H_i) \)</span> e della verosimiglianza <span class="math notranslate nohighlight">\( P(E \mid H_i) \)</span>. Questa formulazione sottolinea che la nostra valutazione probabilistica di una data ipotesi <span class="math notranslate nohighlight">\( H_i \)</span> è modulata sia dall’evidenza empirica <span class="math notranslate nohighlight">\( E \)</span> che dalle nostre credenze a priori <span class="math notranslate nohighlight">\( P(H_i) \)</span>.</p>
<p>Poiché la probabilità è una valutazione intrinsecamente soggettiva, è possibile che diversi osservatori arrivino a conclusioni differenti. Tuttavia, il teorema di Bayes fornisce un meccanismo razionale—conosciuto come “aggiornamento bayesiano”—per ricalibrare queste credenze in risposta a nuove informazioni o evidenze.</p>
<p>L’approccio bayesiano offre strumenti per valutare l’efficacia di diverse strategie di trattamento o interventi in psicologia clinica. Per esempio, se si afferma che la meditazione mattutina è efficace nel trattamento della depressione, è essenziale valutare questa affermazione nel contesto di tutte le evidenze disponibili, compresi i casi in cui la meditazione non ha portato a miglioramenti.</p>
<p>In sintesi, la metodologia bayesiana fornisce una cornice robusta per l’aggiornamento delle probabilità in presenza di nuove informazioni, offrendo spunti importanti sia per la ricerca che per la pratica clinica in psicologia.</p>
<p>Nel contesto di questo capitolo, abbiamo focalizzato la nostra discussione sul teorema di Bayes nel caso delle variabili casuali discrete. Tuttavia, nel prossimo capitolo, esploreremo come il teorema può essere applicato in modo più intuitivo alle variabili casuali continue. Per ulteriori dettagli, si rimanda al notebook <a class="reference internal" href="../chapter_4/01_intro_bayes.html#bayes-workflow-notebook"><span class="std std-ref">Modellazione bayesiana</span></a>.</p>
</section>
<section id="watermark">
<h2>Watermark<a class="headerlink" href="#watermark" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Thu Nov 09 2023

Python implementation: CPython
Python version       : 3.11.6
IPython version      : 8.16.1

pandas    : 2.1.1
arviz     : 0.16.1
numpy     : 1.25.2
matplotlib: 3.8.0

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="E_cond_prob.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">✏️ Esercizi</p>
      </div>
    </a>
    <a class="right-next"
       href="E_bayes_theorem.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">✏️ Esercizi</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretazione">Interpretazione</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alcuni-esempi">Alcuni esempi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inferire-il-genere-dalla-lunghezza-dei-capelli">Inferire il genere dalla lunghezza dei capelli</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mammografia-e-cancro-al-seno">Mammografia e cancro al seno</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-valore-predittivo-di-un-test-di-laboratorio">Il valore predittivo di un test di laboratorio</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-di-bayes-applicato-ai-dati-penguins">Teorema di Bayes applicato ai dati <code class="docutils literal notranslate"><span class="pre">penguins</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-delle-due-urne">Il problema delle due urne</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-problema-dei-dadi">Il problema dei dadi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#l-errore-dell-avvocato-difensore">L’errore dell’avvocato difensore</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-di-bayes-per-eventi-dicotomici">Teorema di Bayes per eventi dicotomici</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#esempio-numerico-diagnosi-di-disturbo-d-ansia-sociale-das">Esempio Numerico: Diagnosi di Disturbo d’Ansia Sociale (DAS)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#informazioni-iniziali">Informazioni Iniziali</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calcolo-degli-odds-a-posteriori">Calcolo degli Odds a Posteriori</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Interpretazione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>