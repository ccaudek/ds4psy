

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Monte Carlo a Catena di Markov &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-VMXNE4BCDL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-VMXNE4BCDL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_4/10_metropolis';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4psy/chapter_4/10_metropolis.html" />
    <link rel="shortcut icon" href="../_static/increasing.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Inferenza bayesiana con PyMC" href="11_beta_binomial_pymc.html" />
    <link rel="prev" title="L’influenza della distribuzione a priori" href="06_balance-prior-post.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Correlazione e causazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/07_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_3/introduction_chapter_3.html">Probabilità</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_cond_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04_expval_var.html">Variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04a_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/04b_illusion.html">Incertezza inferenziale e variabilità dei risultati</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/10_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_3/E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_part_4.html">Inferenza bayesiana</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_conjugate_families_1.html">Distribuzioni coniugate (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="11_beta_binomial_pymc.html">Inferenza bayesiana con PyMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="12_jax.html">Usare JAX per un campionamento più veloce</a></li>
<li class="toctree-l2"><a class="reference internal" href="13_preliz.html">Scegliere le distribuzioni a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="16_summary_posterior_pymc.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="17_prediction.html">La predizione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="18_mcmc_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="19_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="20_poisson_model.html">Modello di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="21_poisson_sim.html">Modello di Poisson: derivazione analitica e MCMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_freq.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="22_normal_normal_model.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_one_mean.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_one_mean_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="23_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="24_multiple_groups.html">Gruppi multipli</a></li>
<li class="toctree-l2"><a class="reference internal" href="30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="32_loo.html">Validazione Incrociata Leave-One-Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="40_hier_beta_binom.html">Modello gerarchico beta-binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="41_hier_poisson.html">Modello gerarchico di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="42_hier_gaussian.html">Modello gerarchico gaussiano</a></li>
<li class="toctree-l2"><a class="reference internal" href="hssm.html">Drift Diffusion Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_1.html">Il modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_2.html">Analisi bayesiana del modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_params_recovery.html">Analisi di simulazione per la stima dei parametri nel modello di regressione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_3.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_4.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_5.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_7.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_simpson.html">Paradosso di Simpson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_logistic_reg.html">Modello di regressione logistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_binomial_reg.html">Regressione binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_covid.html">Inferenza controfattuale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_counterfactual.html">Analisi causale con PyMC</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_stab.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_s_m_errors.html">Crisi della replicabilità</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_virtual_env.html">Ambiente virtuale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a52_reglin_2.html">Regressione lineare con Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a53_reglin_4.html">Posterior Predictive Checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4psy/blob/main/docs/chapter_4/10_metropolis.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_4/10_metropolis.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Monte Carlo a Catena di Markov</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-denominatore-bayesiano">Il denominatore bayesiano</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-di-markov-monte-carlo">Catene di Markov Monte Carlo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-metodo-di-monte-carlo">Il Metodo di Monte Carlo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#le-catene-di-markov">Le Catene di Markov</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estrazione-di-campioni-dalla-distribuzione-a-posteriori">Estrazione di campioni dalla distribuzione a posteriori</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-con-distribuzione-target-nota">Simulazione con distribuzione target nota</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis">Algoritmo di Metropolis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#passaggi-fondamentali-dell-algoritmo-di-metropolis">Passaggi Fondamentali dell’Algoritmo di Metropolis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintassi-della-funzione">Sintassi della funzione</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri">Parametri</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#valore-di-ritorno">Valore di ritorno</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dettagli-dell-algoritmo">Dettagli dell’algoritmo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-nota">Algoritmo di Metropolis con distribuzione target nota</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-incognita">Algoritmo di Metropolis con distribuzione target incognita</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aspetti-computazionali">Aspetti computazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warm-up-burn-in">Warm-up/Burn-in</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintesi-della-distribuzione-a-posteriori">Sintesi della distribuzione a posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diagnostiche-della-soluzione-mcmc">Diagnostiche della soluzione MCMC</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-multiple">Catene multiple</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#stazionarieta">Stazionarietà</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#autocorrelazione">Autocorrelazione</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tasso-di-accettazione">Tasso di accettazione</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-di-convergenza">Test di convergenza</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#effective-sample-size-ess">Effective sample size (ESS)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/github/ccaudek/ds4psy_2023/blob/main/325_metropolis.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="monte-carlo-a-catena-di-markov">
<span id="metropolis-notebook"></span><h1>Monte Carlo a Catena di Markov<a class="headerlink" href="#monte-carlo-a-catena-di-markov" title="Permalink to this heading">#</a></h1>
<p>In precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana relativi alla distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche discusso l’utilizzo di approcci come l’approssimazione tramite griglia e i metodi dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione e spiegheremo perché sono necessari approcci speciali noti come metodi di Monte Carlo a Catena di Markov (MCMC).</p>
<section id="preparazione-del-notebook">
<h2>Preparazione del Notebook<a class="headerlink" href="#preparazione-del-notebook" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.graphics</span> <span class="kn">import</span> <span class="n">tsaplots</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">Warning</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">palette</span><span class="o">=</span><span class="s2">&quot;colorblind&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="il-denominatore-bayesiano">
<h2>Il denominatore bayesiano<a class="headerlink" href="#il-denominatore-bayesiano" title="Permalink to this heading">#</a></h2>
<p>Nel campo dell’approccio bayesiano, il nostro obiettivo primario si concentra sulla determinazione della distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span> di un parametro <span class="math notranslate nohighlight">\(\theta\)</span> (nel caso più semplice), utilizzando come base sia i dati osservati <span class="math notranslate nohighlight">\(y\)</span> che la distribuzione a priori <span class="math notranslate nohighlight">\(p(\theta)\)</span>. Questo processo si avvale del teorema di Bayes per calcolare tale distribuzione.</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{p(y)}.
\]</div>
<p>Tuttavia, ci imbattiamo spesso in una sfida significativa: il calcolo dell’evidenza <span class="math notranslate nohighlight">\(p(y)\)</span> può rivelarsi estremamente complesso, specialmente per modelli più articolati, rendendo difficile ottenere con precisione la distribuzione a posteriori.</p>
<p>Una soluzione possibile si trova nelle distribuzioni a priori coniugate, che offrono un metodo analitico per determinare la distribuzione a posteriori. Questo però limita la selezione delle distribuzioni a priori e di verosimiglianza. Per superare questa limitazione, soprattutto in modelli dove i metodi di campionamento a griglia non sono applicabili, si utilizzano i Metodi di Catena di Markov a Monte Carlo (MCMC). Questi metodi rappresentano una potente alternativa, consentendo di derivare la distribuzione a posteriori basandosi su presupposti teorici e senza restrizioni nella scelta delle distribuzioni.</p>
<p>L’approccio Monte Carlo si basa sulla generazione di sequenze di numeri casuali per creare un campione ampio di osservazioni proveniente dalla distribuzione a posteriori. Da questi campioni, possiamo poi stimare empiricamente le proprietà di interesse. Questo approccio richiede l’uso di metodi computazionalmente intensivi, e con la crescente potenza di calcolo dei computer moderni, tali metodi stanno diventando sempre più accessibili e popolari nell’analisi dei dati.</p>
</section>
<section id="catene-di-markov-monte-carlo">
<h2>Catene di Markov Monte Carlo<a class="headerlink" href="#catene-di-markov-monte-carlo" title="Permalink to this heading">#</a></h2>
<p>Nei capitoli precedenti abbiamo già esplorato l’efficacia della simulazione nel campo della teoria delle probabilità. Un esempio classico è il problema di Monty Hall, che mostra come la simulazione ripetuta possa fornire stime affidabili per la media e la varianza di variabili casuali. Inoltre, applicando la legge dei grandi numeri, queste stime diventano più accurate all’aumentare del numero di simulazioni. Ciò evidenzia la potenza dei metodi Monte Carlo, che evitano la necessità di calcolare somme o integrali complessi.</p>
<section id="il-metodo-di-monte-carlo">
<h3>Il Metodo di Monte Carlo<a class="headerlink" href="#il-metodo-di-monte-carlo" title="Permalink to this heading">#</a></h3>
<p>Il Metodo di Monte Carlo, sviluppato durante il Progetto Manhattan negli anni ‘40, utilizza numeri casuali per risolvere problemi matematici complessi. Originariamente ideato da Stanislaw Ulam e successivamente implementato da John von Neumann, il metodo prende il nome dallo zio giocatore d’azzardo di Ulam, come suggerito da Nicholas Metropolis. Da allora, questo metodo è diventato una tecnica fondamentale in diverse discipline, contribuendo significativamente alla risoluzione di problemi complessi.</p>
<p>La metodologia di Monte Carlo genera un’ampia serie di punti casuali per stimare quantità di interesse, come l’integrazione numerica. Un esempio classico è l’approssimazione dell’integrale di un cerchio in 2D, dove il rapporto tra il numero di punti che cadono all’interno del cerchio e tutti i campioni fornisce un’approssimazione dell’area (per un esempio numerico, si veda <a class="reference internal" href="../chapter_7/a44_montecarlo.html#appendix-montecarlo"><span class="std std-ref">Simulazione Monte Carlo</span></a>).</p>
<p>Per illustrare ulteriormente questo concetto, consideriamo ora una distribuzione continua <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span> con una media <span class="math notranslate nohighlight">\(\mu\)</span>. Se siamo in grado di generare una sequenza di campioni casuali <span class="math notranslate nohighlight">\(\theta^{(1)}, \theta^{(2)}, \dots, \theta^{(T)}\)</span> indipendenti e identicamente distribuiti secondo <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span>, possiamo stimare il valore atteso teorico di <span class="math notranslate nohighlight">\(\theta\)</span> utilizzando la media campionaria <span class="math notranslate nohighlight">\(\frac{1}{T} \sum_{i=1}^T \theta^{(t)}\)</span>. Questa approssimazione diventa sempre più accurata man mano che aumenta il numero di campioni $T, grazie alla Legge Forte dei Grandi Numeri.</p>
<p>Un altro vantaggio del Metodo di Monte Carlo è la sua capacità di approssimare la probabilità che una variabile casuale <span class="math notranslate nohighlight">\(\theta\)</span> cada all’interno di un intervallo specifico <span class="math notranslate nohighlight">\((l, u)\)</span>. Questo può essere ottenuto calcolando la media campionaria della funzione indicatrice <span class="math notranslate nohighlight">\(I(l &lt; \theta &lt; u)\)</span> per ogni realizzazione <span class="math notranslate nohighlight">\(\theta^{(t)}\)</span>, cioè <span class="math notranslate nohighlight">\(Pr(l &lt; \theta &lt; u) \approx \frac{\text{numero di realizzazioni } \theta^{(t)} \in (l, u)}{T}\)</span>.</p>
<p>Nonostante la loro efficacia, un limite dei metodi Monte Carlo tradizionali risiede nella generazione efficiente di un elevato numero di campioni <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span>. In risposta a questa sfida, i metodi di Monte Carlo basati su catene di Markov (MCMC) offrono una soluzione potente per simulare da distribuzioni complesse attraverso catene di Markov. L’evoluzione di questi algoritmi ha trasformato radicalmente la statistica e il calcolo scientifico, permettendo la simulazione da una vasta gamma di distribuzioni, anche in spazi di alta dimensionalità.</p>
</section>
<section id="le-catene-di-markov">
<h3>Le Catene di Markov<a class="headerlink" href="#le-catene-di-markov" title="Permalink to this heading">#</a></h3>
<p>Le catene di Markov, ideate da Andrey Markov nel 1906, rappresentano un tentativo di estendere la legge dei grandi numeri a contesti in cui le variabili casuali non sono indipendenti. Tradizionalmente, la statistica si concentra su sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), simboleggiate come <span class="math notranslate nohighlight">\(X_0, X_1, \ldots, X_n, \ldots\)</span>. In tali sequenze, ogni variabile è indipendente dalle altre e segue la stessa distribuzione, con <span class="math notranslate nohighlight">\(n\)</span> che rappresenta un indice temporale discreto. Tuttavia, questa assunzione di indipendenza non è sempre realistica nei modelli di fenomeni complessi, portando alla necessità di esplorare forme alternative di dipendenza tra variabili.</p>
<p>Per superare le limitazioni dell’indipendenza, le catene di Markov introducono una cosiddetta “dipendenza a un passo”, incarnata nella “proprietà di Markov”. Questa proprietà stabilisce che la previsione di un evento futuro <span class="math notranslate nohighlight">\(X_{n+1}\)</span> dipende unicamente dall’evento immediatamente precedente <span class="math notranslate nohighlight">\(X_n\)</span>, indipendentemente dagli eventi passati <span class="math notranslate nohighlight">\(X_0, X_1, X_2, \ldots, X_{n-1}\)</span>. La proprietà di Markov è espressa matematicamente come:</p>
<div class="math notranslate nohighlight">
\[
P(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).
\]</div>
<p>Questa proprietà afferma che la previsione di un evento futuro dipende solo dall’evento immediatamente precedente, semplificando i calcoli relativi alle probabilità condizionali.</p>
<p>Le catene di Markov rappresentano un framework fondamentale per la modellazione delle dipendenze tra variabili casuali, una nozione cruciale in numerosi campi della statistica e della scienza dei dati, inclusa la metodologia MCMC (Markov Chain Monte Carlo). In particolare, nell’ambito dell’analisi bayesiana, l’uso di MCMC si rivela di estrema importanza, soprattutto quando non è possibile calcolare in modo analitico la distribuzione a posteriori.</p>
<p>L’algoritmo di Metropolis rappresenta una delle implementazioni più semplici del metodo MCMC. Questo algoritmo sfrutta la natura dipendente delle catene di Markov per navigare in modo efficace attraverso lo spazio della distribuzione a posteriori. Questo aspetto rende il MCMC uno strumento di grande potenza per affrontare problemi complessi in cui i metodi analitici tradizionali non possono essere applicati (per ulteriori dettagli, si veda <a class="reference internal" href="../chapter_7/a45_mcmc.html#appendix-markov"><span class="std std-ref">Catene di Markov</span></a>). In breve, il MCMC consente di generare un vasto insieme di valori per il parametro <span class="math notranslate nohighlight">\(\theta\)</span>. Idealmente, questi valori riflettono la distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span> quando questa non può essere ottenuta direttamente. Questa caratteristica rende il MCMC uno strumento essenziale per risolvere problemi complessi in cui i metodi analitici convenzionali non sono applicabili.</p>
</section>
</section>
<section id="estrazione-di-campioni-dalla-distribuzione-a-posteriori">
<h2>Estrazione di campioni dalla distribuzione a posteriori<a class="headerlink" href="#estrazione-di-campioni-dalla-distribuzione-a-posteriori" title="Permalink to this heading">#</a></h2>
<p>Nella discussione seguente ci porremo l’obiettivo di comprendere come utilizzare l’algoritmo di Metropolis per approssimare la distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span>. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.</p>
<ul class="simple">
<li><p>Inizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.</p></li>
<li><p>In seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per raggiungere lo stesso scopo—l’approssimazione della distribuzione a posteriori—mantenendo la presupposizione che la distribuzione target sia già nota.</p></li>
<li><p>Concluderemo il capitolo esplorando le modalità con cui l’algoritmo di Metropolis può essere adattato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.</p></li>
</ul>
<p>A titolo esemplificativo, utilizzeremo il dataset <code class="docutils literal notranslate"><span class="pre">moma_sample.csv</span></code>, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.</p>
<p>Il nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come <span class="math notranslate nohighlight">\(\pi\)</span>. Iniziamo importando i dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">moma_sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/moma_sample.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Esaminiamo le prime cinque righe del DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">moma_sample</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>country</th>
      <th>birth</th>
      <th>death</th>
      <th>alive</th>
      <th>genx</th>
      <th>gender</th>
      <th>count</th>
      <th>year_acquired_min</th>
      <th>year_acquired_max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ad Gerritsen</td>
      <td>dutch</td>
      <td>1940</td>
      <td>2015.0</td>
      <td>False</td>
      <td>False</td>
      <td>male</td>
      <td>1</td>
      <td>1981</td>
      <td>1981</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Kirstine Roepstorff</td>
      <td>danish</td>
      <td>1972</td>
      <td>NaN</td>
      <td>True</td>
      <td>True</td>
      <td>female</td>
      <td>3</td>
      <td>2005</td>
      <td>2005</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa Baumgardner</td>
      <td>american</td>
      <td>1958</td>
      <td>2015.0</td>
      <td>False</td>
      <td>False</td>
      <td>female</td>
      <td>2</td>
      <td>2016</td>
      <td>2016</td>
    </tr>
    <tr>
      <th>3</th>
      <td>David Bates</td>
      <td>american</td>
      <td>1952</td>
      <td>NaN</td>
      <td>True</td>
      <td>False</td>
      <td>male</td>
      <td>1</td>
      <td>2001</td>
      <td>2001</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Simon Levy</td>
      <td>american</td>
      <td>1946</td>
      <td>NaN</td>
      <td>True</td>
      <td>False</td>
      <td>male</td>
      <td>1</td>
      <td>2012</td>
      <td>2012</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Dai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">moma_sample</span><span class="p">[</span><span class="s2">&quot;genx&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>genx
False    86
True     14
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Il valore campionato <span class="math notranslate nohighlight">\(y = 14\)</span> riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di <span class="math notranslate nohighlight">\(\theta\)</span> (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.</p>
<p>Possiamo interpretare i dati <span class="math notranslate nohighlight">\(y = 14\)</span> come l’esito di una variabile casuale Binomiale con parametri <span class="math notranslate nohighlight">\(N = 100\)</span> e <span class="math notranslate nohighlight">\(\theta\)</span> sconosciuto.</p>
<p>Supponiamo che le nostre credenze pregresse riguardo a <span class="math notranslate nohighlight">\(\theta\)</span> possano essere modellate attraverso una distribuzione Beta(4, 6).</p>
<p>Sfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare la distribuzione a posteriori esatta:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>Y ~ Binomiale(100, π)
θ = Beta(4, 6)
θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)
</pre></div>
</div>
<p>Nella figura successiva è rappresentata la distribuzione a posteriori del parametro <span class="math notranslate nohighlight">\(\theta\)</span>, insieme alla distribuzione a priori scelta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">prior_density</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">posterior_density</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_density</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prior: Beta(4, 6)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_density</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Posterior: Beta(18, 92)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Parameter Value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Prior and Posterior Densities&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/00a603a2c50a9b885aefb6fa1a1103e116e78342865414f221c057bb09234dad.png" src="../_images/00a603a2c50a9b885aefb6fa1a1103e116e78342865414f221c057bb09234dad.png" />
</div>
</div>
<p>Se vogliamo conoscere il valore della media a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span>, il risultato esatto è</p>
<div class="math notranslate nohighlight">
\[
\bar{\theta}_{post} = \frac{\alpha}{\alpha + \beta} = \frac{18}{18 + 92} \approx 0.1636.
\]</div>
<section id="simulazione-con-distribuzione-target-nota">
<h3>Simulazione con distribuzione target nota<a class="headerlink" href="#simulazione-con-distribuzione-target-nota" title="Permalink to this heading">#</a></h3>
<p>Usiamo ora una simulazione numerica per stimare la media a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span>. Conoscendo la forma della distribuzione a posteriori <span class="math notranslate nohighlight">\(Beta(18, 92)\)</span>, possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.</p>
<p>Se vogliamo ottenere un risultato approssimato con poche osservazioni (ad esempio, 10), possiamo procedere con la seguente simulazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18267015479897203 0.1640199299316822 0.16798630280416024 0.2502064453468693 0.18621441725894658 0.10683641141879015 0.15273141685072195 0.20257133407616038 0.20673876768515861 0.1782986343112751
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.17982738144827365
</pre></div>
</div>
</div>
</div>
<p>Tuttavia, con solo 10 campioni l’approssimazione potrebbe non essere molto accurata. Più aumentiamo il numero di campioni (cioè il numero di osservazioni casuali generate), più precisa sarà l’approssimazione. Aumentando il numero di campioni, ad esempio a 10000, otteniamo un risultato più preciso:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.16329415024193536
</pre></div>
</div>
</div>
</div>
<p>Quando il numero di campioni a posteriori diventa molto grande, la distribuzione campionaria <em>converge</em> alla densità della popolazione. Questo concetto si applica non solo alla media, ma anche ad altre statistiche descrittive, come la moda e la varianza.</p>
<p>È importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori <span class="math notranslate nohighlight">\(Beta(18, 92)\)</span>.</p>
<p>Tuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) = \frac{\mathrm{e}^{-(\theta - 1 / 2)^2} \theta^y (1 - \theta)^{n - y}} {\int_0^1 \mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}
\]</div>
<p>rende impossibile calcolare analiticamente la distribuzione a posteriori di <span class="math notranslate nohighlight">\(\theta\)</span>, precludendo quindi l’utilizzo diretto di Python per generare campioni casuali.</p>
<p>In queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori <em>senza richiedere la conoscenza della sua rappresentazione analitica</em>. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.</p>
</section>
</section>
<section id="algoritmo-di-metropolis">
<h2>Algoritmo di Metropolis<a class="headerlink" href="#algoritmo-di-metropolis" title="Permalink to this heading">#</a></h2>
<p>L’algoritmo di Metropolis è un metodo avanzato per il campionamento da distribuzioni probabilistiche complesse. Appartiene alla famiglia dei metodi Monte Carlo Markov Chain (MCMC) e combina strategie di campionamento Monte Carlo con catene di Markov per navigare nello spazio dei parametri in modo intelligente. Questo consente di ottenere campioni rappresentativi della distribuzione di interesse indipendentemente dal punto di partenza, riducendo il rischio di bias nei risultati.</p>
<section id="passaggi-fondamentali-dell-algoritmo-di-metropolis">
<h3>Passaggi Fondamentali dell’Algoritmo di Metropolis<a class="headerlink" href="#passaggi-fondamentali-dell-algoritmo-di-metropolis" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Inizio</strong>: Si parte da un valore iniziale casuale per le variabili di interesse.</p></li>
<li><p><strong>Generazione di Nuovi Punti</strong>: A ogni passo, si propone un nuovo valore (“salto”) basandosi su una distribuzione proposta, comunemente una distribuzione normale centrata sul punto corrente.</p></li>
<li><p><strong>Valutazione</strong>: Si calcola la probabilità associata al nuovo punto utilizzando la funzione di densità di probabilità (pdf) della distribuzione che si intende campionare.</p></li>
<li><p><strong>Decisione di Accettazione</strong>: Se il nuovo punto ha una probabilità maggiore rispetto al precedente (minore “energia”), lo si accetta. Questo favorisce la tendenza a spostarsi verso aree di maggiore probabilità.</p></li>
<li><p><strong>Accettazione Probabilistica</strong>: Se invece il nuovo punto presenta una probabilità minore, l’accettazione avviene comunque con una certa probabilità, determinata dal rapporto tra le probabilità del nuovo e del vecchio punto. Questo consente di evitare locali ottimalità e di esplorare più ampiamente lo spazio dei parametri.</p></li>
<li><p><strong>Raccolta dei Punti</strong>: I punti accettati vengono raccolti e costituiscono il campione dalla distribuzione desiderata.</p></li>
</ol>
<p>La procedura continua con l’iterazione dei passi dal 2 al 5, permettendo alla catena di campioni di convergere alla distribuzione target. Inizialmente, i campioni potrebbero non essere rappresentativi, ma dopo un sufficiente numero di iterazioni (il cosiddetto “burn-in”), la distribuzione dei punti accettati dovrebbe avvicinarsi a quella che si intende esplorare.</p>
<p>L’efficacia di questo algoritmo risiede nella sua capacità di bilanciare esplorazione ed esploitazione attraverso l’accettazione probabilistica dei punti proposti, consentendo di ottenere un campionamento rappresentativo della distribuzione di probabilità complessa in esame.</p>
<p>Per una visualizzazione del comportamento dell’algoritmo di Metropolis nell’esplorare lo spazio dei parametri, si può consultare <a class="reference external" href="https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/">questo post</a>. La distinzione tra i diversi metodi MCMC si basa principalmente sul tipo di distribuzione proposta e sul criterio di accettazione dei punti nel campionamento.</p>
<p>Per fornire un esempio pratico, ritorniamo al caso precedentemente discusso in cui la distribuzione a posteriori è una Beta(18, 92). Utilizzeremo l’algoritmo di Metropolis per generare campioni da questa distribuzione nota.</p>
<p>Iniziamo definendo la distribuzione da cui verranno proposti i nuovi campioni. In questo primo esempio, optiamo per la distribuzione proposta più semplice: una variazione minima, estratta da una distribuzione uniforme, che verrà aggiunta al valore del campione precedente.</p>
<p>Ora descriviamo l’implementazione dell’algoritmo di Metropolis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Proposal distribution</span>
<span class="k">def</span> <span class="nf">uniprop</span><span class="p">(</span><span class="n">xprev</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xprev</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="n">delta</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Metropolis algorithm </span>
<span class="k">def</span> <span class="nf">metropolis_v1</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">qdraw</span><span class="p">,</span> <span class="n">nsamp</span><span class="p">,</span> <span class="n">xinit</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements the Metropolis algorithm for MCMC sampling.</span>

<span class="sd">    The function generates `nsamp` samples from a target distribution `p` using </span>
<span class="sd">    the Metropolis algorithm. The algorithm starts with an initial state `xinit` </span>
<span class="sd">    and iteratively applies a proposal mechanism governed by `qdraw` to explore </span>
<span class="sd">    the target distribution.</span>

<span class="sd">    Args:</span>
<span class="sd">        p (callable): A function representing the target distribution to sample from.</span>
<span class="sd">                     Should accept a float or array-like and return the density </span>
<span class="sd">                     (unnormalized is okay) at that point.</span>
<span class="sd">                     </span>
<span class="sd">        qdraw (callable): A function implementing the proposal mechanism. </span>
<span class="sd">                          Takes the current state (float or array-like) as input </span>
<span class="sd">                          and returns a proposed next state.</span>
<span class="sd">                          </span>
<span class="sd">        nsamp (int): The number of samples to draw from the target distribution.</span>
<span class="sd">        </span>
<span class="sd">        xinit (float or array-like): The initial state for the MCMC chain.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: An array of shape (nsamp,) containing samples drawn from the </span>
<span class="sd">        target distribution `p`.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">        &gt;&gt;&gt; target = stats.norm().pdf  # Standard Normal as target</span>
<span class="sd">        &gt;&gt;&gt; qdraw = lambda x: x + np.random.normal(0, 1)  # Random-walk Metropolis</span>
<span class="sd">        &gt;&gt;&gt; samples = metropolis_v1(target, qdraw, 10000, 0.0)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nsamp</span><span class="p">)</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">xinit</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamp</span><span class="p">):</span>
        <span class="n">x_star</span> <span class="o">=</span> <span class="n">qdraw</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
        <span class="n">p_star</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
        <span class="n">p_prev</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
        <span class="n">pdfratio</span> <span class="o">=</span> <span class="n">p_star</span> <span class="o">/</span> <span class="n">p_prev</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pdfratio</span><span class="p">):</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_star</span>
            <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>
    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="sintassi-della-funzione">
<h3>Sintassi della funzione<a class="headerlink" href="#sintassi-della-funzione" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">metropolis_v1</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">qdraw</span><span class="p">,</span> <span class="n">nsamp</span><span class="p">,</span> <span class="n">xinit</span><span class="p">):</span>
</pre></div>
</div>
<section id="parametri">
<h4>Parametri<a class="headerlink" href="#parametri" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">p</span></code>: Questa è la distribuzione target da cui si desidera campionare. È fornita come una funzione invocabile che prende un valore <code class="docutils literal notranslate"><span class="pre">x</span></code> e restituisce la densità di probabilità (o massa) in quel punto. La distribuzione target potrebbe anche non essere normalizzata.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">qdraw</span></code>: Questa è la distribuzione proposta da cui viene generato un possibile stato successivo (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>), dato lo stato corrente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>). Anche questa è una funzione invocabile, che dovrebbe restituire una nuova proposta basata sullo stato corrente.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nsamp</span></code>: Questo è il numero di campioni che si desidera generare dalla distribuzione target. Determina quante iterazioni verranno eseguite dall’algoritmo.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">xinit</span></code>: Questo è lo stato iniziale della catena di Markov. L’algoritmo partirà da questo punto.</p></li>
</ol>
</section>
<section id="valore-di-ritorno">
<h4>Valore di ritorno<a class="headerlink" href="#valore-di-ritorno" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>La funzione restituisce un array (<code class="docutils literal notranslate"><span class="pre">samples</span></code>) di dimensione <code class="docutils literal notranslate"><span class="pre">nsamp</span></code>, contenente i campioni estratti dalla distribuzione target.</p></li>
</ul>
</section>
</section>
<section id="dettagli-dell-algoritmo">
<h3>Dettagli dell’algoritmo<a class="headerlink" href="#dettagli-dell-algoritmo" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Inizializzazione</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nsamp</span><span class="p">)</span>
<span class="n">x_prev</span> <span class="o">=</span> <span class="n">xinit</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">samples</span></code>: Un array NumPy vuoto che sarà popolato con i campioni generati dall’algoritmo.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x_prev</span></code>: Lo stato corrente della catena di Markov. Inizializzato a <code class="docutils literal notranslate"><span class="pre">xinit</span></code>. Iniziamo dunque con un punto arbitrario nello spazio dei parametri. Questo primo valore della catena di Markov può essere scelto casualmente tra i valori possibili del parametro.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Il ciclo</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamp</span><span class="p">):</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Si itera <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> volte per generare <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> campioni.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p><strong>Fase di proposta</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_star</span> <span class="o">=</span> <span class="n">qdraw</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Un nuovo stato (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) viene proposto sulla base dello stato corrente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>) utilizzando la funzione di distribuzione proposta <code class="docutils literal notranslate"><span class="pre">qdraw</span></code>.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p><strong>Calcolo della densità</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">p_star</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
<span class="n">p_prev</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Calcola le densità dei punti proposti (<code class="docutils literal notranslate"><span class="pre">x_star</span></code>) e correnti (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>) utilizzando la funzione di distribuzione target <code class="docutils literal notranslate"><span class="pre">p</span></code>.</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p><strong>Rapporto tra densità</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pdfratio</span> <span class="o">=</span> <span class="n">p_star</span> <span class="o">/</span> <span class="n">p_prev</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Viene calcolato il rapporto tra le densità (<code class="docutils literal notranslate"><span class="pre">p_star</span> <span class="pre">/</span> <span class="pre">p_prev</span></code>). Questo rapporto decide se accettare o meno lo stato proposto.</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p><strong>Fase di accettazione</strong>:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pdfratio</span><span class="p">):</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_star</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Viene estratto un numero casuale dalla distribuzione uniforme tra 0 e 1.</p></li>
<li><p>Se questo numero è minore del minimo tra 1 e <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>, lo stato proposto viene accettato e <code class="docutils literal notranslate"><span class="pre">x_prev</span></code> viene aggiornato a <code class="docutils literal notranslate"><span class="pre">x_star</span></code>.</p></li>
<li><p>Altrimenti, lo stato proposto viene respinto e lo stato corrente (<code class="docutils literal notranslate"><span class="pre">x_prev</span></code>) viene mantenuto per il ciclo successivo.</p></li>
</ul>
<p>In sintesi, la decisione di accettare o rifiutare il parametro proposto <code class="docutils literal notranslate"><span class="pre">x_star</span></code> si basa sul valore di <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>. Se <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> è maggiore di 1, ciò indica che il parametro proposto è più probabile del parametro corrente <code class="docutils literal notranslate"><span class="pre">x_prev</span></code>; di conseguenza, <code class="docutils literal notranslate"><span class="pre">x_star</span></code> viene sempre accettato. Se, invece, <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> è minore di 1, il parametro proposto viene accettato con una probabilità che è proporzionale a <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> stesso. Per esempio, un <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> di 0.10 implica una probabilità del 10% di accettare <code class="docutils literal notranslate"><span class="pre">x_star</span></code>.</p>
<p>Questa strategia di accettazione ci consente di generare campioni che sono statisticamente rappresentativi della distribuzione target. Questo perché la probabilità di accettare un candidato è direttamente proporzionale alla sua densità della distribuzione che stiamo cercando di campionare.</p>
<p>Nella pratica, questo processo decisionale viene implementato confrontando <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> con un numero casuale <span class="math notranslate nohighlight">\(u\)</span>, estratto da una distribuzione uniforme <span class="math notranslate nohighlight">\(Unif(0, 1)\)</span>. Se <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> <span class="math notranslate nohighlight">\(&gt; u\)</span>, il parametro proposto <code class="docutils literal notranslate"><span class="pre">x_star</span></code> viene accettato, e la catena di Markov si sposta verso questo nuovo valore. In caso contrario, il valore corrente <code class="docutils literal notranslate"><span class="pre">x_prev</span></code> viene mantenuto come prossimo elemento nella catena.</p>
</section>
<section id="algoritmo-di-metropolis-con-distribuzione-target-nota">
<h3>Algoritmo di Metropolis con distribuzione target nota<a class="headerlink" href="#algoritmo-di-metropolis-con-distribuzione-target-nota" title="Permalink to this heading">#</a></h3>
<p>Applichiamo ora l’algoritmo di Metropolis usando una Beta(18, 92) quale distribuzione target e una distribuzione uniforme quale distribuzione proposta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialization</span>
<span class="n">init_state</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100000</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using Beta(18, 92) as the target distribution</span>
<span class="n">samps</span> <span class="o">=</span> <span class="n">metropolis_v1</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="n">uniprop</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">init_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>La ragione per cui è necessario scrivere <code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> anziché <code class="docutils literal notranslate"><span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> è che la funzione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code> si aspetta una funzione che può essere chiamata all’interno del codice di <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code>. Scrivere direttamente <code class="docutils literal notranslate"><span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> come argomento causerà un errore di sintassi perché <code class="docutils literal notranslate"><span class="pre">x</span></code> non è definito in quel contesto. La funzione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code> deve poter invocare <code class="docutils literal notranslate"><span class="pre">p</span></code> con differenti valori di <code class="docutils literal notranslate"><span class="pre">x</span></code> durante l’esecuzione. Quindi, ha bisogno di una “funzione” e non di un singolo valore. La funzione lambda <code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">stats.beta.pdf(x,</span> <span class="pre">18,</span> <span class="pre">92)</span></code> è invocabile: dato un <code class="docutils literal notranslate"><span class="pre">x</span></code>, restituirà il valore della PDF della distribuzione Beta in quel punto. Utilizzando la funzione lambda, fissiamo i parametri <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">18</span></code> e <code class="docutils literal notranslate"><span class="pre">beta</span> <span class="pre">=</span> <span class="pre">92</span></code> nella distribuzione Beta, rendendola una funzione di una sola variabile <code class="docutils literal notranslate"><span class="pre">x</span></code>, che è ciò che la funzione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code> richiede.</p>
<p>In sostanza, la funzione lambda serve come un “incapsulamento” o “avvolgimento” per la funzione <code class="docutils literal notranslate"><span class="pre">stats.beta.pdf</span></code>, restringendola a specifici parametri e rendendola invocabile con una sola variabile, che è esattamente ciò che l’algoritmo di Metropolis necessita.</p>
</div>
<p>Esaminiamo i primi 20 valori ottenuti.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.47520674 0.47520674 0.46375313 0.46375313 0.41846012 0.38742118
 0.38972628 0.37167961 0.37427573 0.37427573 0.37427573 0.36258821
 0.36258821 0.31991575 0.33295457 0.29987179 0.29987179 0.29987179
 0.29987179 0.30549992]
</pre></div>
</div>
</div>
</div>
<p>Generiamo ora un istogramma di tutti i 100000 campioni prodotti dall’algoritmo di Metropolis, a cui sovrapponiamo la densità Beta(18, 92).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MCMC distribution&quot;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e155b1e408d01d48de896ce9aff9f98b74fcb0c7f5c761710e527dcfe7332173.png" src="../_images/e155b1e408d01d48de896ce9aff9f98b74fcb0c7f5c761710e527dcfe7332173.png" />
</div>
</div>
<p>Si noti che la procedura di Metropolis genera un insieme di campioni che approssima la distribuzione target desiderata. In altre parole, i campioni ottenuti seguono la distribuzione che stiamo cercando di esplorare, fornendo quindi un modo efficace per ottenere un campionamento casuale da questa distribuzione.</p>
<p>Ora esaminiamo una diversa funzione di proposta: una distribuzione gaussiana centrata attorno allo stato precedente, con una deviazione standard <span class="math notranslate nohighlight">\(\sigma\)</span>. In questo caso, ogni nuovo punto candidato <span class="math notranslate nohighlight">\(x^*\)</span> sarà estratto da una gaussiana con media uguale allo stato corrente <span class="math notranslate nohighlight">\(x_{\text{prev}}\)</span> e deviazione standard <span class="math notranslate nohighlight">\(\sigma\)</span>. Questo introduce un grado di esplorazione randomica attorno al punto attuale, permettendo all’algoritmo di navigare efficacemente nello spazio dei parametri. In pratica, questo significa che, se <span class="math notranslate nohighlight">\(\sigma\)</span> è piccola, il valore candidato <span class="math notranslate nohighlight">\(x^*\)</span> sarà simile al valore corrente <span class="math notranslate nohighlight">\(x_{\text{prev}}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Proposal distribution</span>
<span class="k">def</span> <span class="nf">gaussprop</span><span class="p">(</span><span class="n">xprev</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xprev</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Applichiamo nuovamente l’algorimo di Metropolis con questa nuova distribuzione proposta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samps</span> <span class="o">=</span> <span class="n">metropolis_v1</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="n">gaussprop</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">init_state</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.5        0.47147117 0.47147117 0.47147117 0.36838417 0.31689558
 0.2603292  0.2603292  0.25605986 0.25605986 0.08506906 0.08506906
 0.08506906 0.08506906 0.08506906 0.08506906 0.08506906 0.09847799
 0.23086581 0.20751506]
</pre></div>
</div>
</div>
</div>
<p>Otteniamo anche in questo caso un campione casuale dalla distribuzione target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MCMC distribution&quot;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b43c76706c165256fe9b72f85d6b226a14c497e514b672f9df6d9152567163d5.png" src="../_images/b43c76706c165256fe9b72f85d6b226a14c497e514b672f9df6d9152567163d5.png" />
</div>
</div>
</section>
<section id="algoritmo-di-metropolis-con-distribuzione-target-incognita">
<h3>Algoritmo di Metropolis con distribuzione target incognita<a class="headerlink" href="#algoritmo-di-metropolis-con-distribuzione-target-incognita" title="Permalink to this heading">#</a></h3>
<p>Ora andiamo oltre: invece di presupporre che la distribuzione target sia già nota, cosa che si verifica quando utilizziamo distribuzioni coniugate, nel contesto bayesiano la distribuzione target che vogliamo campionare è in realtà il prodotto non normalizzato della verosimiglianza e della distribuzione a priori.</p>
<p>Iniziamo quindi col definire la distribuzione a priori. In questo esempio, la distribuzione a priori è una distribuzione Beta(2, 10) che è stata scelta solo per motivi didattici e non ha alcuna motivazione ulteriore.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prior</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Definiamo la verosimiglianza. Il problema presente richiede una verosimiglianza binomiale.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mi">14</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>La distribuzione a posteriori non normalizzata è il prodotto della distribuzione a priori e della verosimiglianza. Si noti che, per il motivo spiegato prima, non è necessario normalizzare la distribuzione a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">likelihood</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Per la distribuzione proposta, faremo ricorso alla stessa funzione che abbiamo precedentemente definito. Tuttavia, apporteremo alcune modifiche all’algoritmo di Metropolis per adeguarlo a questo nuovo contesto.</p>
<p>Nell’implementazione di un algoritmo di Metropolis in ambito bayesiano, vi sono diversi aspetti da considerare attentamente. Ecco alcuni punti cruciali:</p>
<ol class="arabic simple">
<li><p><strong>Simmetria della Distribuzione Proposta</strong>: È fondamentale che la distribuzione proposta sia simmetrica. Questa è una condizione necessaria per il funzionamento dell’algoritmo di Metropolis, ma non per quello di Metropolis-Hastings.</p></li>
<li><p><strong>Valore Iniziale</strong>: Il valore iniziale scelto dovrebbe essere plausibile in base alla distribuzione a priori, in modo da facilitare la convergenza dell’algoritmo.</p></li>
<li><p><strong>Probabilità Zero</strong>: Nel caso in cui la verosimiglianza o il prior assumano un valore di zero, il rapporto tra le densità di probabilità (<code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>) all’interno dell’algoritmo di Metropolis risulterà indefinito. Pertanto, è importante garantire che il valore <code class="docutils literal notranslate"><span class="pre">x_star</span></code>, generato dalla distribuzione proposta, cada sempre entro i limiti del supporto sia del prior che della verosimiglianza.</p></li>
</ol>
<p>Di seguito è presentato il codice, rivisto in base a queste considerazioni.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">metropolis_v2</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">qdraw</span><span class="p">,</span> <span class="n">nsamp</span><span class="p">,</span> <span class="n">xinit</span><span class="p">):</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nsamp</span><span class="p">)</span>
    <span class="n">x_prev</span> <span class="o">=</span> <span class="n">xinit</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamp</span><span class="p">):</span>
        <span class="n">x_star</span> <span class="o">=</span> <span class="n">qdraw</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
        <span class="c1"># Check that x_star is within the support of the prior and likelihood</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x_star</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">p_star</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
            <span class="n">p_prev</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x_prev</span><span class="p">)</span>
            <span class="n">pdfratio</span> <span class="o">=</span> <span class="n">p_star</span> <span class="o">/</span> <span class="n">p_prev</span> <span class="k">if</span> <span class="n">p_prev</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pdfratio</span><span class="p">):</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_star</span>
                <span class="n">x_prev</span> <span class="o">=</span> <span class="n">x_star</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_prev</span>  <span class="c1"># reject automatically if outside support</span>
    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</div>
</div>
<p>Le due versioni dell’algoritmo di Metropolis, <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code> e <code class="docutils literal notranslate"><span class="pre">metropolis_v2</span></code>, sono simili nella loro struttura di base, ma presentano alcune differenze chiave che riguardano la gestione dei casi speciali:</p>
<ol class="arabic simple">
<li><p><strong>Controllo del supporto</strong>: Nella versione <code class="docutils literal notranslate"><span class="pre">metropolis_v2</span></code>, c’è un controllo esplicito che assicura che il valore proposto <code class="docutils literal notranslate"><span class="pre">x_star</span></code> cada all’interno del supporto della distribuzione priori e della verosimiglianza (<code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">x_star</span> <span class="pre">&lt;=</span> <span class="pre">1</span></code>). Se <code class="docutils literal notranslate"><span class="pre">x_star</span></code> è fuori dal supporto, viene automaticamente rifiutato e il campione precedente <code class="docutils literal notranslate"><span class="pre">x_prev</span></code> viene conservato. Questo controllo è assente nella versione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code>.</p></li>
<li><p><strong>Gestione delle probabilità zero</strong>: Nella versione <code class="docutils literal notranslate"><span class="pre">metropolis_v2</span></code>, viene effettuato un ulteriore controllo sulla probabilità precedente <code class="docutils literal notranslate"><span class="pre">p_prev</span></code>. Se <code class="docutils literal notranslate"><span class="pre">p_prev</span></code> è zero, <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code> viene impostato automaticamente a 1 (<code class="docutils literal notranslate"><span class="pre">pdfratio</span> <span class="pre">=</span> <span class="pre">p_star</span> <span class="pre">/</span> <span class="pre">p_prev</span> <span class="pre">if</span> <span class="pre">p_prev</span> <span class="pre">&gt;</span> <span class="pre">0</span> <span class="pre">else</span> <span class="pre">1</span></code>). Questo gestisce i casi in cui potrebbe verificarsi una divisione per zero. Nella versione <code class="docutils literal notranslate"><span class="pre">metropolis_v1</span></code>, non vi è un controllo simile, e una divisione per zero potrebbe portare a comportamenti indesiderati.</p></li>
</ol>
<p>In sintesi, <code class="docutils literal notranslate"><span class="pre">metropolis_v2</span></code> è una versione più robusta dell’algoritmo che tiene conto sia del supporto della distribuzione target sia di eventuali valori zero nella densità di probabilità.</p>
<p>Si osservi un punto importante: nel calcolo di <code class="docutils literal notranslate"><span class="pre">pdfratio</span></code>, il rapporto tra la densità a posteriori del parametro proposto <code class="docutils literal notranslate"><span class="pre">x_star</span></code> e quella del parametro corrente <code class="docutils literal notranslate"><span class="pre">x_prev</span></code>, la costante di normalizzazione si annulla grazie alla regola di Bayes. Questo lascia nel rapporto solamente le componenti relative alla verosimiglianza e alla distribuzione a priori, che sono entrambe facilmente calcolabili. Matematicamente, questo si esprime come:</p>
<div class="math notranslate nohighlight" id="equation-eq-ratio-metropolis">
<span class="eqno">(62)<a class="headerlink" href="#equation-eq-ratio-metropolis" title="Permalink to this equation">#</a></span>\[
\begin{equation}
\text{pdfratio} = \frac{p(\theta^* \mid y)}{p(\theta^{\text{prev}} \mid y)} = \frac{\frac{p(y \mid \theta^*) p(\theta^*)}{p(y)}}{\frac{p(y \mid \theta^{\text{prev}}) p(\theta^{\text{prev}})}{p(y)}}
= \frac{p(y \mid \theta^*) p(\theta^*)}{p(y \mid \theta^{\text{prev}}) p(\theta^{\text{prev}})}
\end{equation}
\]</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform Metropolis sampling</span>
<span class="n">samps</span> <span class="o">=</span> <span class="n">metropolis_v2</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">gaussprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">init_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In somma, l’algoritmo Metropolis accetta come input il numero <code class="docutils literal notranslate"><span class="pre">nsamp</span></code> di passi da simulare, la deviazione standard <span class="math notranslate nohighlight">\( \sigma \)</span> della distribuzione proposta (in questo esempio, la deviazione standard <span class="math notranslate nohighlight">\(\sigma\)</span> è stata scelta empiricamente in modo tale da ottenere un tasso di accettazione adeguato), e la densità a priori. Come output, l’algoritmo restituisce una catena di valori del parametro, specificamente la sequenza <span class="math notranslate nohighlight">\( \theta^{(1)}, \theta^{(2)}, \ldots, \theta^{\text{nsamp}} \)</span>. Uno degli aspetti cruciali per la riuscita dell’algoritmo è il raggiungimento della stazionarietà da parte della catena. In genere, i primi 1000-5000 valori vengono scartati in quanto rappresentano il periodo di “burn-in” della catena. Dopo un determinato numero di passi <span class="math notranslate nohighlight">\( k \)</span>, la catena converge e i valori diventano campioni effettivi dalla distribuzione a posteriori <span class="math notranslate nohighlight">\( p(\theta \mid y) \)</span>.</p>
<p>Il modello descritto è stato inizialmente proposto da Metropolis et al. nel 1953 <span id="id1">Metropolis <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id133" title="Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller. Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6):1087-1092, 1953.">MRR+53</a>]</span>. Hastings nel 1970 introdusse un’estensione nota come algoritmo Metropolis-Hastings <span id="id2">Hastings [<a class="reference internal" href="../references/bibliography.html#id132" title="W. Keith Hastings. Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1):97-109, 1970.">Has70</a>]</span>. Altre varianti includono il campionatore di Gibbs, introdotto da Geman e Geman nel 1984 <span id="id3">[<a class="reference internal" href="../references/bibliography.html#id131" title="Stuart Geman and Donald Geman. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6:721-741, 1984.">GG84</a>]</span>, l’Hamiltonian Monte Carlo <span id="id4">Duane <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id173" title="Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid monte carlo. Physics letters B, 195(2):216–222, 1987.">DKPR87</a>]</span>, e il No-U-Turn Sampler (NUTS) utilizzato in pacchetti come PyMC e Stan <span id="id5">Hoffman <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id172" title="Matthew D Hoffman, Andrew Gelman, and others. The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo. Journal of Machine Learning Research, 15(1):1593–1623, 2014.">HG+14</a>]</span>. Per un’analisi più dettagliata e intuitiva dell’algoritmo Metropolis, si rimanda a <span id="id6">Kruschke [<a class="reference internal" href="../references/bibliography.html#id136" title="John Kruschke. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press, 2014.">Kru14</a>]</span>.</p>
<p>Un elemento chiave da considerare nell’uso dell’algoritmo Metropolis è il tasso di accettazione, che è il rapporto tra il numero di valori del parametro proposti e il numero di quei valori che vengono effettivamente accettati. Un limite di questo algoritmo è la sua inefficienza relativa: rispetto alle sue varianti più moderne, l’algoritmo Metropolis tende ad essere meno efficiente.</p>
</section>
</section>
<section id="aspetti-computazionali">
<h2>Aspetti computazionali<a class="headerlink" href="#aspetti-computazionali" title="Permalink to this heading">#</a></h2>
<section id="warm-up-burn-in">
<h3>Warm-up/Burn-in<a class="headerlink" href="#warm-up-burn-in" title="Permalink to this heading">#</a></h3>
<p>Una catena di Markov ha bisogno di alcune iterazioni per raggiungere la distribuzione stazionaria. Queste iterazioni sono comunemente chiamate iterazioni di warm-up o burn-in (a seconda dell’algoritmo e del software utilizzato) e vengono di solito scartate. In molti programmi software, la prima metà delle iterazioni viene considerata come iterazioni di warm-up, quindi, nel caso presente, anche se abbiamo ottenuto 100000 iterazioni, ne utilizzeremo solo 50000.</p>
</section>
<section id="sintesi-della-distribuzione-a-posteriori">
<h3>Sintesi della distribuzione a posteriori<a class="headerlink" href="#sintesi-della-distribuzione-a-posteriori" title="Permalink to this heading">#</a></h3>
<p>L’array <code class="docutils literal notranslate"><span class="pre">samps</span></code> contiene 100000 valori di una catena di Markov. Escludiamo i primi 50000 valori considerati come burn-in e consideriamo i restanti 50000 valori come un campione casuale estratto dalla distribuzione a posteriori <span class="math notranslate nohighlight">\(p(\theta \mid y)\)</span>.</p>
<p>Mediante i valori della catena così ottenuta è facile trovare una stima a posteriori del parametro <span class="math notranslate nohighlight">\(\theta\)</span>. Per esempio, possiamo trovare la stima della media a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">burnin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">burnin</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>50000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.16370053382923697
</pre></div>
</div>
</div>
</div>
<p>Oppure possiamo stimare la deviazione standard della distribuzione a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.03525796985331454
</pre></div>
</div>
</div>
</div>
<p>Visualizziamo un <em>trace plot</em> dei valori della catena di Markov dopo il periodo di burn-in.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;theta&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/a0272201630fffce7bcf27bc1e495ec624cb51ccb8c30199e3b5a9bd785be66e.png" src="../_images/a0272201630fffce7bcf27bc1e495ec624cb51ccb8c30199e3b5a9bd785be66e.png" />
</div>
</div>
<p>Il trace plot indica che la catena inizia con un valore casuale per poi spostarsi rapidamente nell’area intorno a 0.16, che è l’area con alta densità a posteriori. Successivamente, oscilla intorno a quel valore per le iterazioni successive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samps</span><span class="p">[:</span><span class="mi">500</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;theta&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7796364833661aa7c7898a9271d5dd2d71c2f418ec6362dda440beeb78a4a9b5.png" src="../_images/7796364833661aa7c7898a9271d5dd2d71c2f418ec6362dda440beeb78a4a9b5.png" />
</div>
</div>
<p>L’istogramma mostrato di seguito, sul quale è stata sovrapposta la distribuzione a posteriori derivata analiticamente – specificamente una <span class="math notranslate nohighlight">\(\text{Beta}(25, 17)\)</span> – dimostra che la catena converge effettivamente alla distribuzione a posteriori desiderata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MCMC distribution&quot;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># plot the true function</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">92</span><span class="p">),</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ea01458336ebf4ee1d5af87dca2fe8404a1c9b1d30c8bdcd58a0f5bd8e4f259c.png" src="../_images/ea01458336ebf4ee1d5af87dca2fe8404a1c9b1d30c8bdcd58a0f5bd8e4f259c.png" />
</div>
</div>
<p>È possibile usare la funzione <code class="docutils literal notranslate"><span class="pre">summary</span></code> del pacchetto AriviZ per calolare l’intervallo di credibilità, ovvero l’intervallo che contiene la proporzione indicata dei valori estratti a caso dalla distribuzione a posteriori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:],</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;stats&quot;</span><span class="p">,</span> <span class="n">hdi_prob</span><span class="o">=</span><span class="mf">0.94</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>x</th>
      <td>0.16</td>
      <td>0.04</td>
      <td>0.1</td>
      <td>0.23</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Un KDE plot corrispondente all’istogramma precedente si può generare usando <code class="docutils literal notranslate"><span class="pre">az.plot_posterior()</span></code>. La curva  rappresenta l’intera distribuzione a posteriori e viene calcolata utilizzando la stima della densità del kernel (KDE) che serve a “lisciare” l’istogramma.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/23187f0dce7954c55181173a6bcec1ba2e21aca4d73cbd75d5c447134a794a94.png" src="../_images/23187f0dce7954c55181173a6bcec1ba2e21aca4d73cbd75d5c447134a794a94.png" />
</div>
</div>
<p>L’HDI è una scelta comune nelle statistiche bayesiane e valori arrotondati come 50% o 95% sono molto popolari. Ma ArviZ utilizza il 94% come valore predefinito. La ragione di questa scelta è che il 94% è vicino al valore ampiamente utilizzato del 95%, ma è anche diverso da questo, così da servire da “amichevole promemoria” che non c’è niente di speciale nella soglia del 5%. Idealmente sarebbe opportuno scegliere un valore che si adatti alle specifiche esigenze dell’analisi statistica che si sta svolgendo, o almeno riconoscere che si sta usando un valore arbitrario.</p>
</section>
<section id="diagnostiche-della-soluzione-mcmc">
<h3>Diagnostiche della soluzione MCMC<a class="headerlink" href="#diagnostiche-della-soluzione-mcmc" title="Permalink to this heading">#</a></h3>
<section id="catene-multiple">
<h4>Catene multiple<a class="headerlink" href="#catene-multiple" title="Permalink to this heading">#</a></h4>
<p>Poiché ciascuno stato in una catena di Markov dipende dagli stati precedenti, il valore o i valori iniziali possono influenzare i valori campionati. Una soluzione per verificare la sensibilità rispetto ai valori iniziali è utilizzare più catene, ognuna con diversi valori iniziali. Se più catene campionano la stessa distribuzione target, queste dovrebbero mescolarsi bene, ovvero intersecarsi l’una con l’altra in un trace plot.</p>
</section>
<section id="stazionarieta">
<h4>Stazionarietà<a class="headerlink" href="#stazionarieta" title="Permalink to this heading">#</a></h4>
<p>Un punto importante da verificare è se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta “mixing”.</p>
</section>
<section id="autocorrelazione">
<h4>Autocorrelazione<a class="headerlink" href="#autocorrelazione" title="Permalink to this heading">#</a></h4>
<p>Ogni passo nell’algoritmo MCMC è chiamato <em>iterazione</em>. I valori campionati sono dipendenti, il che significa che il valore all’iterazione <span class="math notranslate nohighlight">\(m\)</span> dipende dal valore all’iterazione <span class="math notranslate nohighlight">\(m-1\)</span>. Questa è una differenza importante rispetto alle funzioni che generano campioni casuali indipendenti, come <code class="docutils literal notranslate"><span class="pre">beta(25,</span> <span class="pre">17).rvs()</span></code>. I valori campionati formano una <em>catena di Markov</em>, il che significa che ciascun valore campionato è correlato con il valore precedente (ad esempio, se <span class="math notranslate nohighlight">\(\theta(m)\)</span> è grande, <span class="math notranslate nohighlight">\(\theta(m+1)\)</span> sarà anch’esso grande).</p>
<p>Informazioni sul “mixing” della catena di Markov sono fornite dall’autocorrelazione. L’autocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore <span class="math notranslate nohighlight">\(m\)</span>-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantità <span class="math notranslate nohighlight">\(k\)</span> (dove <span class="math notranslate nohighlight">\(k\)</span> è l’entità del ritardo) per verificare quanto si correli al variare di <span class="math notranslate nohighlight">\(k\)</span>. L’autocorrelazione di ordine 1 (<em>lag 1</em>) misura la correlazione tra valori successivi della catena di Markow (cioè, la correlazione tra <span class="math notranslate nohighlight">\(\theta^{(m)}\)</span> e <span class="math notranslate nohighlight">\(\theta^{(m-1)}\)</span>); l’autocorrelazione di ordine 2 (<em>lag 2</em>) misura la correlazione tra valori della catena di Markow separati da due “passi” (cioè, la correlazione tra <span class="math notranslate nohighlight">\(\theta^{(m)}\)</span> e <span class="math notranslate nohighlight">\(\theta^{(m-2)}\)</span>); e così via.</p>
<p>L’autocorrelazione di ordine <span class="math notranslate nohighlight">\(k\)</span> è data da <span class="math notranslate nohighlight">\(\rho_k\)</span> e può essere stimata come:</p>
<div class="math notranslate nohighlight" id="equation-eq-autocor">
<span class="eqno">(63)<a class="headerlink" href="#equation-eq-autocor" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align}
\rho_k &amp;= \frac{Cov(\theta_m, \theta_{m+k})}{Var(\theta_m)}\notag\\
&amp;= \frac{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})(\theta_{m-k} - \bar{\theta})}{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})^2} \qquad\text{con }\quad \bar{\theta} = \frac{1}{n}\sum_{m=1}^{n}\theta_m.
\end{align}
\end{split}\]</div>
<p>Per fare un esempio pratico, simuliamo dei dati autocorrelati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">22</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">47</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">51</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>22 24 25 25 28 29 34 37 40 44 51 48 47 50 51
</pre></div>
</div>
</div>
</div>
<p>L’autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">acf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 1.        ,  0.83174224,  0.65632458,  0.49105012,  0.27863962,
        0.03102625, -0.16527446, -0.30369928, -0.40095465, -0.45823389,
       -0.45047733, -0.36933174])
</pre></div>
</div>
</div>
</div>
<p>Nell’esempio, il vettore <code class="docutils literal notranslate"><span class="pre">x</span></code> è una sequenza temporale di 15 elementi. Il vettore <span class="math notranslate nohighlight">\(x'\)</span> include gli elementi con gli indici da 0 a 13 nella sequenza originaria, mentre il vettore <span class="math notranslate nohighlight">\(x''\)</span> include gli elementi 1:14. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici <span class="math notranslate nohighlight">\((0, 1)\)</span>, <span class="math notranslate nohighlight">\((1, 2), (2, 3), \dots (13, 14)\)</span> degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori <span class="math notranslate nohighlight">\(x'\)</span> e <span class="math notranslate nohighlight">\(x''\)</span> corrisponde all’autocorrelazione di ordine 1 della serie temporale.</p>
<p>Nell’output precedente</p>
<ul class="simple">
<li><p>0.83174224 è l’autocorrelazione di ordine 1 (lag = 1),</p></li>
<li><p>0.65632458 è l’autocorrelazione di ordine 2 (lag = 2),</p></li>
<li><p>0.49105012 è l’autocorrelazione di ordine 3 (lag = 3),</p></li>
<li><p>ecc.</p></li>
</ul>
<p>È possibile specificare il numero di ritardi (<em>lag</em>) da utilizzare con l’argomento <code class="docutils literal notranslate"><span class="pre">nlags</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">acf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nlags</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.        , 0.83174224, 0.65632458, 0.49105012, 0.27863962])
</pre></div>
</div>
</div>
</div>
<p>In Python possiamo creare un grafico della funzione di autocorrelazione (correlogramma) per una serie temporale usando la funzione <code class="docutils literal notranslate"><span class="pre">tsaplots.plot_acf()</span></code> dalla libreria <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fe40086037850224a29d6e7d5f324b39208d7861b5054c5113172dfa0179e4a9.png" src="../_images/fe40086037850224a29d6e7d5f324b39208d7861b5054c5113172dfa0179e4a9.png" />
</div>
</div>
<p>Per i dati dell’esempio in discussione otteniamo la situazione seguente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">:],</span> <span class="n">lags</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/92e9759f14ef28cc3afa754852209d9b652e6bfb534853b23486c04f62f963ae.png" src="../_images/92e9759f14ef28cc3afa754852209d9b652e6bfb534853b23486c04f62f963ae.png" />
</div>
</div>
<p>Il correlogramma è uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall’autocorrelazione <span class="math notranslate nohighlight">\(\rho_k\)</span> di una catena di Markov in funzione del ritardo <span class="math notranslate nohighlight">\(k\)</span> con cui l’autocorrelazione è calcolata: nel grafico ogni barretta verticale riporta il valore dell’autocorrelazione (sull’asse delle ordinate) in funzione del ritardo (sull’asse delle ascisse).</p>
<p>In situazioni ottimali l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per piccoli lag. Ciò indica che i valori della catena di Markov che si trovano a più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del “mixing” della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l’autocorrelazione è quella di assottigliare l’output immagazzinando solo ogni <span class="math notranslate nohighlight">\(m\)</span>-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di <em>thinning</em>.</p>
<p>Nel seguente correlogramma, analizziamo la medesima catena di Markov. Tuttavia, in questa occasione applichiamo un “thinning” (sottocampionamento) con un fattore di 5.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thin</span><span class="o">=</span><span class="mi">5</span>
<span class="n">sampsthin</span><span class="o">=</span><span class="n">samps</span><span class="p">[</span><span class="n">burnin</span><span class="p">::</span><span class="n">thin</span><span class="p">]</span>
<span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">sampsthin</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/483a58999b0629d0ce513f922eacd51ac6794ad2b2dafc11d367654a30fcc4a1.png" src="../_images/483a58999b0629d0ce513f922eacd51ac6794ad2b2dafc11d367654a30fcc4a1.png" />
</div>
</div>
<p>Si può notare come l’autocorrelazione diminuisce molto più rapidamente.</p>
</section>
<section id="tasso-di-accettazione">
<h4>Tasso di accettazione<a class="headerlink" href="#tasso-di-accettazione" title="Permalink to this heading">#</a></h4>
<p>Quando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.</p>
</section>
<section id="test-di-convergenza">
<h4>Test di convergenza<a class="headerlink" href="#test-di-convergenza" title="Permalink to this heading">#</a></h4>
<p>Un test di convergenza può essere svolto in maniera grafica mediante le tracce delle serie temporali (<em>trace plot</em>), cioè il grafico dei valori simulati rispetto al numero di iterazioni. Se la catena è in uno stato stazionario le tracce mostrano assenza di periodicità nel tempo e ampiezza costante, senza tendenze visibili o andamenti degni di nota.</p>
<p>Ci sono inoltre alcuni test che permettono di verificare la stazionarietà del campionatore dopo un dato punto. Uno è il test di Geweke che suddivide il campione, dopo aver rimosso un periodo di burn in, in due parti. Se la catena è in uno stato stazionario, le medie dei due campioni dovrebbero essere uguali. Un test modificato, chiamato Geweke z-score, utilizza un test <span class="math notranslate nohighlight">\(z\)</span> per confrontare i due subcampioni ed il risultante test statistico, se ad esempio è più alto di 2, indica che la media della serie sta ancora muovendosi da un punto ad un altro e quindi è necessario un periodo di burn-in più lungo.</p>
</section>
<section id="effective-sample-size-ess">
<h4>Effective sample size (ESS)<a class="headerlink" href="#effective-sample-size-ess" title="Permalink to this heading">#</a></h4>
<p>Quando le iterazioni sono dipendenti, ogni iterazione contiene informazioni sovrapposte con le iterazioni precedenti. In altre parole, quando si ottengono 500 campioni dipendenti dalla distribuzione a posteriori, questi contengono solo informazioni equivalenti a &lt; 500 campioni indipendenti. L’ESS (Effective Sample Size) quantifica la quantità effettiva di informazioni, quindi una catena con ESS = n conterrà approssimativamente la stessa quantità di informazioni di n campioni indipendenti. In generale, vogliamo che l’ESS sia almeno 400 per un’utilizzazione generale nel riassumere la distribuzione a posteriori.</p>
</section>
</section>
</section>
<section id="commenti-e-considerazioni-finali">
<h2>Commenti e considerazioni finali<a class="headerlink" href="#commenti-e-considerazioni-finali" title="Permalink to this heading">#</a></h2>
<p>In generale, la distribuzione a posteriori dei parametri di un modello statistico non può essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l’uso dei metodi MCMC, insieme all’incremento della potenza di calcolo dei computer, ha contribuito a rendere sempre più popolare il metodo dell’inferenza bayesiana che, in questo modo, può essere estesa a problemi di qualunque grado di complessità.</p>
</section>
<section id="watermark">
<h2>Watermark<a class="headerlink" href="#watermark" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Mon Jan 22 2024

Python implementation: CPython
Python version       : 3.11.7
IPython version      : 8.19.0

statsmodels: 0.14.1
matplotlib : 3.8.2
numpy      : 1.26.2
seaborn    : 0.13.0
pandas     : 2.1.4
arviz      : 0.17.0
scipy      : 1.11.4

Watermark: 2.4.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="06_balance-prior-post.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">L’influenza della distribuzione a priori</p>
      </div>
    </a>
    <a class="right-next"
       href="11_beta_binomial_pymc.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Inferenza bayesiana con PyMC</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#il-denominatore-bayesiano">Il denominatore bayesiano</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-di-markov-monte-carlo">Catene di Markov Monte Carlo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#il-metodo-di-monte-carlo">Il Metodo di Monte Carlo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#le-catene-di-markov">Le Catene di Markov</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estrazione-di-campioni-dalla-distribuzione-a-posteriori">Estrazione di campioni dalla distribuzione a posteriori</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulazione-con-distribuzione-target-nota">Simulazione con distribuzione target nota</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis">Algoritmo di Metropolis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#passaggi-fondamentali-dell-algoritmo-di-metropolis">Passaggi Fondamentali dell’Algoritmo di Metropolis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintassi-della-funzione">Sintassi della funzione</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#parametri">Parametri</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#valore-di-ritorno">Valore di ritorno</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dettagli-dell-algoritmo">Dettagli dell’algoritmo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-nota">Algoritmo di Metropolis con distribuzione target nota</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritmo-di-metropolis-con-distribuzione-target-incognita">Algoritmo di Metropolis con distribuzione target incognita</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aspetti-computazionali">Aspetti computazionali</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warm-up-burn-in">Warm-up/Burn-in</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sintesi-della-distribuzione-a-posteriori">Sintesi della distribuzione a posteriori</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diagnostiche-della-soluzione-mcmc">Diagnostiche della soluzione MCMC</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#catene-multiple">Catene multiple</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#stazionarieta">Stazionarietà</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#autocorrelazione">Autocorrelazione</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tasso-di-accettazione">Tasso di accettazione</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#test-di-convergenza">Test di convergenza</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#effective-sample-size-ess">Effective sample size (ESS)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>