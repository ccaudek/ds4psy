{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://colab.research.google.com/github/ccaudek/ds4psy_2023/blob/main/115_conditional_prob.ipynb\">![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)</a>\n",
    "\n",
    "(cond_prob_notebook)=\n",
    "# Probabilità condizionata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo capitolo esploreremo i seguenti concetti probabilistici:\n",
    "\n",
    "- La probabilità congiunta, ovvero la probabilità del verificarsi simultaneo di due eventi che appartengono allo stesso evento, anche se si verificano in momenti diversi. Ad esempio, potremmo essere interessati alla probabilità congiunta di estrarre una pallina rossa e una verde.\n",
    "- La probabilità marginale, ovvero la probabilità di un singolo evento indipendentemente da tutti gli altri eventi. Ad esempio, possiamo calcolare la probabilità marginale di estrarre una pallina verde da un'urna.\n",
    "- La probabilità condizionata, ovvero la probabilità di un evento dato il verificarsi di un altro evento. Ad esempio, se estraiamo una pallina verde da un'urna, possiamo chiederci quanto è grande la probabilità di estrarre una seconda pallina verde dalla stessa urna.\n",
    "\n",
    "Inoltre, esamineremo i principali teoremi associati alla probabilità condizionata.\n",
    "\n",
    "## Il paradosso di Monty Hall\n",
    "\n",
    "Il paradosso di Monty Hall è un esempio molto interessante di come nuove informazioni possano influenzare il risultato di un problema di probabilità condizionatamente alle informazioni acquisite. Questo famoso problema di teoria della probabilità è strettamente legato al celebre gioco televisivo americano \"Let's Make a Deal\" ed è stato reso famoso dal presentatore Monty Hall.\n",
    "\n",
    "![Monty Hall](../images/monty-hall.jpg)\n",
    "\n",
    "Il gioco coinvolge tre porte chiuse, dietro una delle quali si trova un'automobile e dietro le altre due si nasconde una capra ciascuna. Il concorrente sceglie inizialmente una delle tre porte senza aprirla. A questo punto, Monty Hall apre una delle due porte rimanenti, svelando una capra. A questo punto, Monty offre al concorrente la possibilità di cambiare la propria scelta iniziale, passando alla porta rimasta chiusa. Il paradosso sorge dal fatto che cambiare la propria scelta in questo momento migliora le probabilità del concorrente di vincere l'automobile, portandole da 1/3 a 2/3.\n",
    "\n",
    "Per dimostrare questo risultato sorprendente, possiamo creare una simulazione in Python in cui consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e uno in cui il concorrente cambia la sua scelta dopo che Monty Hall ha aperto una porta contenente una capra. Ripetiamo questi scenari migliaia di volte e confrontiamo i risultati. In questo modo, possiamo verificare empiricamente come il cambio della scelta aumenti le probabilità di vincere l'automobile.\n",
    "\n",
    "Di seguito viene presentato lo script di una simulazione che può essere utilizzata per risolvere il paradosso di Monty Hall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3355\n",
      "0.6645\n"
     ]
    }
   ],
   "source": [
    "porte = [\n",
    "    \"capra1\",\n",
    "    \"capra2\",\n",
    "    \"macchina\",\n",
    "]  # definisco il gioco, scelgo una porta a caso per n volte\n",
    "counter = 0\n",
    "contatore_cambio = 0\n",
    "n = 10000\n",
    "porta_vincente = \"macchina\"\n",
    "for i in range(n):\n",
    "    scelta_casuale = random.choice(porte)\n",
    "    porte_rimaste = [x for x in porte if x != scelta_casuale]\n",
    "    porta_rivelata = random.choice([x for x in porte_rimaste if x != porta_vincente])\n",
    "    porta_alternativa = [\n",
    "        x for x in porte if x != scelta_casuale and x != porta_rivelata\n",
    "    ]\n",
    "    if \"macchina\" in porta_alternativa:\n",
    "        contatore_cambio += 1\n",
    "    if scelta_casuale == \"macchina\":\n",
    "        counter += 1\n",
    "\n",
    "print(counter / n)  # quante volte vinco non cambiando porta\n",
    "print(contatore_cambio / n)  # quante volte vinco cambiando porta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo script Python è stato creato da un gruppo di studenti di Psicometria. Utilizzando una simulazione possiamo comprendere meglio il ragionamento alla base del paradosso di Monty Hall e apprezzare come nuove informazioni possano influenzare in modo significativo le probabilità degli eventi. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(sec-bayes-cancer)=\n",
    "## Probabilità condizionata su altri eventi \n",
    "\n",
    "La probabilità di un evento è sempre condizionata dal nostro stato di conoscenza. In base alle informazioni disponibili, attribuiamo a un evento una certa probabilità di verificarsi. Tuttavia, se il nostro stato di conoscenza cambia, la probabilità associata all'evento può cambiare di conseguenza.\n",
    "\n",
    "In realtà, tutte le probabilità possono essere considerate come probabilità condizionate, anche se l'evento condizionante non è sempre esplicitamente menzionato. Ciò significa che le probabilità sono sempre riferite ad un contesto specifico e dipendono dalle informazioni disponibili in quel contesto.\n",
    "\n",
    "Questo concetto ci porta a considerare le probabilità come una sorta di \"valutazione di plausibilità\" basata sulla nostra conoscenza attuale del sistema o del fenomeno in esame. A seconda delle nuove informazioni che otteniamo o dell'evoluzione del contesto, la nostra valutazione di plausibilità può cambiare, portando a una diversa attribuzione di probabilità agli eventi.\n",
    "\n",
    "```{admonition} Definizione\n",
    "Siano $A$ e $B$ due eventi definiti sullo spazio campione $S$. Supponiamo di sapere che l'evento $B$ si è verificato. Si chiama *probabilità condizionata* di $A$ dato $B$ il numero\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) > 0,\n",
    "$$ (eq-probcond)\n",
    "\n",
    "dove $P(A\\cap B)$ è la *probabilità congiunta* dei due eventi, ovvero la probabilità che si verifichino entrambi.\n",
    "```\n",
    "\n",
    "Si noti che $P(A \\mid B)$ non è definita se $P(B) = 0$.\n",
    "\n",
    "Possiamo pensare alla probabilità condizionata come a un cambiamento dello spazio campionario da\n",
    "$S$ a $B$. Per semplici spazi campione abbiamo dunque\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{\\mid A \\cap B \\mid}{\\mid B \\mid}.\n",
    "$$\n",
    "\n",
    "(sec-prob-cond-lancio-dadi)=\n",
    "### Probabilità condizionata e lancio di due dadi\n",
    "\n",
    "Consideriamo un esempio. Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.\n",
    "\n",
    "Inizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.\n",
    "\n",
    "Supponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l'informazione aggiuntiva del risultato dispari.\n",
    "\n",
    "Svolgiamo ora il problema in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (4, 6),\n",
       " (5, 1),\n",
       " (5, 2),\n",
       " (5, 3),\n",
       " (5, 4),\n",
       " (5, 5),\n",
       " (5, 6),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (6, 5),\n",
       " (6, 6)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = range(1, 7)\n",
    "sample = [(i, j) for i in r for j in r]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 / 36\n"
     ]
    }
   ],
   "source": [
    "event = [roll for roll in sample if sum(roll) < 8]\n",
    "print(f\"{len(event)} / {len(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2),\n",
       " (1, 4),\n",
       " (1, 6),\n",
       " (2, 1),\n",
       " (2, 3),\n",
       " (2, 5),\n",
       " (3, 2),\n",
       " (3, 4),\n",
       " (3, 6),\n",
       " (4, 1),\n",
       " (4, 3),\n",
       " (4, 5),\n",
       " (5, 2),\n",
       " (5, 4),\n",
       " (5, 6),\n",
       " (6, 1),\n",
       " (6, 3),\n",
       " (6, 5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_odd = [roll for roll in sample if (sum(roll) % 2) != 0]\n",
    "sample_odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 / 18\n"
     ]
    }
   ],
   "source": [
    "event = [roll for roll in sample_odd if sum(roll) < 8]\n",
    "print(f\"{len(event)} / {len(sample_odd)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se applichiamo l'eq. {eq}`eq-probcond`, abbiamo: $P(A \\cap B)$ = 12/36, $P(B)$ = 18/36 e \n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{12}{18}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l'informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec-mammografia)=\n",
    "### Mammografia e cancro al seno\n",
    "\n",
    "In questo esempio, consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n",
    "\n",
    "- Sensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\n",
    "- Specificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\n",
    "- Prevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.\n",
    "\n",
    "Ora cerchiamo di rispondere alle seguenti domande:\n",
    "\n",
    "- Qual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).\n",
    "\n",
    "- Se la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n",
    "\n",
    "Per risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n",
    "\n",
    "- 10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).\n",
    "- Per le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).\n",
    "\n",
    "Questa situazione può essere rappresentata graficamente nel seguente modo:\n",
    "\n",
    "```{image} ../images/mammografia.png\n",
    ":height: 165px\n",
    ":name: mammografia\n",
    "``` \n",
    "\n",
    "Combinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è $\\frac{108}{1000}$ = 0.108.\n",
    "\n",
    "Tuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a $\\frac{9}{108}$ = 0.083, corrispondente all'8.3%.\n",
    "\n",
    "In questo esempio, la probabilità dell'evento \"ottenere un risultato positivo al test\" è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D'altra parte, la probabilità dell'evento \"avere il cancro al seno, dato che il test ha prodotto un risultato positivo\" è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\n",
    "\n",
    "Questo esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.\n",
    "\n",
    "## Teorema della probabilità composta\n",
    "\n",
    "È possibile scrivere l'eq. {eq}`eq-probcond` nella forma:\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n",
    "$$ (eq-probcondinv)\n",
    "\n",
    "Questo secondo modo di scrivere l'equazione {eq}`eq-probcond` è chiamato *teorema della probabilità composta* (o regola moltiplicativa, o regola della catena). La legge della probabilità composta ci dice che la probabilità che si verifichino contemporaneamente due eventi $A$ e $B$ è pari alla probabilità di uno dei due eventi moltiplicata per la probabilità dell'altro evento condizionata al verificarsi del primo.\n",
    "\n",
    "L'eq. {eq}`eq-probcondinv` si estende al caso di $n$ eventi $A_1, \\dots, A_n$ nella forma seguente:\n",
    "\n",
    "$$\n",
    "P\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n",
    "$$ (eq-probcomposte)\n",
    "\n",
    "Per esempio, nel caso di quattro eventi abbiamo\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n",
    " & P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Per fare un esempio, consideriamo il problema seguente. Da un'urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell'urna. Indichiamo con $B_i$ l'evento: \"esce una pallina bianca alla $i$-esima estrazione\" e con $N_i$ l'estrazione di una pallina nera. L'evento: \"escono due palline bianche nelle prime due estrazioni\" è rappresentato dalla intersezione $\\{B_1 \\cap B_2\\}$ e, per l'eq. {eq}`eq-probcondinv`, la sua probabilità vale\n",
    "\n",
    "$$\n",
    "P(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n",
    "$$\n",
    "\n",
    "$P(B_1)$ vale 6/10, perché nella prima estrazione $\\Omega$ è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata $P(B_2 \\mid B_1)$ vale 5/9, perché nella seconda estrazione, se è verificato l'evento $B_1$, lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n",
    "\n",
    "$$\n",
    "P(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n",
    "$$\n",
    "\n",
    "In modo analogo si ha che\n",
    "\n",
    "$$\n",
    "P(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n",
    "$$\n",
    "\n",
    "Se l'esperimento consiste nell'estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l'eq. {eq}`eq-probcomposte`, vale\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\ \n",
    "&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\ \n",
    "&= \\frac{1}{6}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "La probabilità dell'estrazione di tre palline nere è invece:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\ \n",
    "&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\ \n",
    "&= \\frac{1}{30}.\\notag\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "## Il teorema della probabilità totale\n",
    "\n",
    "Il *teorema della probabilità totale* (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario $\\Omega$ in $n$ eventi mutualmente esclusivi e tali che la loro unione formi $\\Omega$, allora la probabilità di un qualsiasi evento in $\\Omega$ può essere calcolata sommando la probabilità dell'evento su ciascun sottoinsieme della partizione, pesata in base alla probabilità del sottoinsieme.\n",
    "\n",
    "In altre parole, se $H_1, H_2, \\dots, H_n$ sono eventi mutualmente esclusivi e tali che $\\bigcup_{i=1}^n H_i = \\Omega$, allora per ogni evento $E \\subseteq \\Omega$, la probabilità di $E$ è data dalla formula:\n",
    "\n",
    "$$\n",
    "P(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n",
    "$$ (eq-prob-tot)\n",
    "\n",
    "dove $P(E \\mid H_i)$ rappresenta la probabilità condizionata di $E$ dato che si è verificato l'evento $H_i$, e $P(H_i)$ è la probabilità dell'evento $H_i$. \n",
    "\n",
    "Questo teorema è molto utile quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilità di un evento, sfruttando le probabilità dei singoli eventi della partizione. Il caso più semplice è quello di una partizione dello spazio campione in due sottoinsiemi: $P(E) = P(E \\cap H_1) + P(E \\cap H_2)$.\n",
    "\n",
    "```{image} ../images/bayes_theorem.png\n",
    ":height: 230px\n",
    ":align: center\n",
    ":name: image-bayes-theorem\n",
    "```\n",
    "\n",
    "In tali circostanza abbiamo che\n",
    "\n",
    "$$\n",
    "P(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n",
    "$$ \n",
    "\n",
    "L'eq. {eq}`eq-prob-tot` è utile per calcolare $P(E)$, se $P(E \\mid H_i)$ e $P(H_i)$ sono facili da trovare. Quale esempio, consideriamo il seguente problema. Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n",
    "\n",
    "-   Urna 1: 75 palline rosse e 25 palline blu,\n",
    "-   Urna 2: 60 palline rosse e 40 palline blu,\n",
    "-   Urna 3: 45 palline rosse e 55 palline blu.\n",
    "\n",
    "Una pallina viene estratta a caso da un'urna anch'essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\n",
    "\n",
    "Sia $R$ l'evento \"la pallina estratta è rossa\" e sia $U_i$ l'evento che corrisponde alla scelta dell'$i$-esima urna. Sappiamo che\n",
    "\n",
    "$$\n",
    "P(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n",
    "$$\n",
    "\n",
    "Gli eventi $U_1$, $U_2$ e $U_3$ costituiscono una partizione dello spazio campione in quanto $U_1$, $U_2$ e $U_3$ sono eventi mutualmente esclusivi ed esaustivi, ovvero $P(U_1 \\cup U_2 \\cup U_3) = 1.0$. In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n",
    "&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n",
    "&=0.60.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "## L'indipendendenza stocastica\n",
    "\n",
    "L'indipendenza stocastica è un concetto fondamentale nell'applicazione della probabilità in campo statistico. Possiamo esprimere in modo intuitivo l'indipendenza tra due eventi $A$ e $B$ utilizzando l'equazione {eq}`eq-probcond`. Se $A$ e $B$ sono indipendenti, ciò significa che il verificarsi di uno degli eventi non influisce sulla probabilità del verificarsi dell'altro, e viceversa. In altre parole, il verificarsi di uno dei due eventi non condiziona la probabilità dell'altro evento. \n",
    "\n",
    "Per esprimere l'indipendenza con l'equazione {eq}`eq-probcond`, consideriamo $A$ e $B$ come eventi indipendenti. Allora, abbiamo:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(A)P(B)}{P(B)} = P(A),\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(B \\mid A) = \\frac{P(A)P(B)}{P(A)} = P(B).\n",
    "$$\n",
    "\n",
    "Possiamo quindi affermare che due eventi $A$ e $B$ sono indipendenti se soddisfano le seguenti condizioni:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(A \\mid B) &= P(A), \\\\\n",
    "P(B \\mid A) &= P(B).\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Questo implica che la probabilità dell'evento $A$ rimane invariata, indipendentemente dal verificarsi dell'evento $B$, e viceversa.\n",
    "\n",
    "Tre eventi $A$, $B$ e $C$ sono indipendenti se soddisfano le seguenti condizioni:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A \\cap B) &= P(A) P(B) \\notag\\\\\n",
    "P(A \\cap C) &= P(A) P(C) \\notag\\\\\n",
    "P(B \\cap C) &= P(B) P(C) \\notag\\\\\n",
    "P(A \\cap B \\cap C) &= P(A) P(B) P(C). \\notag\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In altre parole, l'intersezione di ciascuna coppia di eventi deve avere una probabilità uguale al prodotto delle probabilità dei singoli eventi. Se queste prime tre condizioni sono soddisfatte, allora gli eventi si dicono \"indipendenti a due a due\". Tuttavia, per essere completamente indipendenti, è necessario che anche l'intersezione di tutti e tre gli eventi abbia una probabilità uguale al prodotto delle probabilità dei singoli eventi. Solo in questo caso possiamo dire che gli eventi sono completamente indipendenti.\n",
    "\n",
    "Consideriamo il seguente problema. Nel lancio di due dadi non truccati, si considerino gli eventi: $A$ = \"esce un 1 o un 2 nel primo lancio\" e $B$ = \"il punteggio totale è 8\". Gli eventi $A$ e $B$ sono indipendenti?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo $P(A)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 / 36\n"
     ]
    }
   ],
   "source": [
    "r = range(1, 7)\n",
    "sample = [(i, j) for i in r for j in r]\n",
    "A = [roll for roll in sample if roll[0] == 1 or roll[0] == 2]\n",
    "print(A)\n",
    "print(f\"{len(A)} / {len(sample)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo $P(B)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 / 36\n"
     ]
    }
   ],
   "source": [
    "B = [roll for roll in sample if roll[0] + roll[1] == 8]\n",
    "print(B)\n",
    "print(f\"{len(B)} / {len(sample)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo $P(A \\cap B)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 36\n"
     ]
    }
   ],
   "source": [
    "I = [\n",
    "    roll\n",
    "    for roll in sample\n",
    "    if (roll[0] == 1 or roll[0] == 2) and (roll[0] + roll[1] == 8)\n",
    "]\n",
    "print(I)\n",
    "print(f\"{len(I)} / {len(sample)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gli eventi $A$ e $B$ non sono statisticamente indipendenti dato che $P(A \\cap B) \\neq P(A)P(B)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12/36 * 5/36 == 1/36"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commenti e considerazioni finali \n",
    "\n",
    "La probabilità condizionata riveste un ruolo fondamentale poiché ci permette di definire in modo preciso il concetto di indipendenza statistica. Uno degli aspetti cruciali dell'analisi statistica riguarda la valutazione dell'associazione tra due variabili. Nel capitolo attuale, ci siamo concentrati sul concetto di indipendenza, che indica l'assenza di relazione tra le variabili. Tuttavia, in futuro, esploreremo come fare inferenze sulla correlazione tra variabili, ovvero come determinare se le variabili sono associate tra loro o se esiste una relazione statistica credibile tra di esse. Questo approfondimento ci permetterà di studiare le connessioni tra variabili e comprendere meglio i fenomeni osservati nei dati."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbb367cc0128e23b7454d788d5a4229ca1f9848fd2e857f4797fbd26ab3b0776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
