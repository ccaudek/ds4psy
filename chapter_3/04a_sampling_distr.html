

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Stime, stimatori e parametri &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-VMXNE4BCDL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-VMXNE4BCDL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_3/04a_sampling_distr';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4psy/chapter_3/04a_sampling_distr.html" />
    <link rel="shortcut icon" href="../_static/increasing.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Incertezza inferenziale e variabilità dei risultati" href="04b_illusion.html" />
    <link rel="prev" title="Variabili casuali" href="04_expval_var.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Correlazione e causazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/07_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_chapter_3.html">Probabilità</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_cond_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_expval_var.html">Variabili casuali</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Stime, stimatori e parametri</a></li>
<li class="toctree-l2"><a class="reference internal" href="04b_illusion.html">Incertezza inferenziale e variabilità dei risultati</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_4/introduction_part_4.html">Inferenza bayesiana</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/03_conjugate_families_1.html">Distribuzioni coniugate (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/11_beta_binomial_pymc.html">Inferenza bayesiana con PyMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/12_jax.html">Usare JAX per un campionamento più veloce</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/13_preliz.html">Scegliere le distribuzioni a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/16_summary_posterior_pymc.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/17_prediction.html">La predizione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/18_mcmc_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/19_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/20_poisson_model.html">Modello di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/21_poisson_sim.html">Modello di Poisson: derivazione analitica e MCMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_freq.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/22_normal_normal_model.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/23_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/24_multiple_groups.html">Gruppi multipli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/40_hier_beta_binom.html">Modello gerarchico beta-binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/41_hier_poisson.html">Modello gerarchico di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/42_hier_gaussian.html">Modello gerarchico gaussiano</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/hssm.html">Drift Diffusion Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_1.html">Il modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_2.html">Analisi bayesiana del modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_params_recovery.html">Analisi di simulazione per la stima dei parametri nel modello di regressione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_3.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_4.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_5.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_multilevel_modeling.html">A Primer on Bayesian Methods for Multilevel Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_7.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_simpson.html">Paradosso di Simpson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_logistic_reg.html">Modello di regressione logistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_binomial_reg.html">Regressione binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_covid.html">Inferenza controfattuale: calcolo delle morti in eccesso dovute al COVID-19</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_counterfactual.html">Analisi causale con PyMC</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_stab.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_s_m_errors.html">Crisi della replicabilità</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a04_summation_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a05_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a06_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a07_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a08_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a09_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_predict_counts.html">La predizione delle frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a21_reglin_2.html">Regressione lineare con Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a23_reglin_4.html">Posterior Predictive Checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4psy/blob/main/docs/chapter_3/04a_sampling_distr.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_3/04a_sampling_distr.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Stime, stimatori e parametri</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#popolazione-e-campioni">Popolazione e campioni</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#la-relazione-tra-stime-e-parametri">La relazione tra stime e parametri</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-campionaria">Distribuzione campionaria</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#valore-atteso-della-media-campionaria">Valore atteso della media campionaria</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#varianza-della-media-campionaria">Varianza della media campionaria</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-standard-e-rappresentazione-dell-incertezza-inferenziale">Errore standard e rappresentazione dell’incertezza inferenziale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#legge-dei-grandi-numeri">Legge dei grandi numeri</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#legge-forte-dei-grandi-numeri">Legge forte dei grandi numeri</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#legge-debole-dei-grandi-numeri">Legge debole dei grandi numeri</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-del-limite-centrale">Teorema del Limite Centrale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#enunciato">Enunciato</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#significato-e-generalizzazione">Significato e generalizzazione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzioni-campionarie-di-altre-statistiche">Distribuzioni campionarie di altre statistiche</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-conclusive">Considerazioni conclusive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/github/ccaudek/ds4psy_2023/blob/main/500_intro_frequentist.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="stime-stimatori-e-parametri">
<span id="sampling-distr-notebook"></span><h1>Stime, stimatori e parametri<a class="headerlink" href="#stime-stimatori-e-parametri" title="Permalink to this heading">#</a></h1>
<p>In questo capitolo, approfondiremo il concetto di <em>distribuzione campionaria</em> che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà verranno utilizzate per costruire gli strumenti fondamentali dell’inferenza frequentista: gli intervalli di fiducia e i test di ipotesi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">statistics</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">itertools</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="popolazione-e-campioni">
<h2>Popolazione e campioni<a class="headerlink" href="#popolazione-e-campioni" title="Permalink to this heading">#</a></h2>
<p>Nell’analisi dei dati, l’obiettivo spesso è comprendere una quantità specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo determinare viene chiamata <em>parametro</em>. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta è chiamata <em>stima</em>, e la formula che utilizziamo per ottenerla è conosciuta come <em>stimatore</em>. In termini formali, uno stimatore è una funzione dei dati osservati, utilizzata per fornire un’approssimazione del parametro di interesse.</p>
<p>In pratica, quando analizziamo un campione di dati, il nostro obiettivo è inferire determinate proprietà della popolazione intera dalla quale il campione è stato tratto. Il parametro è l’indicatore numerico di queste proprietà, ma poiché spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore è la regola o la formula matematica che usiamo per arrivare a questa approssimazione.</p>
<p>È importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.</p>
</section>
<section id="la-relazione-tra-stime-e-parametri">
<h2>La relazione tra stime e parametri<a class="headerlink" href="#la-relazione-tra-stime-e-parametri" title="Permalink to this heading">#</a></h2>
<p>In questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con <span class="math notranslate nohighlight">\(\mu\)</span>. Il nostro obiettivo è capire e caratterizzare l’incertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l’approccio frequentista, facendo uso di un importante strumento statistico chiamato <em>distribuzione campionaria</em>.</p>
<section id="distribuzione-campionaria">
<h3>Distribuzione campionaria<a class="headerlink" href="#distribuzione-campionaria" title="Permalink to this heading">#</a></h3>
<p>Per illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.</p>
<p>La distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.</p>
<p>In termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di <span class="math notranslate nohighlight">\(\mu\)</span>. Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.</p>
<p>Nella simulazione seguente, ipotizziamo la seguente popolazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.  4.5 5.  5.5]
</pre></div>
</div>
</div>
</div>
<p>L’istogramma seguente descrive la distribuzione di frequenza della popolazione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/674bf36acd59be48a67b47d4b217f6354945f9a37a0e0737d524a498d927b9d5.png" src="../_images/674bf36acd59be48a67b47d4b217f6354945f9a37a0e0737d524a498d927b9d5.png" />
</div>
</div>
<p>Calcoliamo la media e la varianza della popolazione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4.25, 1.8125)
</pre></div>
</div>
</div>
</div>
<p>Supponiamo ora di voler considerare l’estrazione di tutti i possibili campioni di dimensione <span class="math notranslate nohighlight">\(n\)</span> = 2 da una popolazione rappresentata dall’array <code class="docutils literal notranslate"><span class="pre">x</span></code>. Per fare ciò, possiamo fare uso di uno strumento di programmazione, come la funzione <code class="docutils literal notranslate"><span class="pre">product</span></code> del modulo <code class="docutils literal notranslate"><span class="pre">itertools</span></code> in Python.</p>
<p>Specificamente, possiamo utilizzare <code class="docutils literal notranslate"><span class="pre">product</span></code> con l’argomento <code class="docutils literal notranslate"><span class="pre">repeat</span></code> impostato a 2, che indica che vogliamo formare tutte le possibili coppie di valori. In altre parole, stiamo cercando tutte le combinazioni in cui ogni valore nell’array <code class="docutils literal notranslate"><span class="pre">x</span></code> può essere abbinato a se stesso o a un altro valore nell’array.</p>
<p>Dopo aver utilizzato la funzione <code class="docutils literal notranslate"><span class="pre">product</span></code>, otteniamo una lista di tuple, che rappresenta tutte le possibili coppie di valori. Possiamo convertire questa lista in un array NumPy più maneggevole utilizzando la funzione <code class="docutils literal notranslate"><span class="pre">np.array</span></code>. Stampando il risultato, otteniamo un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie che possono essere formate dall’array <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<p>Questa rappresentazione di tutte le possibili coppie è coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento può essere scelto più di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sarà <span class="math notranslate nohighlight">\(4^2 = 16 \)</span>. Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di <span class="math notranslate nohighlight">\(4 \times 4 = 16\)</span> possibili coppie.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an array with all the pairs of possible values</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[2.  2. ]
 [2.  4.5]
 [2.  5. ]
 [2.  5.5]
 [4.5 2. ]
 [4.5 4.5]
 [4.5 5. ]
 [4.5 5.5]
 [5.  2. ]
 [5.  4.5]
 [5.  5. ]
 [5.  5.5]
 [5.5 2. ]
 [5.5 4.5]
 [5.5 5. ]
 [5.5 5.5]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># total number of samples</span>
<span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16
</pre></div>
</div>
</div>
</div>
<p>Per calcolare la media di ogni campione di ampiezza <span class="math notranslate nohighlight">\(n=2\)</span>, possiamo utilizzare la funzione <code class="docutils literal notranslate"><span class="pre">mean</span></code> del modulo NumPy e applicarla lungo l’asse delle colonne dell’array di coppie di valori. In questo modo otterremo un array unidimensionale contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la <em>distribuzione campionaria</em> delle medie di campioni di ampiezza <span class="math notranslate nohighlight">\(n=2\)</span> che possono essere estratti dalla popolazione <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an array with the mean of each sample</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.
 5.25 5.5 ]
</pre></div>
</div>
</div>
</div>
<p>Una rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza <span class="math notranslate nohighlight">\(n\)</span> = 2 che possono essere estratti dalla popolazione <code class="docutils literal notranslate"><span class="pre">x</span></code> è fornita qui sotto.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C1&quot;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7c4bab2d51aa3c8e28d703d891c7bb98e7e3f237fc2f6d6005e006227c30ef8a.png" src="../_images/7c4bab2d51aa3c8e28d703d891c7bb98e7e3f237fc2f6d6005e006227c30ef8a.png" />
</div>
</div>
<p>Mostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;x_bar&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Samples</th>
      <th>x_bar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(2.0, 2.0)</td>
      <td>2.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(2.0, 4.5)</td>
      <td>3.25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(2.0, 5.0)</td>
      <td>3.50</td>
    </tr>
    <tr>
      <th>3</th>
      <td>(2.0, 5.5)</td>
      <td>3.75</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(4.5, 2.0)</td>
      <td>3.25</td>
    </tr>
    <tr>
      <th>5</th>
      <td>(4.5, 4.5)</td>
      <td>4.50</td>
    </tr>
    <tr>
      <th>6</th>
      <td>(4.5, 5.0)</td>
      <td>4.75</td>
    </tr>
    <tr>
      <th>7</th>
      <td>(4.5, 5.5)</td>
      <td>5.00</td>
    </tr>
    <tr>
      <th>8</th>
      <td>(5.0, 2.0)</td>
      <td>3.50</td>
    </tr>
    <tr>
      <th>9</th>
      <td>(5.0, 4.5)</td>
      <td>4.75</td>
    </tr>
    <tr>
      <th>10</th>
      <td>(5.0, 5.0)</td>
      <td>5.00</td>
    </tr>
    <tr>
      <th>11</th>
      <td>(5.0, 5.5)</td>
      <td>5.25</td>
    </tr>
    <tr>
      <th>12</th>
      <td>(5.5, 2.0)</td>
      <td>3.75</td>
    </tr>
    <tr>
      <th>13</th>
      <td>(5.5, 4.5)</td>
      <td>5.00</td>
    </tr>
    <tr>
      <th>14</th>
      <td>(5.5, 5.0)</td>
      <td>5.25</td>
    </tr>
    <tr>
      <th>15</th>
      <td>(5.5, 5.5)</td>
      <td>5.50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Procediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza <span class="math notranslate nohighlight">\(n\)</span> = 2 che possono essere estratti dalla popolazione <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
</section>
<section id="valore-atteso-della-media-campionaria">
<h3>Valore atteso della media campionaria<a class="headerlink" href="#valore-atteso-della-media-campionaria" title="Permalink to this heading">#</a></h3>
<p>Supponiamo che <span class="math notranslate nohighlight">\( X_1, X_2, \ldots, X_n \)</span> siano variabili aleatorie iid con valore atteso <span class="math notranslate nohighlight">\( \mu \)</span> e varianza <span class="math notranslate nohighlight">\( \sigma^2 \)</span>. Vogliamo trovare il valore atteso della media campionaria:</p>
<div class="math notranslate nohighlight">
\[
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i 
\]</div>
<p>Ecco la dimostrazione:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathbb{E}(\bar{X}) &amp; = \mathbb{E}\left(\frac{1}{n} \sum_{i=1}^n X_i\right) \\
&amp; = \frac{1}{n} \mathbb{E}\left(\sum_{i=1}^n X_i\right) \\
&amp; = \frac{1}{n} \sum_{i=1}^n \mathbb{E}(X_i) \\
&amp; = \frac{1}{n} \sum_{i=1}^n \mu \\
&amp; = \frac{1}{n} \cdot n \cdot \mu \\
&amp; = \mu
\end{align*}
\end{split}\]</div>
<p>Quindi, il valore atteso della media campionaria di <span class="math notranslate nohighlight">\( n \)</span> variabili iid è uguale al valore atteso di ciascuna variabile singola, che in questo caso è <span class="math notranslate nohighlight">\( \mu \)</span>.</p>
<p>Verifichiamo che ciò sia vero nel nostro caso specifico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">means</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4.25, 4.25)
</pre></div>
</div>
</div>
</div>
</section>
<section id="varianza-della-media-campionaria">
<h3>Varianza della media campionaria<a class="headerlink" href="#varianza-della-media-campionaria" title="Permalink to this heading">#</a></h3>
<p>Dato che le variabili <span class="math notranslate nohighlight">\( X_1, X_2, \ldots, X_n \)</span> sono indipendenti ed identicamente distribuite (iid) con valore atteso <span class="math notranslate nohighlight">\( \mu \)</span> e varianza <span class="math notranslate nohighlight">\( \sigma^2 \)</span>, possiamo calcolare la varianza della media campionaria <span class="math notranslate nohighlight">\(\bar{X}\)</span> come segue:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{Var}(\bar{X}) &amp; = \text{Var}\left(\frac{1}{n} \sum_{i=1}^n X_i\right) \\
&amp; = \frac{1}{n^2} \text{Var}\left(\sum_{i=1}^n X_i\right) \\
&amp; = \frac{1}{n^2} \sum_{i=1}^n \text{Var}(X_i) \quad \text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\
&amp; = \frac{1}{n^2} \sum_{i=1}^n \sigma^2 \\
&amp; = \frac{1}{n^2} \cdot n \cdot \sigma^2 \\
&amp; = \frac{\sigma^2}{n}
\end{align*}
\end{split}\]</div>
<p>Quindi, la varianza della media campionaria di <span class="math notranslate nohighlight">\( n \)</span> variabili iid è uguale alla varianza di ciascuna variabile singola divisa per <span class="math notranslate nohighlight">\( n \)</span>, che in questo caso è <span class="math notranslate nohighlight">\( \sigma^2/n \)</span>.</p>
<p>Per l’esempio in discussione, il valore della varianza delle medie dei campioni è dunque pari a</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.90625
</pre></div>
</div>
</div>
</div>
<p>Lo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.90625
</pre></div>
</div>
</div>
</div>
<p>Consideriamo ora un particolare campione. Per esempio</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observed_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">observed_sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[5.  5.5]
</pre></div>
</div>
</div>
</div>
<p>Troviamo la media del campione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">observed_sample</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_mean</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.25
</pre></div>
</div>
</div>
</div>
<p>La media del campione è diversa dalla media della popolazione (<span class="math notranslate nohighlight">\(\mu\)</span> = 4.25).</p>
<p>Troviamo la deviazione standard del campione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">observed_sample</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_sd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.3535533905932738
</pre></div>
</div>
</div>
</div>
<p>La deviazione standard del campione è diversa dalla deviazione standard della popolazione:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.346291201783626
</pre></div>
</div>
</div>
</div>
<p>In conclusione, possiamo sottolineare due risultati centrali che emergono dall’analisi delle medie campionarie:</p>
<ol class="arabic simple">
<li><p><strong>Media delle medie campionarie e media della popolazione</strong>: La media della distribuzione delle medie campionarie è identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media <span class="math notranslate nohighlight">\( \mu \)</span> è:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
   \mathbb{E}(\bar{X}_n) = \mu.
\]</div>
<ol class="arabic simple" start="2">
<li><p><strong>Varianza delle medie campionarie e varianza della popolazione</strong>: La varianza della distribuzione delle medie campionarie è inferiore alla varianza della popolazione e, precisamente, è pari alla varianza della popolazione divisa per la dimensione del campione:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
   \mathbb{V}(\bar{X}_n) = \frac{\sigma^2}{n}.
\]</div>
<p>Questi risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.</p>
<p>Inoltre, è importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:</p>
<ul class="simple">
<li><p>Se la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sarà anch’essa normale.</p></li>
<li><p>Se la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.</p></li>
</ul>
<p>Questi principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.</p>
</section>
</section>
<section id="errore-standard-e-rappresentazione-dell-incertezza-inferenziale">
<h2>Errore standard e rappresentazione dell’incertezza inferenziale<a class="headerlink" href="#errore-standard-e-rappresentazione-dell-incertezza-inferenziale" title="Permalink to this heading">#</a></h2>
<p>Nella statistica inferenziale, l’errore standard è una misura frequentemente utilizzata per rappresentare l’incertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L’errore standard quantifica quanto possa variare la stima di una statistica da un campione all’altro; un errore standard minore indica una stima più precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di “media più o meno uno (o due) errori standard.” Questa espressione fornisce una gamma di valori entro cui è plausibile che ricada il valore vero del parametro della popolazione.</p>
<p>L’uso dell’errore standard nei grafici non è soltanto una convenzione; esso è uno strumento per quantificare e visualizzare l’incertezza inferenziale. Contribuisce alla comprensione dell’affidabilità delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, è importante notare che questo utilizzo dell’errore standard può essere problematico, come evidenziato nello studio di <span id="id1">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id34" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>, descritto nel capitolo <a class="reference internal" href="04b_illusion.html#illusion-notebook"><span class="std std-ref">Incertezza inferenziale e variabilità dei risultati</span></a>.</p>
<div class="proof example admonition" id="sampling-disr-expl-1">
<p class="admonition-title"><span class="caption-number">Example 7 </span></p>
<section class="example-content" id="proof-content">
<p>Prendiamo in considerazione la figura seguente, presente in un recente articolo di <span id="id2">Ward and Mann [<a class="reference internal" href="../references/bibliography.html#id32" title="Andrew Ward and Traci Mann. Control yourself: broad implications of narrowed attention. Perspectives on Psychological Science, 17(6):1692–1703, 2022.">WM22</a>]</span>.</p>
<figure class="align-default" id="file-collection">
<a class="reference internal image-reference" href="../_images/mann_ward_2004.png"><img alt="../_images/mann_ward_2004.png" src="../_images/mann_ward_2004.png" style="height: 400px;" /></a>
</figure>
<p>Gli autori commentano la figura come segue:</p>
<blockquote>
<div><p>We tested this prediction in a study (Mann &amp; Ward, 2004) that asked dieters to consume a milkshake in the presence of inhibiting cues, including a collection of diet books, a weight scale, and a recipe card that indicated the high level of fat in the milkshake. Compared with conditions in which the milkshake itself constituted the salient cue in the environment, rendering diet cues salient actually led to decreased consumption under high cognitive load (p. 1696).</p>
</div></blockquote>
<p>Il confronto cruciale è tra le due medie rappresentate dalle barre blu scuro. Le barre d’errore rappresentano un errore standard, indicando che possiamo essere abbastanza sicuri che le medie siano statisticamente diverse. Tuttavia, è importante notare che, nel contesto frequentista, l’analisi cruciale coinvolge gli intervalli costruiti con la media ± due errori standard. Inoltre, la ridotta ampiezza dei campioni potrebbe influenzare l’interpretazione dei risultati.</p>
<blockquote>
<div><p>The milkshake-salient–high load condition included 27 participants, the milkshake-salient–low load condition included 31 participants, the diet-salient–high load condition included 23 participants, and the diet-salient–low load condition included 21 participants.</p>
</div></blockquote>
<p>In effetti, senza conoscere la variabilità all’interno dei gruppi, diventa difficile interpretare i risultati. In un disegno <em>between-subjects</em> non abbiamo alcuna evidenza che il pattern mostrato nella figura rappresenti qualcosa che succede <em>a ciascun singolo individuo</em>, se si sottoponesse alle due condizioni in cui viene manipolata la salienza, o alle due condizioni in cui viene manipolata l’attenzione. Le differenze tra le <em>medie</em> dei gruppi potrebbero dipendere dalle idiosincrasie dei diversi campioni. Nel caso di campioni così piccoli, gli effetti della randomizzazione non consentono di escludere conseguenze importanti degli artefatti che dipendono dalla specificità dei gruppi. Inoltre, i risultati potrebbero dipendere dalla presenza di uno o pochissimi individui che si comportano in questo modo, mentre la maggioranza degli individui non mostra alcuna differenza tra le varie condizioni.</p>
<p>Questo esempio dimostra che la rappresentazione grafica, che include la media e le barre d’errore, non è il metodo più efficace per illustrare il significato pratico di un effetto sperimentale. Questa tematica verrà esplorata più in dettaglio nel prossimo capitolo, in cui discuteremo l’articolo di <span id="id3">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id34" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>.</p>
</section>
</div></section>
<section id="legge-dei-grandi-numeri">
<h2>Legge dei grandi numeri<a class="headerlink" href="#legge-dei-grandi-numeri" title="Permalink to this heading">#</a></h2>
<p>La Legge dei grandi numeri (<em>Law of Large Numbers</em>, LLN) stabilisce che, all’aumentare di <span class="math notranslate nohighlight">\( n \)</span>, la media campionaria <span class="math notranslate nohighlight">\( \bar{X}_n \)</span> tende a convergere verso la media reale <span class="math notranslate nohighlight">\( \mu \)</span> (in un modo che sarà spiegato più avanti). La LLN è formulata in due versioni: una “forte” (SLLN) e una “debole” (WLLN), che adottano definizioni leggermente differenti riguardo al concetto di convergenza di una sequenza di variabili aleatorie verso un numero. Esamineremo entrambe le versioni.</p>
<section id="legge-forte-dei-grandi-numeri">
<h3>Legge forte dei grandi numeri<a class="headerlink" href="#legge-forte-dei-grandi-numeri" title="Permalink to this heading">#</a></h3>
<p>La media campionaria <span class="math notranslate nohighlight">\( \bar{X}_n \)</span> converge punto per punto verso la media reale <span class="math notranslate nohighlight">\( \mu \)</span>, con probabilità 1. Tenendo presente che le variabili aleatorie sono funzioni che mappano lo spazio campionario <span class="math notranslate nohighlight">\( S \)</span> su <span class="math notranslate nohighlight">\( \mathbb{R} \)</span>, questa forma di convergenza implica che <span class="math notranslate nohighlight">\( \bar{X}_n(s) \)</span> tende a <span class="math notranslate nohighlight">\( \mu \)</span> per ciascun punto <span class="math notranslate nohighlight">\( s \)</span> appartenente a <span class="math notranslate nohighlight">\( S \)</span>. L’unica eccezione è che la convergenza può fallire su un insieme <span class="math notranslate nohighlight">\( B_0 \)</span> di casi eccezionali, purché <span class="math notranslate nohighlight">\( P(B_0) = 0 \)</span>. In sintesi, <span class="math notranslate nohighlight">\( P(\bar{X}_n \to \mu) = 1 \)</span>.</p>
</section>
<section id="legge-debole-dei-grandi-numeri">
<h3>Legge debole dei grandi numeri<a class="headerlink" href="#legge-debole-dei-grandi-numeri" title="Permalink to this heading">#</a></h3>
<p>Per ogni <span class="math notranslate nohighlight">\( \epsilon &gt; 0 \)</span>, la probabilità <span class="math notranslate nohighlight">\( P(|\bar{X}_n - \mu| &gt; \epsilon) \)</span> tende a zero all’aumentare di <span class="math notranslate nohighlight">\( n \)</span>. Questo tipo di convergenza è noto come convergenza in probabilità.</p>
<p>La Legge dei grandi numeri è fondamentale per le simulazioni, la statistica e la scienza in generale. Pensate alla generazione di “dati” derivanti da un elevato numero di repliche indipendenti di un esperimento, siano esse eseguite tramite simulazione al computer o in condizioni reali. Ogni volta che facciamo uso del valore medio ottenuto dalle repliche per approssimare la media teorica di una data quantità, stiamo implicitamente facendo appello alla LLN.</p>
<div class="proof example admonition" id="sampling-disr-expl-2">
<p class="admonition-title"><span class="caption-number">Example 8 </span></p>
<section class="example-content" id="proof-content">
<p>Siano <span class="math notranslate nohighlight">\( X_1, X_2, \ldots \)</span> variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro <span class="math notranslate nohighlight">\(1/2\)</span>. Interpretando gli <span class="math notranslate nohighlight">\( X_j \)</span> come indicatori di “Testa” in una sequenza di lanci di una moneta equa, <span class="math notranslate nohighlight">\( \bar{X}_n \)</span> rappresenta la proporzione di “Testa” dopo <span class="math notranslate nohighlight">\( n \)</span> lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilità 1, la sequenza di variabili aleatorie <span class="math notranslate nohighlight">\( \bar{X}_1, \bar{X}_2, \bar{X}_3, \ldots \)</span> convergerà a <span class="math notranslate nohighlight">\( 1/2 \)</span> quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di “Testa” (HHHHHH…) o sequenze irregolari come HHTHHTHHTHHT…, ma queste hanno una probabilità collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni <span class="math notranslate nohighlight">\( \epsilon &gt; 0 \)</span>, la probabilità che <span class="math notranslate nohighlight">\( \bar{X}_n \)</span> sia distante più di <span class="math notranslate nohighlight">\( \epsilon \)</span> da <span class="math notranslate nohighlight">\( 1/2 \)</span> può essere resa arbitrariamente piccola aumentando <span class="math notranslate nohighlight">\( n \)</span>.</p>
<p>Come illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato <span class="math notranslate nohighlight">\( \bar{X}_n \)</span> in funzione di <span class="math notranslate nohighlight">\( n \)</span>. Ovviamente, nella realtà non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra <span class="math notranslate nohighlight">\( \bar{X}_n \)</span> in funzione di <span class="math notranslate nohighlight">\( n \)</span> per ciascuna delle sei sequenze. All’inizio, notiamo una certa variazione nella proporzione cumulativa di “Testa”. Tuttavia, con l’aumentare del numero di lanci, la varianza <span class="math notranslate nohighlight">\( \text{Var}(\bar{X}_n) \)</span> diminuisce progressivamente e <span class="math notranslate nohighlight">\( \bar{X}_n \)</span> tende a <span class="math notranslate nohighlight">\( 1/2 \)</span>.</p>
</section>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of sequences</span>
<span class="n">num_sequences</span> <span class="o">=</span> <span class="mi">6</span>
<span class="c1"># Number of tosses</span>
<span class="n">num_tosses</span> <span class="o">=</span> <span class="mi">300</span>
<span class="c1"># Initialize a figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="c1"># Loop through each sequence</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sequences</span><span class="p">):</span>
    
    <span class="c1"># Generate a sequence of fair coin tosses (Heads=1, Tails=0)</span>
    <span class="n">coin_tosses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">num_tosses</span><span class="p">)</span>
    
    <span class="c1"># Calculate the running proportion of Heads</span>
    <span class="n">running_proportion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">coin_tosses</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_tosses</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Plot the running proportion as a function of the number of tosses</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_tosses</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">running_proportion</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Sequence </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Plotting the true mean (1/2)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True Mean (1/2)&#39;</span><span class="p">)</span>

<span class="c1"># Adding labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Tosses&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Running Proportion of Heads&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Running Proportion of Heads in Six Sequences of Fair Coin Tosses&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;small&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/04cabe89b972733eba30b5aee395c91d905434cda7ee6ad98f6141f1ed70ba01.png" src="../_images/04cabe89b972733eba30b5aee395c91d905434cda7ee6ad98f6141f1ed70ba01.png" />
</div>
</div>
</section>
</section>
<section id="teorema-del-limite-centrale">
<h2>Teorema del Limite Centrale<a class="headerlink" href="#teorema-del-limite-centrale" title="Permalink to this heading">#</a></h2>
<p>Il teorema del limite centrale è un risultato fondamentale in statistica che è stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare così frequentemente nei fenomeni naturali. Ecco la formulazione essenziale:</p>
<section id="enunciato">
<h3>Enunciato<a class="headerlink" href="#enunciato" title="Permalink to this heading">#</a></h3>
<p>Supponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), <span class="math notranslate nohighlight">\( Y = Y_1, \dots, Y_i, \ldots, Y_n \)</span>, ciascuna con valore atteso <span class="math notranslate nohighlight">\( \mathbb{E}(Y_i) = \mu \)</span> e deviazione standard <span class="math notranslate nohighlight">\( SD(Y_i) = \sigma \)</span>. Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:</p>
<div class="math notranslate nohighlight">
\[
Z = \frac{1}{n} \sum_{i=1}^n Y_i.
\]</div>
<p>Allora, quando <span class="math notranslate nohighlight">\( n \)</span> tende all’infinito, la distribuzione di <span class="math notranslate nohighlight">\( Z \)</span> convergerà a una distribuzione normale con media <span class="math notranslate nohighlight">\( \mu \)</span> e deviazione standard ridotta di un fattore <span class="math notranslate nohighlight">\( \frac{1}{\sqrt{n}} \)</span>:</p>
<div class="math notranslate nohighlight">
\[
p_Z(z) \rightarrow \mathcal{N}\left(z \ \Bigg| \ \mu, \, \frac{\sigma}{\sqrt{n}}\right).
\]</div>
</section>
<section id="significato-e-generalizzazione">
<h3>Significato e generalizzazione<a class="headerlink" href="#significato-e-generalizzazione" title="Permalink to this heading">#</a></h3>
<p>Il TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma può essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacità di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.</p>
<p>Ad esempio, l’altezza degli esseri umani adulti può essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalità rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.</p>
<div class="proof example admonition" id="sampling-disr-expl-3">
<p class="admonition-title"><span class="caption-number">Example 9 </span></p>
<section class="example-content" id="proof-content">
<p>Per visualizzare il TLC in azione, si può condurre una simulazione. Immaginiamo una popolazione iniziale con una distribuzione asimmetrica, come una Beta(2, 1). Estraiamo 50.000 campioni di dimensione <span class="math notranslate nohighlight">\( n \)</span> da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.</p>
</section>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># parameters of the beta distribution</span>
<span class="n">a</span><span class="o">=</span><span class="mi">2</span>
<span class="n">b</span><span class="o">=</span><span class="mi">1</span>

<span class="k">def</span> <span class="nf">plotSamples</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># create normal distribution with mean and standard deviation of the beta</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">a</span><span class="o">*</span><span class="n">b</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">/</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

    <span class="c1"># find sample means from samples of &quot;ramped&quot; beta distribution</span>
    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50000</span><span class="p">):</span>
          <span class="n">v</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="n">sample_means</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># plot a histogram of the distribution of sample means, together </span>
    <span class="c1"># with the population distribution</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">sample_means</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C2&quot;</span><span class="p">)</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">yticklabels</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">yticklabels</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Ampiezza campionaria = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Se l’ampiezza campionaria è 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotSamples</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/143827c6ca2d092673bafc21cda6d35088445b693886f8b1d959f10cea70a277.png" src="../_images/143827c6ca2d092673bafc21cda6d35088445b693886f8b1d959f10cea70a277.png" />
</div>
</div>
<p>Con <span class="math notranslate nohighlight">\(n\)</span> = 2, la distribuzione delle medie dei campioni non è certamente Normale, inizia ad avvicinarsi alla gaussianità.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotSamples</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/110b98d11d841486d950046e0579f5c052753084d42c5ae3d715dba9e8f0695b.png" src="../_images/110b98d11d841486d950046e0579f5c052753084d42c5ae3d715dba9e8f0695b.png" />
</div>
</div>
<p>Con <span class="math notranslate nohighlight">\(n\)</span> = 4 c’è ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l’approssimazione migliora.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotSamples</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/537ab95ed70e241f2e39535f8df8e61824c089b18fbaac33d98d2fee5d51aece.png" src="../_images/537ab95ed70e241f2e39535f8df8e61824c089b18fbaac33d98d2fee5d51aece.png" />
</div>
</div>
<p>Con <span class="math notranslate nohighlight">\(n\)</span> = 30 la funzione <span class="math notranslate nohighlight">\(\mathcal{N}(100, 15/\sqrt{50})\)</span> fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotSamples</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/3cb4e3ef527e49d1d73053d3cb0c1e6ddd9c706cf3bfd74d66dbbdc6e05edf22.png" src="../_images/3cb4e3ef527e49d1d73053d3cb0c1e6ddd9c706cf3bfd74d66dbbdc6e05edf22.png" />
</div>
</div>
<p>In conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, è possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ciò avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media <span class="math notranslate nohighlight">\(\mu\)</span> e la deviazione standard <span class="math notranslate nohighlight">\(\sigma\)</span>, ed è espresso dalla relazione <span class="math notranslate nohighlight">\(\bar{X} \sim \mathcal{N}(\mu, \sigma/\sqrt{n})\)</span>.</p>
</section>
</section>
<section id="distribuzioni-campionarie-di-altre-statistiche">
<h2>Distribuzioni campionarie di altre statistiche<a class="headerlink" href="#distribuzioni-campionarie-di-altre-statistiche" title="Permalink to this heading">#</a></h2>
<p>In precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente è possibile costruire la distribuzione campionaria di altre statistiche campionarie.  Ad esempio, la figura seguente mostra l’approssimazione empirica della distribuzione campionaria del valore massimo del campione. È chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sarà maggiore della media della popolazione.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define a normal distribution with a mean of 100 and a standard deviation of 15</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

<span class="c1"># run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment</span>
<span class="n">sample_maxes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">):</span>
    <span class="n">sample_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
    <span class="n">sample_maxes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_max</span><span class="p">)</span>

<span class="c1"># plot a histogram of the distribution of sample maximums, together with the population distribution</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">sample_maxes</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C2&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/dd135588782abc92561bd3b7a7d3675ef453c09ce6da1854dcad1ee96980b073.png" src="../_images/dd135588782abc92561bd3b7a7d3675ef453c09ce6da1854dcad1ee96980b073.png" />
</div>
</div>
<p>La distribuzione campionaria della varianza dei campioni è particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero</p>
<div class="math notranslate nohighlight">
\[
S^2 = \frac{\sum_{i=1}^n (Y_i - \bar{Y})^2}{n}.
\]</div>
<p>Una volta compresa la procedura, possiamo creare un grafico che rappresenta l’approssimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione è uguale a <span class="math notranslate nohighlight">\(15^2\)</span>, abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto è stato interessante: in media, l’utilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza <em>distorsione</em>, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define a normal distribution with a mean of 100 and a standard </span>
<span class="c1"># deviation of 15</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

<span class="c1"># run 10000 simulated experiments with 5 subjects each, and find </span>
<span class="c1"># the variance score for each experiment</span>
<span class="n">sample_vars</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">sample_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">sample_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_var</span><span class="p">)</span>

<span class="c1"># plot a histogram of the distribution of sample variance</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">sample_vars</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C2&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_vars</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>181.7310644703327
</pre></div>
</div>
<img alt="../_images/16e9ac37544f4a9d5adefbe404a4d9559378c56a83eae4e389fe51f985daca3c.png" src="../_images/16e9ac37544f4a9d5adefbe404a4d9559378c56a83eae4e389fe51f985daca3c.png" />
</div>
</div>
<p>Abbiamo già visto come questo problema trova una semplice soluzione nel momento in cui usiamo <span class="math notranslate nohighlight">\(n-1\)</span> al denominatore.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define a normal distribution with a mean of 100 and a standard </span>
<span class="c1"># deviation of 15</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

<span class="c1"># run 10000 simulated experiments with 5 subjects each, and find </span>
<span class="c1"># the variance score for each experiment</span>
<span class="n">sample_vars</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">sample_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sample_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_var</span><span class="p">)</span>

<span class="c1"># plot a histogram of the distribution of sample variance</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">sample_vars</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C2&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_vars</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>224.92207264264866
</pre></div>
</div>
<img alt="../_images/b7a081312e35aa73bd8cd7d417cec9811c8e5aabfb88a57727850ee8076c5249.png" src="../_images/b7a081312e35aa73bd8cd7d417cec9811c8e5aabfb88a57727850ee8076c5249.png" />
</div>
</div>
<p>La differenza tra la stima di un parametro e il valore vero del parametro è chiamata <em>errore della stima</em>. Uno stimatore si dice <em>non distorto</em> (<em>unbiased</em>) se la media delle sue stime su molteplici campioni ipotetici è uguale al valore del parametro che si vuole stimare. In altre parole, l’errore medio di stima è zero.</p>
<p>In questo capitolo abbiamo visto che <span class="math notranslate nohighlight">\(\frac{\sum_{i=1}^n{X_i}}{n}\)</span> è uno stimatore non distorto di <span class="math notranslate nohighlight">\(\mu\)</span> e che <span class="math notranslate nohighlight">\(\frac{\sum_{i=1}^n{(^2)}}{n-1}\)</span> è uno stimatore non distorto di <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.</p>
</section>
<section id="considerazioni-conclusive">
<h2>Considerazioni conclusive<a class="headerlink" href="#considerazioni-conclusive" title="Permalink to this heading">#</a></h2>
<p>In generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Simbolo</p></th>
<th class="head text-left"><p>Nome</p></th>
<th class="head text-left"><p>È qualcosa che conosciamo?</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><span class="math notranslate nohighlight">\(s\)</span></p></td>
<td class="text-left"><p>Deviazione standard del campione</p></td>
<td class="text-left"><p>Sì, la calcoliamo dai dati grezzi</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="math notranslate nohighlight">\(\sigma\)</span></p></td>
<td class="text-left"><p>Deviazione standard della popolazione</p></td>
<td class="text-left"><p>No, tranne in casi particolari o nelle simulazioni</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span class="math notranslate nohighlight">\(\hat{\sigma}\)</span></p></td>
<td class="text-left"><p>Stima della deviazione standard della popolazione</p></td>
<td class="text-left"><p>Sì, ma non è uguale a <span class="math notranslate nohighlight">\(\sigma\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="math notranslate nohighlight">\(s^2\)</span></p></td>
<td class="text-left"><p>Varianza del campione</p></td>
<td class="text-left"><p>Sì, la calcoliamo dai dati grezzi</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><span class="math notranslate nohighlight">\(\sigma^2\)</span></p></td>
<td class="text-left"><p>Varianza della popolazione</p></td>
<td class="text-left"><p>No, tranne in casi particolari o nelle simulazioni</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="math notranslate nohighlight">\(\hat{\sigma}^2\)</span></p></td>
<td class="text-left"><p>Stima della varianza della popolazione</p></td>
<td class="text-left"><p>Sì, ma non è uguale a <span class="math notranslate nohighlight">\(\sigma^2\)</span></p></td>
</tr>
</tbody>
</table>
<p>Utilizzando le informazioni di un campione casuale di ampiezza <span class="math notranslate nohighlight">\(n\)</span>:</p>
<ul class="simple">
<li><p>La stima migliore che possiamo ottenere per la media <span class="math notranslate nohighlight">\(\mu\)</span> della popolazione è la media del campione <span class="math notranslate nohighlight">\(\bar{Y}\)</span>.</p></li>
<li><p>La stima migliore che possiamo ottenere per la varianza <span class="math notranslate nohighlight">\(\sigma^2\)</span> della popolazione è:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{\sigma}^2 = \frac{1}{n-1} \sum_{i=1}^n (Y_i - \bar{Y})^2.
\]</div>
</section>
<section id="watermark">
<h2>Watermark<a class="headerlink" href="#watermark" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Thu Nov 09 2023

Python implementation: CPython
Python version       : 3.11.6
IPython version      : 8.16.1

matplotlib: 3.8.0
arviz     : 0.16.1
seaborn   : 0.13.0
scipy     : 1.11.3
pandas    : 2.1.1
numpy     : 1.25.2
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="04_expval_var.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Variabili casuali</p>
      </div>
    </a>
    <a class="right-next"
       href="04b_illusion.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Incertezza inferenziale e variabilità dei risultati</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#popolazione-e-campioni">Popolazione e campioni</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#la-relazione-tra-stime-e-parametri">La relazione tra stime e parametri</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzione-campionaria">Distribuzione campionaria</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#valore-atteso-della-media-campionaria">Valore atteso della media campionaria</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#varianza-della-media-campionaria">Varianza della media campionaria</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#errore-standard-e-rappresentazione-dell-incertezza-inferenziale">Errore standard e rappresentazione dell’incertezza inferenziale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#legge-dei-grandi-numeri">Legge dei grandi numeri</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#legge-forte-dei-grandi-numeri">Legge forte dei grandi numeri</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#legge-debole-dei-grandi-numeri">Legge debole dei grandi numeri</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teorema-del-limite-centrale">Teorema del Limite Centrale</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#enunciato">Enunciato</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#significato-e-generalizzazione">Significato e generalizzazione</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuzioni-campionarie-di-altre-statistiche">Distribuzioni campionarie di altre statistiche</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#considerazioni-conclusive">Considerazioni conclusive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>