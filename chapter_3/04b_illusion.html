

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Incertezza inferenziale e variabilità dei risultati &#8212; ds4p</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-VMXNE4BCDL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-VMXNE4BCDL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_3/04b_illusion';</script>
    <link rel="canonical" href="https://ccaudek.github.io/ds4psy/chapter_3/04b_illusion.html" />
    <link rel="shortcut icon" href="../_static/increasing.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="✏️ Esercizi" href="E_rv_discrete.html" />
    <link rel="prev" title="Stime, stimatori e parametri" href="04a_sampling_distr.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="ds4p - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="ds4p - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Benvenuti
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_1/introduction_chapter_1.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/01_python_1.html">Python (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/02_python_2.html">Python (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_python.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/03_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_numpy.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/04_pandas.html">Pandas (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/05_pandas_aggregate.html">Pandas (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/06_pandas_functions.html">Pandas (3)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_pandas.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/07_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/08_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_1/ex_matplotlib.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_2/introduction_chapter_2.html">Statistica descrittiva</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/01_key_notions.html">Concetti chiave</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_key_notions.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/02_measurement.html">La misurazione in psicologia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_scales.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/03_freq_distr.html">Dati e frequenze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_sums.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/04_loc_scale.html">Indici di posizione e di scala</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/05_correlation.html">Le relazioni tra variabili</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/06_causality.html">Correlazione e causazione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/07_crisis.html">La crisi della generalizzabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_eda.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_2/E_mehr_song_spelke.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduction_chapter_3.html">Probabilità</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_intro_prob.html">Introduzione al calcolo delle probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_conditional_prob.html">Probabilità condizionata</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_cond_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_bayes_theorem.html">Il teorema di Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_bayes_theorem.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_expval_var.html">Variabili casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="04a_sampling_distr.html">Stime, stimatori e parametri</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Incertezza inferenziale e variabilità dei risultati</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_rv_discrete.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_joint_prob.html">Probabilità congiunta</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_joint_prob.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_density_func.html">La funzione di densità di probabilità</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_discr_rv_distr.html">Distribuzioni di v.c. discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_binomial.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_cont_rv_distr.html">Distribuzioni di v.c. continue</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_gaussian.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_beta_distr.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="09_likelihood.html">La verosimiglianza</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_rescorla_wagner.html">Apprendimento per rinforzo</a></li>
<li class="toctree-l2"><a class="reference internal" href="E_likelihood.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_4/introduction_part_4.html">Inferenza bayesiana</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/01_intro_bayes.html">Modellazione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/02_subj_prop.html">Pensare ad una proporzione in termini soggettivi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/03_conjugate_families_1.html">Distribuzioni coniugate (1)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/04_conjugate_families_2.html">Distribuzioni coniugate (2)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/05_summary_posterior.html">Sintesi a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_conjugate.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/06_balance-prior-post.html">L’influenza della distribuzione a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/10_metropolis.html">Monte Carlo a Catena di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/11_beta_binomial_pymc.html">Inferenza bayesiana con PyMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/12_jax.html">Usare JAX per un campionamento più veloce</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/13_preliz.html">Scegliere le distribuzioni a priori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/16_summary_posterior_pymc.html">Metodi di sintesi della distribuzione a posteriori</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/17_prediction.html">La predizione bayesiana</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/18_mcmc_diagnostics.html">Diagnostica delle catene markoviane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/19_odds_ratio.html">Analisi bayesiana dell’odds-ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/20_poisson_model.html">Modello di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/21_poisson_sim.html">Modello di Poisson: derivazione analitica e MCMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_freq.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/22_normal_normal_model.html">Inferenza bayesiana su una media</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean.html">✏️ Esercizio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/E_one_mean_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/23_two_groups.html">Confronto tra due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/24_multiple_groups.html">Gruppi multipli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/30_entropy.html">Entropia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/31_kl.html">La divergenza di Kullback-Leibler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/32_loo.html">Validazione Incrociata Leave-One-Out</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/40_hier_beta_binom.html">Modello gerarchico beta-binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/41_hier_poisson.html">Modello gerarchico di Poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/42_hier_gaussian.html">Modello gerarchico gaussiano</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_4/hssm.html">Drift Diffusion Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_5/introduction_part_5.html">Analisi della regressione</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_1.html">Il modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_2.html">Analisi bayesiana del modello di regressione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_params_recovery.html">Analisi di simulazione per la stima dei parametri nel modello di regressione</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_3.html">Zucchero sintattico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_4.html">Confronto tra le medie di due gruppi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_5.html">Il modello lineare gerarchico</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_reglin_7.html">Regressione robusta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_simpson.html">Paradosso di Simpson</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_1.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_2.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_3.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_reglin_4.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_logistic_reg.html">Modello di regressione logistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_binomial_reg.html">Regressione binomiale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_covid.html">Inferenza controfattuale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_5/05_counterfactual.html">Analisi causale con PyMC</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter_5/E_stab.html">✏️ Esercizi</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_6/introduction_part_6.html">Inferenza frequentista</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_estimation.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/02_conf_interv.html">Intervallo di confidenza</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/03_test_ipotesi.html">Significatività statistica</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_interpretation_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_significato_test.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/04_two_ind_samples.html">Test t di Student per campioni indipendenti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_test_media_pop.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_ampie.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_medie_pop_piccoli.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_campioni_appaiati.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/E_confronto_proporzioni.html">✏️ Esercizi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/05_limiti_stat_frequentista.html">Limiti dell’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_6/06_s_m_errors.html">Crisi della replicabilità</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../references/bibliography.html">Bibliografia</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_7/introduction_appendix.html">Appendici</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a00_installation.html">Ambiente di lavoro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a01_markdown.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a02_shell.html">La Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a03_virtual_env.html">Ambiente virtuale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a10_math_symbols.html">Simbologia di base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a11_numbers.html">Numeri binari, interi, razionali, irrazionali e reali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a12_sum_notation.html">Simbolo di somma (sommatorie)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a13_sets.html">Insiemi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a14_combinatorics.html">Calcolo combinatorio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a15_calculus.html">Per liberarvi dai terrori preliminari</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a20_kde_plot.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a30_prob_tutorial.html">Esercizi di probabilità discreta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a40_rng.html">Generazione di numeri casuali</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a44_montecarlo.html">Simulazione Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a45_mcmc.html">Catene di Markov</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a50_lin_fun.html">La funzione lineare</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a51_reglin_1.html">Regressione lineare bivariata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a52_reglin_2.html">Regressione lineare con Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a53_reglin_4.html">Posterior Predictive Checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a60_ttest_exercises.html">Esercizi sull’inferenza frequentista</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_7/a70_predict_counts.html">La predizione delle frequenze</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ccaudek/ds4psy/blob/main/docs/chapter_3/04b_illusion.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter_3/04b_illusion.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Incertezza inferenziale e variabilità dei risultati</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#la-rappresentazione-dell-incertezza-inferenziale">La rappresentazione dell’incertezza inferenziale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#illusione-di-prevedibilita">Illusione di prevedibilità</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-conclusive">Commenti e considerazioni conclusive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/github/ccaudek/ds4psy_2023/blob/main/4b_illusion.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="incertezza-inferenziale-e-variabilita-dei-risultati">
<span id="illusion-notebook"></span><h1>Incertezza inferenziale e variabilità dei risultati<a class="headerlink" href="#incertezza-inferenziale-e-variabilita-dei-risultati" title="Permalink to this heading">#</a></h1>
<p>Nel presente capitolo, ci addentreremo nell’analisi degli errori standard della media. Sebbene l’errore standard sia un concetto tipico della statistica frequentista, e questo corso ponga l’accento sulla statistica bayesiana, è importante esplorare questo tema, in quanto il suo utilizzo nella ricerca è estremamente diffuso. In particolare, ci focalizzeremo su un articolo di <span id="id1">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>, che stabilisce un collegamento tra l’incertezza inferenziale, espressa dall’errore standard, e la deviazione standard, che simboleggia la variabilità dei risultati all’interno di uno studio. Comprendere il legame tra questi due concetti è fondamentale. Infatti, <span id="id2">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> sottolineano che l’approccio dominante nella visualizzazione scientifica, il quale include esclusivamente l’incertezza inferenziale (vale a dire la rappresentazione grafica della media con l’aggiunta delle barre d’errore corrispondenti agli errori standard), può portare a interpretazioni fuorvianti dei dati. Questo può condurre a una sovrastima sistematica degli effetti del trattamento, un fenomeno che può verificarsi persino tra gli esperti più qualificati del settore. Attraverso questo approfondimento, miriamo a fornire una visione chiara di come l’errore standard e la deviazione standard interagiscano, e di come la loro corretta interpretazione possa evitare possibili equivoci nell’analisi e nella comunicazione dei risultati della ricerca.</p>
<section id="preparazione-del-notebook">
<h2>Preparazione del Notebook<a class="headerlink" href="#preparazione-del-notebook" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">statistics</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="la-rappresentazione-dell-incertezza-inferenziale">
<h2>La rappresentazione dell’incertezza inferenziale<a class="headerlink" href="#la-rappresentazione-dell-incertezza-inferenziale" title="Permalink to this heading">#</a></h2>
<p><span id="id3">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> iniziano la loro analisi esplorando la relazione tra incertezza inferenziale e variabilità dei risultati nel contesto della ricerca empirica. Nell’ambito della ricerca empirica, l’obiettivo è fare inferenze sulla popolazione intera utilizzando un campione ristretto di dati. Questo può riguardare, ad esempio, il confronto tra il benessere psicologico di un gruppo sottoposto a trattamento sperimentale e un gruppo di controllo, o la valutazione dell’efficacia di un intervento psicologico tra individui con differenti caratteristiche personologiche. In tali casi, trarre conclusioni valide può essere complicato, specialmente quando si ha a che fare con campioni piccoli e risultati altamente variabili all’interno di ciascun campione.</p>
<p>La risposta comune a questi problemi è concentrarsi su misure aggregate, come le medie dei gruppi, invece che sui singoli risultati, e fornire una misura dell’incertezza inferenziale relativa alla precisione della stima della media. L’incertezza inferenziale è spesso espressa attraverso errori standard (SE), intervalli di confidenza, intervalli di credibilità Bayesiani, o metodologie analoghe.</p>
<p>La quantificazione dell’incertezza inferenziale è fondamentale, in quanto fornisce un intervallo plausibile di valori per la quantità di interesse e previene interpretazioni erronee dovute alla variazione casuale nei campioni. Ciò assicura che le conclusioni siano rappresentative delle tendenze reali nella popolazione e non siano semplici artefatti dei campioni specifici.</p>
<p>Tuttavia, <span id="id4">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> evidenziano una problematica che può sorgere quando la ricerca si focalizza unicamente sui risultati aggregati e sull’incertezza inferenziale, ovvero il fatto che viene trascurata la variabilità dei risultati individuali. Questa variabilità, spesso quantificata attraverso la deviazione standard (SD) o la varianza, è cruciale per valutare le dimensioni dell’effetto e la prevedibilità dei risultati futuri.</p>
<p>Benché esistano associazioni tra incertezza inferenziale e variabilità dei risultati, questi sono concetti distinti e facilmente confondibili. L’incertezza inferenziale si riferisce alla fiducia nelle stime di parametri specifici, come la media, mentre la variabilità dei risultati riguarda le differenze nei risultati individuali all’interno di un gruppo.</p>
<p>La confusione tra questi due aspetti e/o l’eccessiva enfasi sull’incertezza inferenziale può generare interpretazioni sbagliate riguardo all’ampiezza e alla rilevanza dei risultati della ricerca. Ciò può verificarsi anche tra gli specialisti che si occupano di creare e interpretare questi dati, sottolineando l’importanza di una comunicazione chiara e di una maggiore consapevolezza nella presentazione delle analisi statistiche.</p>
</section>
<section id="illusione-di-prevedibilita">
<h2>Illusione di prevedibilità<a class="headerlink" href="#illusione-di-prevedibilita" title="Permalink to this heading">#</a></h2>
<p>Per comprendere le differenze tra incertezza inferenziale e variabilità dei risultati, e cogliere come focalizzarsi sulla prima possa portare a conclusioni errate sulla seconda, <span id="id5">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>, citando un esempio basato su un celebre studio di <span id="id6">Anderson and Dill [<a class="reference internal" href="../references/bibliography.html#id36" title="Craig A Anderson and Karen E Dill. Video games and aggressive thoughts, feelings, and behavior in the laboratory and in life. Journal of Personality and Social Psychology, 78(4):772–790, 2000.">AD00</a>]</span>.
Questo studio riguarda l’effetto dei videogiochi violenti sul comportamento aggressivo dei giocatori e include una serie di esperimenti in cui i partecipanti sono stati esposti a videogiochi con diversi livelli di contenuti violenti. In seguito, sono stati misurati vari aspetti dell’aggressività attraverso questionari e osservazioni comportamentali. Gli autori hanno scoperto che c’era una correlazione significativa tra il gioco di videogiochi violenti e un aumento dell’aggressività nei partecipanti. Hanno concluso che i videogiochi violenti possono aumentare i comportamenti aggressivi e hanno suggerito che tale effetto potrebbe essere dovuto all’immersione in un contesto violento e all’apprendimento di nuovi schemi comportamentali attraverso il gioco. Questo studio è diventato un punto di riferimento nelle discussioni sulla regolamentazione dei contenuti dei videogiochi e sull’impatto potenziale che i media possono avere sul comportamento.</p>
<p>Ispirandosi ai risultati riportati da <span id="id7">Anderson and Dill [<a class="reference internal" href="../references/bibliography.html#id36" title="Craig A Anderson and Karen E Dill. Video games and aggressive thoughts, feelings, and behavior in the laboratory and in life. Journal of Personality and Social Psychology, 78(4):772–790, 2000.">AD00</a>]</span>, <span id="id8">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> hanno costruito la figura seguente.</p>
<figure class="align-default" id="file-collection">
<a class="reference internal image-reference" href="../_images/zhang_fig_1.png"><img alt="../_images/zhang_fig_1.png" src="../_images/zhang_fig_1.png" style="height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Incertezza inferenziale vs. variabilità dei risultati. (Sinistra) Medie stimate e una barra di errore che rappresenta un errore standard (SE) sopra e uno sotto la media, per due condizioni in un esperimento. L’errore standard è una misura dell’incertezza nella nostra inferenza della media. (Destra) Risultati individuali mostrati in aggiunta agli stessi errori standard sulla Sinistra. Con solo 100 partecipanti per condizione (Sopra), abbiamo stime meno sicure della media rispetto a quando abbiamo 800 partecipanti per condizione (Sotto). Tuttavia, più dati non riducono sistematicamente la variabilità nei risultati stessi. La figura è tratta da <span id="id9">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>.</span><a class="headerlink" href="#file-collection" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>I grafici a sinistra mostrano i punteggi medi di aggressività per i due gruppi (videogioco violento e non violento), con le barre di errore che simbolizzano l’incertezza inferenziale. Questo formato agevola l‘“inferenza visiva”, permettendo una deduzione immediata dell’intervallo possibile per i valori medi.</p></li>
<li><p>I grafici a destra includono le stesse informazioni dei grafici a sinistra, ma aggiungono dei punti colorati che rappresentano i risultati individuali. Questo formato, proposto originariamente da Gardner e Altman, evidenzia non solo l’incertezza inferenziale ma anche la variabilità dei risultati e la dimensione dell’effetto.</p></li>
</ul>
<p>Sebbene a prima vista i grafici forniti a sinistra e a destra nella figura possano sembrare equivalenti, essi enfatizzano aspetti differenti. I grafici a sinistra possono portare a un‘“illusione di prevedibilità”, dove la variabilità dei risultati viene sottovalutata e l’effetto dei videogiochi violenti sul comportamento aggressivo viene visto come più forte e determinante di quanto effettivamente sia.</p>
<p>I grafici a destra, invece, mettendo in luce i risultati individuali, forniscono una visione più equilibrata. Fanno capire che la relazione tra videogiochi violenti e comportamento aggressivo non è deterministica e sottolineano l’importanza di considerare la variabilità all’interno di ciascun gruppo.</p>
<p>Questa distinzione diventa ancora più evidente con l’aumentare della dimensione del campione. L’aumento delle dimensioni del campione non riduce necessariamente la variabilità dei risultati, e questa è una sfumatura che può essere persa se si enfatizza solo l’incertezza inferenziale.</p>
<p>In sintesi, la scelta del formato grafico può avere un impatto importante sulle conclusioni tratte dal lettore. Sebbene i grafici focalizzati sull’incertezza inferenziale siano spesso considerati una “migliore pratica”, <span id="id10">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> sottolineano che essi possono indurre in errore, specialmente se non vengono chiaramente distinti da altri concetti come la variabilità dei risultati.</p>
<p>In pratica, l’ambiguità nella terminologia statistica utilizzata e nelle descrizioni delle rappresentazioni grafiche può ulteriormente confondere il lettore. È invece essenziale fornire una comunicazione chiara e trasparente nella presentazione dei risultati statistici. La scelta del formato appropriato non è dunque una mera questione di stile, ma riveste un aspetto di sostanza fondamentale, mirato a garantire una comprensione accurata e onesta dei risultati della ricerca empirica.</p>
<p>I risultati degli esperimenti di <span id="id11">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>, i quali hanno chiesto a gruppi di esperti di interpretare dei grafici come quelli illustrati sopraa, mettono in luce una problematica seria nella comunicazione scientifica, evidenziando come l’enfasi pervasiva sull’incertezza inferenziale nelle visualizzazioni dei dati possa ingannare persino gli esperti in merito alla dimensione e all’importanza dei risultati della ricerca. Questa situazione può portare a una percezione distorta degli effetti, facendoli apparire più significativi di quanto non siano realmente. Tale ‘illusione di prevedibilità’ sembra originarsi dalla confusione tra i concetti di incertezza inferenziale, che si riferisce all’intervallo entro cui è probabile che si trovi il valore vero di un parametro, e la variabilità dei risultati, che descrive quanto i dati individuali possano differire tra loro.</p>
<p>Proprio per risolvere questo problema, <span id="id12">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> propongono una soluzione semplice e diretta: visualizzare contemporaneamente sia l’incertezza inferenziale che la variabilità dei risultati, rappresentando i dati individuali accanto alle stime statistiche – come nei grafici forniti nella colonna di sinistra della figura precedente. Questo approccio permette ai lettori di distinguere più chiaramente tra queste due nozioni, contribuendo così a una comprensione più precisa e onesta della grandezza e della rilevanza dell’effetto studiato, senza rischiare di sovrastimarne l’importanza.</p>
<div class="proof example admonition" id="illusion-expl-1">
<p class="admonition-title"><span class="caption-number">Example 10 </span></p>
<section class="example-content" id="proof-content">
<p>Consideriamo ora i dati utilizzti da <span id="id13">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>. Poniamoci il problema di ottenere i valori numerici che rappresentano l’incertezza inferenziale e la variabilità dei risultati.</p>
</section>
</div><p>Iniziamo importando i dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/video_games.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>outcome</th>
      <th>condition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.145137</td>
      <td>Violent game</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.484930</td>
      <td>Violent game</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.297470</td>
      <td>Violent game</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.760477</td>
      <td>Violent game</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.497964</td>
      <td>Violent game</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Il dataset completo usato da <span id="id14">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> contiene 800 osservazioni.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(800, 2)
</pre></div>
</div>
</div>
</div>
<p>Per il dataset completo calcoliamo la media della variabile di esito nei due gruppi, insieme alle deviazioni standard e agli errori standard della media.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;condition&#39;</span><span class="p">)[</span><span class="s1">&#39;outcome&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
    <span class="n">standard_deviation</span><span class="o">=</span><span class="s1">&#39;std&#39;</span><span class="p">,</span>
    <span class="n">standard_error</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                  mean  standard_deviation  standard_error
condition                                                 
Non-violent game  6.65                0.53          0.0265
Violent game      6.81                0.51          0.0255
</pre></div>
</div>
</div>
</div>
<p>Consideriamo ora un sottoinsieme di questi dati, ovvero selezioniamo in maniera casuale 100 righe dal DataFrame precedente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assuming df has at least 100 rows</span>
<span class="n">df_100</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Svolgiamo gli stessi calcoli per questo sottoinsieme di dati.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_100</span> <span class="o">=</span> <span class="n">df_100</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;condition&#39;</span><span class="p">)[</span><span class="s1">&#39;outcome&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
    <span class="n">standard_deviation</span><span class="o">=</span><span class="s1">&#39;std&#39;</span><span class="p">,</span>
    <span class="n">standard_error</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">summary_100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                      mean  standard_deviation  standard_error
condition                                                     
Non-violent game  6.688967            0.531433        0.073696
Violent game      6.833342            0.592238        0.085482
</pre></div>
</div>
</div>
</div>
<p>Si noti che, nelle analisi condotte su due campioni di dimensioni differenti, <span class="math notranslate nohighlight">\(n\)</span> = 800 e <span class="math notranslate nohighlight">\(n\)</span> = 100, si manifestano delle lievi differenze nei valori delle medie e delle deviazioni standard. Queste discrepanze sono attese e si possono attribuire alla variabilità naturale dei campioni. Nonostante ciò, possiamo dire che le medie e deviazioni standard sono sostanzialmente simili nei due campioni di grandezze diverse.</p>
<p>Un discorso diverso invece riguarda invece l’errore standard della media: esso è, per definizione, più piccolo quando la numerosità campionaria è più grande. In altre parole, l’incertezza inferenziale sul vero valore della media della popolazione <span class="math notranslate nohighlight">\(\mu\)</span> diminuisce all’aumentare della grandezza del campione.</p>
<p>Questo fenomeno, tuttavia, non ha alcun collegamento con l’effetto che i video-game, violenti o meno, possono avere sull’aggressività del comportamento successivo. La correlazione tra il tipo di video-game giocato e il successivo comportamento aggressivo risulta essere molto debole, indipendentemente dalla grandezza del campione analizzato.</p>
<p>Per una valutazione più dettagliata della relazione tra tipo di videogioco e agressività successiva, possiamo calcolare l’indice <span class="math notranslate nohighlight">\(d\)</span> di Cohen, una misura standardizzata che quantifica la differenza tra le medie dei due gruppi. Iniziamo con il campione di dimensioni maggiori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cohen_d</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">sd1</span><span class="p">,</span> <span class="n">sd2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">):</span>
    <span class="n">pooled_sd</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">n1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">sd1</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">n2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">sd2</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mean2</span> <span class="o">-</span> <span class="n">mean1</span><span class="p">)</span> <span class="o">/</span> <span class="n">pooled_sd</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean1</span> <span class="o">=</span> <span class="mf">6.663322</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="mf">6.861076</span>
<span class="n">sd1</span> <span class="o">=</span> <span class="mf">0.566330</span>
<span class="n">sd2</span> <span class="o">=</span> <span class="mf">0.519873</span>
<span class="n">n1</span> <span class="o">=</span> <span class="n">n2</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cohen_d</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">sd1</span><span class="p">,</span> <span class="n">sd2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cohen&#39;s d:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cohen&#39;s d: 0.3637871999925845
</pre></div>
</div>
</div>
</div>
<p>Calcoliamo ora il <span class="math notranslate nohighlight">\(d\)</span> di Cohen nel caso di <span class="math notranslate nohighlight">\(n\)</span> = 100.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean1</span> <span class="o">=</span> <span class="mf">6.65</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="mf">6.81</span>
<span class="n">sd1</span> <span class="o">=</span> <span class="mf">0.53</span>
<span class="n">sd2</span> <span class="o">=</span> <span class="mf">0.51</span>
<span class="n">n1</span> <span class="o">=</span> <span class="n">n2</span> <span class="o">=</span> <span class="mi">800</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">cohen_d</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">sd1</span><span class="p">,</span> <span class="n">sd2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cohen&#39;s d:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cohen&#39;s d: 0.3076354277014899
</pre></div>
</div>
</div>
</div>
<p>In entrambi i casi, possiamo dire che la dimensione dell’effetto è piccola, secondo la metrica dell’indice <span class="math notranslate nohighlight">\(d\)</span> di Cohen, che definisce un effetto come “debole” quando il valore è compreso tra 0.2 e 0.4.</p>
<p>Questo significa che, all’aumentare delle dimensioni del campione, l’incertezza inferenziale nella stima della differenza tra le medie dei due gruppi diminuisce, e ciò può portare a rilevare una differenza statistica tra le medie dei due gruppi. Tuttavia, ciò non implica che un aumento della dimensione del campione renda l’effetto del trattamento più marcato. La grandezza dell’effetto del trattamento è indipendente dalla dimensione del campione; essa dipende invece dalla differenza tra le medie dei due gruppi e dalla variabilità delle osservazioni all’interno di ciascun gruppo. In altre parole, la misura dell’effetto è determinata dalle caratteristiche intrinseche del fenomeno studiato e non è influenzata dall’ampiezza dei campioni utilizzati nell’analisi.</p>
</section>
<section id="commenti-e-considerazioni-conclusive">
<h2>Commenti e considerazioni conclusive<a class="headerlink" href="#commenti-e-considerazioni-conclusive" title="Permalink to this heading">#</a></h2>
<p><span id="id15">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span> concludono il loro articolo riflettendo sul modo in cui la ricerca scientifica viene condotta e i suoi risultati vengono comunicati. Essi evidenziano che, in molti campi scientifici, l’attenzione si è concentrata per lungo tempo sull’inferenza (ossia, sull’ottenimento di stime non distorte degli effetti sperimentali) piuttosto che sulla previsione (come, ad esempio, la proiezione dei possibili risultati futuri). Questa enfasi potrebbe derivare, in parte, dalla complessità intrinseca della previsione, specialmente quando confrontata con l’inferenza. Infatti, stimare un effetto medio su una popolazione, come avviene nell’inferenza statistica standard, è indubbiamente più semplice che prevedere i risultati individuali, tenendo conto di tutti i fattori che potrebbero influenzare un fenomeno specifico. Tuttavia, questa enfasi sull’inferenza può generare confusione nella comunicazione dei risultati dello studio, dando l’impressione che i risultati della ricerca possano prevedere gli esiti individuali, quando in realtà hanno soltanto stabilito un effetto medio. Di conseguenza, anche gli esperti possono finire con l’equiparare le rappresentazioni visive che esprimono l’incertezza inferenziale con quelle che trasmettono informazioni sulla previsione dei dati individuali.</p>
<p>Per <span id="id16">Zhang <em>et al.</em> [<a class="reference internal" href="../references/bibliography.html#id37" title="Sam Zhang, Patrick R Heck, Michelle N Meyer, Christopher F Chabris, Daniel G Goldstein, and Jake M Hofman. An illusion of predictability in scientific results: even experts confuse inferential uncertainty and outcome variability. Proceedings of the National Academy of Sciences, 120(33):e2302491120, 2023.">ZHM+23</a>]</span>, la soluzione a questo problema sta nella comunicazione chiara e integrata sia dell’incertezza inferenziale che della variabilità dei risultati. Invece di favorire l’inferenza rispetto alla previsione (o viceversa), gli autori propongono un approccio olistico che consideri entrambi gli aspetti dell’indagine scientifica, presentandoli in modo parallelo e comprensibile. Ciò consentirebbe ai lettori di trarre inferenze più accurate ed appropriate dai dati presentati. Questa prospettiva integrata potrebbe rappresentare un passo importante verso una comprensione e una comunicazione della ricerca più trasparenti e precise, contribuendo a colmare il divario tra ciò che gli studi effettivamente dimostrano e ciò che viene percepito da chi li legge.</p>
</section>
<section id="watermark">
<h2>Watermark<a class="headerlink" href="#watermark" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: Thu Nov 09 2023

Python implementation: CPython
Python version       : 3.11.6
IPython version      : 8.16.1

seaborn   : 0.13.0
matplotlib: 3.8.0
arviz     : 0.16.1
pandas    : 2.1.1
numpy     : 1.25.2
scipy     : 1.11.3
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="04a_sampling_distr.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Stime, stimatori e parametri</p>
      </div>
    </a>
    <a class="right-next"
       href="E_rv_discrete.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">✏️ Esercizi</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparazione-del-notebook">Preparazione del Notebook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#la-rappresentazione-dell-incertezza-inferenziale">La rappresentazione dell’incertezza inferenziale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#illusione-di-prevedibilita">Illusione di prevedibilità</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#commenti-e-considerazioni-conclusive">Commenti e considerazioni conclusive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#watermark">Watermark</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Corrado Caudek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>